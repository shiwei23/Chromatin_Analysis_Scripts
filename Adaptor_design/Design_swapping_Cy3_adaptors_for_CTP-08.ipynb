{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design adaptors to convert CTP-08 Cy3 into Cy7 and Cy5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18848\n"
     ]
    }
   ],
   "source": [
    "%run \"E:\\Users\\puzheng\\Documents\\Startup_py3.py\"\n",
    "sys.path.append(r\"E:\\Users\\puzheng\\Documents\")\n",
    "\n",
    "import ImageAnalysis3 as ia\n",
    "%matplotlib notebook\n",
    "\n",
    "from ImageAnalysis3 import *\n",
    "print(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biopython imports\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "from Bio.Blast import NCBIXML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_filename = r'\\\\10.245.74.69\\Chromatin_NAS_2\\Libraries\\CTP-08_IgH\\5kb\\final_probes\\batch_1_final_probes.fasta'\n",
    "if not os.path.isfile(probe_filename):\n",
    "    raise IOError(f\"input probe file: {probe_filename} doesn't exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_records = []\n",
    "with open(probe_filename, 'r') as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        pb_records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get readout names in the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout_names = {}\n",
    "for _r in pb_records:\n",
    "    _rid = int(_r.id.split('gene_')[1].split('_')[0])\n",
    "    _rd_names = _r.id.split('[')[1].split(']')[0].split(',')\n",
    "    if _rid not in readout_names:\n",
    "        readout_names[_rid] = []\n",
    "        for _rd in _rd_names:\n",
    "            if _rd not in readout_names[_rid]:\n",
    "                if \"_u\" not in _rd:\n",
    "                    readout_names[_rid].append(_rd)\n",
    "                else:\n",
    "                    readout_names[_rid].append(_rd.split('_u')[0])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_info = {}\n",
    "for _r in pb_records:\n",
    "    _rid = int(_r.id.split('gene_')[1].split('_')[0])\n",
    "    \n",
    "    if _rid not in region_info:\n",
    "        # extract region info\n",
    "        _reg_info = _r.id.split('_gene')[0].split('chr')[1]\n",
    "        #print(_reg_info)\n",
    "        chr_name = 'chr'+_reg_info.split(':')[0]\n",
    "        start = int(_reg_info.split(':')[1].split('-')[0])\n",
    "        end = int(_reg_info.split(':')[1].split('-')[1])\n",
    "        mid = int((start+end)/2)\n",
    "        region_info[_rid] = {'chr': chr_name,\n",
    "                             'start': start,\n",
    "                             'end': end,\n",
    "                             'mid': mid,\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load readouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout_folder = r'\\\\10.245.74.69\\Chromatin_NAS_2\\Libraries\\Readouts'\n",
    "ref_files = [_fl for _fl in os.listdir(readout_folder) if 'designed_readouts' in _fl]\n",
    "\n",
    "ref_readout_dict = {}\n",
    "ref_readout_record_dict = {}\n",
    "for _fl in ref_files:\n",
    "    _channel = int(_fl.split('designed_readouts_')[1].split('.fasta')[0])\n",
    "    _ref_readout_names = []\n",
    "    _ref_readout_records = []\n",
    "    with open(os.path.join(readout_folder, _fl), 'r') as _rd_handle:\n",
    "        for _readout in SeqIO.parse(_rd_handle, \"fasta\"):\n",
    "            _ref_readout_names.append(_readout.id)\n",
    "            _ref_readout_records.append(_readout)\n",
    "    ref_readout_dict[_channel] = _ref_readout_names\n",
    "    ref_readout_record_dict[_channel] = _ref_readout_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort regions with readout types\n",
    "readout_by_channel = {_c:{} for _c in ref_readout_dict}\n",
    "for _reg, _names in readout_names.items():\n",
    "    for _c in readout_by_channel:\n",
    "        _rd = np.unique(_names)[0]\n",
    "        if _rd in ref_readout_dict[_c] and _reg not in readout_by_channel.values():\n",
    "            readout_by_channel[_c][_reg] = _rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here, adaptors for cy3 are the ones we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SeqRecord(seq=Seq('TTTGCACTGCCGTCCTTGAC', SingleLetterAlphabet()), id='Stv_82', name='Stv_82', description='Stv_82 cy7 rev-com_last20', dbxrefs=[]), SeqRecord(seq=Seq('GATCCGATTGGAACCGTCCC', SingleLetterAlphabet()), id='Stv_1', name='Stv_1', description='Stv_1 cy5 rev-com_last20', dbxrefs=[]), SeqRecord(seq=Seq('TGCGAACTGTCCGGCTTTCA', SingleLetterAlphabet()), id='Stv_79', name='Stv_79', description='Stv_79 cy3 rev-com_last20', dbxrefs=[])]\n"
     ]
    }
   ],
   "source": [
    "# load readout sites\n",
    "adaptor_folder = r'\\\\10.245.74.69\\Chromatin_NAS_2\\Libraries\\Adaptors'\n",
    "readout_site_file = os.path.join(adaptor_folder, 'Readout_sites.fasta')\n",
    "readout_sites = []\n",
    "with open(readout_site_file, 'r') as _rd_handle:\n",
    "    for _readout in SeqIO.parse(_rd_handle, \"fasta\"):\n",
    "        readout_sites.append(_readout)\n",
    "print(readout_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of cy3 convert to cy5 and cy7\n",
    "num_cy7 = np.int(len(readout_names)/2)\n",
    "num_cy5 = len(readout_names) - num_cy7\n",
    "num_cy3_to_7 = num_cy7 - len(readout_by_channel[750])\n",
    "num_cy3_to_5 = num_cy5 - len(readout_by_channel[647])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cy3_to_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "# pick records \n",
    "cy3_records = []\n",
    "for _reg, _name in readout_by_channel[561].items():\n",
    "    for _record in ref_readout_record_dict[561]:\n",
    "        if _record.id == _name:\n",
    "            cy3_records.append(_record)\n",
    "            break\n",
    "print(len(cy3_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate adaptor\n",
    "reload(library_tools.readouts)\n",
    "from ImageAnalysis3.library_tools.readouts import Generate_adaptors\n",
    "\n",
    "cy3_adaptors = Generate_adaptors(cy3_records[:2*min(num_cy3_to_5, num_cy3_to_7)], readout_sites[:2])\n",
    "\n",
    "cy3_adaptors += Generate_adaptors(cy3_records[2*min(num_cy3_to_5, num_cy3_to_7):], readout_sites[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate csv file to order in IDT\n",
    "import csv\n",
    "\n",
    "with open(os.path.join(adaptor_folder, 'CTP-08_swap_cy3_adaptor.csv'), 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', \n",
    "                       quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    # write header\n",
    "    _header = ['Name', 'Sequence', 'Scale', 'Purification']\n",
    "    csvwriter.writerow(_header)\n",
    "    # write sequence\n",
    "    for _adaptor in cy3_adaptors:\n",
    "        _info = [_adaptor.id, str(_adaptor.seq), '25nm', 'STD']\n",
    "        csvwriter.writerow(_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 Stv_119_2xStv_82\n",
      "46 Stv_120_2xStv_1\n",
      "49 Stv_121_2xStv_82\n",
      "52 Stv_125_2xStv_1\n",
      "55 Stv_127_2xStv_82\n",
      "59 Stv_129_2xStv_1\n",
      "62 Stv_130_2xStv_82\n",
      "65 Stv_131_2xStv_1\n",
      "68 Stv_133_2xStv_82\n",
      "71 Stv_136_2xStv_1\n",
      "74 Stv_145_2xStv_82\n",
      "77 Stv_182_2xStv_1\n",
      "80 NDB_3_2xStv_82\n",
      "83 NDB_6_2xStv_1\n",
      "86 NDB_9_2xStv_82\n",
      "89 NDB_12_2xStv_1\n",
      "92 NDB_15_2xStv_82\n",
      "95 NDB_18_2xStv_1\n",
      "98 NDB_21_2xStv_82\n",
      "101 NDB_24_2xStv_1\n",
      "104 NDB_27_2xStv_82\n",
      "107 NDB_30_2xStv_1\n",
      "110 NDB_33_2xStv_82\n",
      "113 NDB_36_2xStv_1\n",
      "325 NDB_243_2xStv_82\n",
      "328 NDB_246_2xStv_1\n",
      "331 NDB_249_2xStv_82\n",
      "334 NDB_252_2xStv_1\n",
      "341 NDB_258_2xStv_82\n",
      "344 NDB_261_2xStv_1\n",
      "347 NDB_264_2xStv_82\n",
      "350 NDB_267_2xStv_1\n",
      "353 NDB_270_2xStv_82\n",
      "356 NDB_273_2xStv_1\n",
      "359 NDB_276_2xStv_82\n",
      "362 NDB_279_2xStv_1\n",
      "365 NDB_282_2xStv_82\n",
      "368 NDB_285_2xStv_1\n",
      "371 NDB_288_2xStv_82\n",
      "374 NDB_291_2xStv_1\n",
      "377 NDB_294_2xStv_82\n",
      "381 NDB_297_2xStv_1\n",
      "384 NDB_300_2xStv_82\n",
      "387 NDB_303_2xStv_1\n",
      "390 NDB_306_2xStv_82\n",
      "393 NDB_309_2xStv_82\n"
     ]
    }
   ],
   "source": [
    "# update dict\n",
    "new_readout_by_channel = {\n",
    "    750: readout_by_channel[750],\n",
    "    647: readout_by_channel[647],\n",
    "}\n",
    "for (_reg, _name), _adaptor in zip(readout_by_channel[561].items(),cy3_adaptors):\n",
    "    print(_reg, _adaptor.id)\n",
    "    if 'Stv_82' in _adaptor.id:\n",
    "        new_readout_by_channel[750][_reg] = _name\n",
    "    elif 'Stv_1' in _adaptor.id:\n",
    "        new_readout_by_channel[647][_reg] = _name\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{750: {41: 'Stv_19',\n",
       "  44: 'Stv_20',\n",
       "  47: 'Stv_21',\n",
       "  50: 'Stv_22',\n",
       "  53: 'Stv_23',\n",
       "  56: 'Stv_25',\n",
       "  60: 'Stv_26',\n",
       "  63: 'Stv_27',\n",
       "  66: 'Stv_28',\n",
       "  69: 'Stv_29',\n",
       "  72: 'Stv_30',\n",
       "  75: 'Stv_31',\n",
       "  78: 'NDB_1',\n",
       "  81: 'NDB_4',\n",
       "  84: 'NDB_7',\n",
       "  87: 'NDB_10',\n",
       "  90: 'NDB_13',\n",
       "  93: 'NDB_16',\n",
       "  96: 'NDB_19',\n",
       "  99: 'NDB_22',\n",
       "  102: 'NDB_25',\n",
       "  105: 'NDB_28',\n",
       "  108: 'NDB_31',\n",
       "  111: 'NDB_34',\n",
       "  114: 'NDB_37',\n",
       "  323: 'NDB_241',\n",
       "  326: 'NDB_244',\n",
       "  329: 'NDB_247',\n",
       "  332: 'NDB_250',\n",
       "  335: 'NDB_253',\n",
       "  339: 'NDB_256',\n",
       "  342: 'NDB_259',\n",
       "  345: 'NDB_262',\n",
       "  348: 'NDB_265',\n",
       "  351: 'NDB_268',\n",
       "  354: 'NDB_271',\n",
       "  357: 'NDB_274',\n",
       "  360: 'NDB_277',\n",
       "  363: 'NDB_280',\n",
       "  366: 'NDB_283',\n",
       "  369: 'NDB_286',\n",
       "  372: 'NDB_289',\n",
       "  375: 'NDB_292',\n",
       "  379: 'NDB_295',\n",
       "  382: 'NDB_298',\n",
       "  388: 'NDB_304',\n",
       "  391: 'NDB_307',\n",
       "  394: 'NDB_310',\n",
       "  43: 'Stv_119',\n",
       "  49: 'Stv_121',\n",
       "  55: 'Stv_127',\n",
       "  62: 'Stv_130',\n",
       "  68: 'Stv_133',\n",
       "  74: 'Stv_145',\n",
       "  80: 'NDB_3',\n",
       "  86: 'NDB_9',\n",
       "  92: 'NDB_15',\n",
       "  98: 'NDB_21',\n",
       "  104: 'NDB_27',\n",
       "  110: 'NDB_33',\n",
       "  325: 'NDB_243',\n",
       "  331: 'NDB_249',\n",
       "  341: 'NDB_258',\n",
       "  347: 'NDB_264',\n",
       "  353: 'NDB_270',\n",
       "  359: 'NDB_276',\n",
       "  365: 'NDB_282',\n",
       "  371: 'NDB_288',\n",
       "  377: 'NDB_294',\n",
       "  384: 'NDB_300',\n",
       "  390: 'NDB_306',\n",
       "  393: 'NDB_309'},\n",
       " 647: {42: 'Stv_53',\n",
       "  45: 'Stv_54',\n",
       "  48: 'Stv_59',\n",
       "  51: 'Stv_60',\n",
       "  54: 'Stv_61',\n",
       "  57: 'Stv_63',\n",
       "  61: 'Stv_64',\n",
       "  64: 'Stv_65',\n",
       "  67: 'Stv_86',\n",
       "  70: 'Stv_87',\n",
       "  73: 'Stv_88',\n",
       "  76: 'Stv_90',\n",
       "  79: 'NDB_2',\n",
       "  82: 'NDB_5',\n",
       "  85: 'NDB_8',\n",
       "  88: 'NDB_11',\n",
       "  91: 'NDB_14',\n",
       "  94: 'NDB_17',\n",
       "  97: 'NDB_20',\n",
       "  100: 'NDB_23',\n",
       "  103: 'NDB_26',\n",
       "  106: 'NDB_29',\n",
       "  109: 'NDB_32',\n",
       "  112: 'NDB_35',\n",
       "  115: 'NDB_38',\n",
       "  321: 'NDB_239',\n",
       "  324: 'NDB_242',\n",
       "  327: 'NDB_245',\n",
       "  330: 'NDB_248',\n",
       "  333: 'NDB_251',\n",
       "  337: 'NDB_254',\n",
       "  340: 'NDB_257',\n",
       "  343: 'NDB_260',\n",
       "  346: 'NDB_263',\n",
       "  349: 'NDB_266',\n",
       "  352: 'NDB_269',\n",
       "  355: 'NDB_272',\n",
       "  358: 'NDB_275',\n",
       "  361: 'NDB_278',\n",
       "  364: 'NDB_281',\n",
       "  367: 'NDB_284',\n",
       "  370: 'NDB_287',\n",
       "  373: 'NDB_290',\n",
       "  376: 'NDB_293',\n",
       "  380: 'NDB_296',\n",
       "  383: 'NDB_299',\n",
       "  386: 'NDB_302',\n",
       "  389: 'NDB_305',\n",
       "  392: 'NDB_308',\n",
       "  395: 'NDB_311',\n",
       "  46: 'Stv_120',\n",
       "  52: 'Stv_125',\n",
       "  59: 'Stv_129',\n",
       "  65: 'Stv_131',\n",
       "  71: 'Stv_136',\n",
       "  77: 'Stv_182',\n",
       "  83: 'NDB_6',\n",
       "  89: 'NDB_12',\n",
       "  95: 'NDB_18',\n",
       "  101: 'NDB_24',\n",
       "  107: 'NDB_30',\n",
       "  113: 'NDB_36',\n",
       "  328: 'NDB_246',\n",
       "  334: 'NDB_252',\n",
       "  344: 'NDB_261',\n",
       "  350: 'NDB_267',\n",
       "  356: 'NDB_273',\n",
       "  362: 'NDB_279',\n",
       "  368: 'NDB_285',\n",
       "  374: 'NDB_291',\n",
       "  381: 'NDB_297',\n",
       "  387: 'NDB_303'}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_readout_by_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 72]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "save_folder = r'\\\\10.245.74.158\\Chromatin_NAS_6\\20200920-B_DMSO_CTP-08_IgH\\Analysis'\n",
    "with open(os.path.join(save_folder, 'adaptor_sequences.csv'), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', \n",
    "                           quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    _header = ['group', 'hyb', ]\n",
    "    for _ch in new_readout_by_channel:\n",
    "        _header += [f\"{_ch}_region\", f\"{_ch}_readout\"]\n",
    "    dict_sizes = [len(_v) for _k,_v in new_readout_by_channel.items()]\n",
    "    print(dict_sizes)\n",
    "    csvwriter.writerow(_header)\n",
    "    \n",
    "    for _i in range(max(dict_sizes)):\n",
    "        _row = [int((_i)/32)+1, _i%32+1,] \n",
    "        for _ch, _dict in new_readout_by_channel.items():\n",
    "            if _i >= len(_dict):\n",
    "                _row += ['', '']\n",
    "            else:\n",
    "                _regs = list(_dict.keys()) \n",
    "                _row += [_regs[_i], _dict[_regs[_i]]]      \n",
    "        csvwriter.writerow(_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save color_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hyb', '750', '647', '488', '405']\n",
      "['H0R0', 'forward_chrom', 'reverse_chrom', 'beads', 'DAPI']\n",
      "['H1R1', 'u41', 'u42', 'beads']\n",
      "['H2R2', 'u43', 'u45', 'beads']\n",
      "['H3R3', 'u44', 'u46', 'beads']\n",
      "['H4R4', 'u47', 'u48', 'beads']\n",
      "['H5R5', 'u49', 'u51', 'beads']\n",
      "['H6R6', 'u50', 'u52', 'beads']\n",
      "['H7R7', 'u53', 'u54', 'beads']\n",
      "['H8R8', 'u55', 'u57', 'beads']\n",
      "['H9R9', 'u56', 'u59', 'beads']\n",
      "['H10R10', 'u60', 'u61', 'beads']\n",
      "['H11R11', 'u62', 'u64', 'beads']\n",
      "['H12R12', 'u63', 'u65', 'beads']\n",
      "['H13R13', 'u66', 'u67', 'beads']\n",
      "['H14R14', 'u68', 'u70', 'beads']\n",
      "['H15R15', 'u69', 'u71', 'beads']\n",
      "['H16R16', 'u72', 'u73', 'beads']\n",
      "['H17R17', 'u74', 'u76', 'beads']\n",
      "['H18R18', 'u75', 'u77', 'beads']\n",
      "['H19R19', 'u78', 'u79', 'beads']\n",
      "['H20R20', 'u80', 'u82', 'beads']\n",
      "['H21R21', 'u81', 'u83', 'beads']\n",
      "['H22R22', 'u84', 'u85', 'beads']\n",
      "['H23R23', 'u86', 'u88', 'beads']\n",
      "['H24R24', 'u87', 'u89', 'beads']\n",
      "['H25R25', 'u90', 'u91', 'beads']\n",
      "['H26R26', 'u92', 'u94', 'beads']\n",
      "['H27R27', 'u93', 'u95', 'beads']\n",
      "['H28R28', 'u96', 'u97', 'beads']\n",
      "['H29R29', 'u98', 'u100', 'beads']\n",
      "['H30R30', 'u99', 'u101', 'beads']\n",
      "['H31R31', 'u102', 'u103', 'beads']\n",
      "['H32R32', 'u104', 'u106', 'beads']\n",
      "['H33R33', 'u105', 'u107', 'beads']\n",
      "['H34R34', 'u108', 'u109', 'beads']\n",
      "['H35R35', 'u110', 'u112', 'beads']\n",
      "['H36R36', 'u111', 'u113', 'beads']\n",
      "['H37R37', 'u114', 'u115', 'beads']\n",
      "['H38R38', 'u323', 'u321', 'beads']\n",
      "['H39R39', 'u325', 'u324', 'beads']\n",
      "['H40R40', 'u326', 'u327', 'beads']\n",
      "['H41R41', 'u329', 'u328', 'beads']\n",
      "['H42R42', 'u331', 'u330', 'beads']\n",
      "['H43R43', 'u332', 'u333', 'beads']\n",
      "['H44R44', 'u335', 'u334', 'beads']\n",
      "['H45R45', 'u339', 'u337', 'beads']\n",
      "['H46R46', 'u341', 'u340', 'beads']\n",
      "['H47R47', 'u342', 'u343', 'beads']\n",
      "['H48R48', 'u345', 'u344', 'beads']\n",
      "['H49R49', 'u347', 'u346', 'beads']\n",
      "['H50R50', 'u348', 'u349', 'beads']\n",
      "['H51R51', 'u351', 'u350', 'beads']\n",
      "['H52R52', 'u353', 'u352', 'beads']\n",
      "['H53R53', 'u354', 'u355', 'beads']\n",
      "['H54R54', 'u357', 'u356', 'beads']\n",
      "['H55R55', 'u359', 'u358', 'beads']\n",
      "['H56R56', 'u360', 'u361', 'beads']\n",
      "['H57R57', 'u363', 'u362', 'beads']\n",
      "['H58R58', 'u365', 'u364', 'beads']\n",
      "['H59R59', 'u366', 'u367', 'beads']\n",
      "['H60R60', 'u369', 'u368', 'beads']\n",
      "['H61R61', 'u371', 'u370', 'beads']\n",
      "['H62R62', 'u372', 'u373', 'beads']\n",
      "['H63R63', 'u375', 'u374', 'beads']\n",
      "['H64R64', 'u377', 'u376', 'beads']\n",
      "['H65R65', 'u379', 'u380', 'beads']\n",
      "['H66R66', 'u382', 'u381', 'beads']\n",
      "['H67R67', 'u384', 'u383', 'beads']\n",
      "['H68R68', 'u388', 'u386', 'beads']\n",
      "['H69R69', 'u390', 'u387', 'beads']\n",
      "['H70R70', 'u391', 'u389', 'beads']\n",
      "['H71R71', 'u393', 'u392', 'beads']\n",
      "['H72R72', 'u394', 'u395', 'beads']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "drift_channel = '488'\n",
    "dapi_channel = '405'\n",
    "chrom_labels = {'750': 'forward',\n",
    "                '647': 'reverse',}\n",
    "\n",
    "with open(os.path.join(save_folder, 'Color_Usage.csv'), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', \n",
    "                           quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    # write header\n",
    "    _header = ['Hyb']\n",
    "    for _ch in new_readout_by_channel:\n",
    "        _header .append(str(_ch))\n",
    "    _header.append(drift_channel)\n",
    "    _header.append(dapi_channel)\n",
    "    print(_header)\n",
    "    csvwriter.writerow(_header)\n",
    "    \n",
    "    # write reference frame\n",
    "    _ref_row = ['H0R0']\n",
    "    for _ch in new_readout_by_channel:\n",
    "        if str(_ch) in chrom_labels:\n",
    "            _ref_row.append(chrom_labels[str(_ch)]+'_chrom')\n",
    "        else:\n",
    "            _ref_row.append(\"\")\n",
    "    _ref_row.append('beads')\n",
    "    _ref_row.append('DAPI')\n",
    "    print(_ref_row)\n",
    "    csvwriter.writerow(_ref_row)\n",
    "    \n",
    "    \n",
    "    for _i in range(max(dict_sizes)):\n",
    "        _row = [f\"H{int(_i)+1}R{int(_i)+1}\",] \n",
    "        for _ch, _dict in new_readout_by_channel.items():\n",
    "            if _i >= len(_dict):\n",
    "                _row += ['']\n",
    "            else:\n",
    "                _regs = sorted(_dict) \n",
    "                _row += [f\"u{_regs[_i]}\"]\n",
    "        _row.append(\"beads\")\n",
    "        print(_row)\n",
    "        csvwriter.writerow(_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save region_positions for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(os.path.join(save_folder, 'Region_Positions.csv'), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', \n",
    "                           quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    # write header\n",
    "    csvwriter.writerow(['region', 'chr', 'start', 'end', 'midpoint',])\n",
    "    \n",
    "    for _i,_info in region_info.items():\n",
    "        csvwriter.writerow([_i, \n",
    "                            _info['chr'], \n",
    "                            _info['start'],\n",
    "                            _info['end'],\n",
    "                            _info['mid'],\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
