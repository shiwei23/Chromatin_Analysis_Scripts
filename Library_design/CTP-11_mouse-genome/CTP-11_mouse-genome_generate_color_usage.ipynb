{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create reference files for adding adaptors and analysis\n",
    "\n",
    "for library CTP-10 Aire (209 gene)\n",
    "\n",
    "by Pu Zheng\n",
    "\n",
    "2021.06.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14140\n"
     ]
    }
   ],
   "source": [
    "%run \"..\\Startup_py3.py\"\n",
    "sys.path.append(r\"..\\..\\..\\Documents\")\n",
    "\n",
    "import ImageAnalysis3 as ia\n",
    "%matplotlib notebook\n",
    "\n",
    "from ImageAnalysis3 import *\n",
    "print(os.getpid())\n",
    "\n",
    "# other required parameters\n",
    "from ImageAnalysis3.classes import _allowed_kwds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_folder = r'\\\\10.245.74.212\\Chromatin_NAS_2\\Chromatin_Libraries\\CTP-11_brain'\n",
    "library_folder = os.path.join(pool_folder, r'mouse_genome_1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_filename = os.path.join(pool_folder, 'final_pool_probes.fasta')\n",
    "if not os.path.isfile(probe_filename):\n",
    "    raise IOError(f\"input probe file: {probe_filename} doesn't exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biopython imports\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "from Bio.Blast import NCBIXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_records = []\n",
    "with open(probe_filename, 'r') as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        pb_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loc_1:3740000-3760000_gene_1_pb_23_pos_2742_strand_-_readouts_[NDB_856_c,NDB_946_c,NDB_935_c]_primers_[W1A03_primer_2,W1A10_primer_9]_library_1000-mouse-genome_500_library_1000-mouse-genome_500'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb_records[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1000-mouse-genome_500', '1000-mouse-genome_250_1', '1000-mouse-genome_250_2', '1000-mouse-genome-short_500', '1000-mouse-genome-short_250_1', '1000-mouse-genome-short_250_2']\n"
     ]
    }
   ],
   "source": [
    "# extract library names\n",
    "lib_names = []\n",
    "lib_splitter = 'library'\n",
    "for _r in pb_records:\n",
    "    _lib_name = _r.id.split('_'+lib_splitter+'_')[-1]\n",
    "    if _lib_name not in lib_names:\n",
    "        lib_names.append(_lib_name)\n",
    "print(lib_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a library\n",
    "lib_id = 0\n",
    "# select lib type\n",
    "lib_type = 'combo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract library probes\n",
    "lib_records_dict = {_n:[] for _n in lib_names}\n",
    "for _r in pb_records:\n",
    "    _lib_name = _r.id.split('_'+lib_splitter+'_')[-1]\n",
    "    if _lib_name == lib_names[lib_id]:\n",
    "        lib_records_dict[_lib_name].append(_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    }
   ],
   "source": [
    "from ImageAnalysis3 import library_tools\n",
    "pb_dict = library_tools.quality_check.split_probe_by_gene(lib_records_dict[lib_names[lib_id]])\n",
    "print(len(pb_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout_usage_file = os.path.join(library_folder, 'readout_usage.pkl')\n",
    "readout_dict = pickle.load(open(readout_usage_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_readout_names = [_r.id for _r in readout_dict[_allowed_kwds[lib_type]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save adaptor_sequences.csv for adding adaptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout_folder = r'\\\\10.245.74.212\\Chromatin_NAS_2\\Chromatin_Libraries\\Readouts'\n",
    "ref_files = [_fl for _fl in os.listdir(readout_folder) if 'designed_readouts' in _fl]\n",
    "\n",
    "ref_readout_dict = {}\n",
    "for _fl in ref_files:\n",
    "    _channel = int(_fl.split('designed_readouts_')[1].split('.fasta')[0])\n",
    "    _ref_readout_names = []\n",
    "    with open(os.path.join(readout_folder, _fl), 'r') as _rd_handle:\n",
    "        for _readout in SeqIO.parse(_rd_handle, \"fasta\"):\n",
    "            _ref_readout_names.append(_readout.id)\n",
    "    ref_readout_dict[_channel] = _ref_readout_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort regions with readout types\n",
    "readout_by_channel = {_c:[] for _c in ref_readout_dict}\n",
    "for _rd in readout_dict[_allowed_kwds[lib_type]]:\n",
    "    for _c in readout_by_channel:\n",
    "        if _rd.id in ref_readout_dict[_c]:\n",
    "            readout_by_channel[_c].append(_rd.id)\n",
    "readout_by_channel = {_k:_v for _k,_v in sorted(readout_by_channel.items(), key=lambda v:-int(v[0])) if len(_v) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{750: ['NDB_784',\n",
       "  'NDB_826',\n",
       "  'NDB_865',\n",
       "  'NDB_817',\n",
       "  'NDB_652',\n",
       "  'NDB_718',\n",
       "  'NDB_847',\n",
       "  'NDB_643',\n",
       "  'NDB_760',\n",
       "  'NDB_790',\n",
       "  'NDB_778',\n",
       "  'NDB_844',\n",
       "  'NDB_961',\n",
       "  'NDB_661',\n",
       "  'NDB_901',\n",
       "  'NDB_868',\n",
       "  'NDB_1027',\n",
       "  'NDB_754',\n",
       "  'NDB_856',\n",
       "  'NDB_634',\n",
       "  'NDB_715',\n",
       "  'NDB_883',\n",
       "  'NDB_1033',\n",
       "  'NDB_631',\n",
       "  'NDB_1075',\n",
       "  'NDB_1060',\n",
       "  'NDB_805',\n",
       "  'NDB_730',\n",
       "  'NDB_880',\n",
       "  'NDB_832',\n",
       "  'NDB_835',\n",
       "  'NDB_946',\n",
       "  'NDB_721',\n",
       "  'NDB_853',\n",
       "  'NDB_838',\n",
       "  'NDB_994',\n",
       "  'NDB_1066',\n",
       "  'NDB_637',\n",
       "  'NDB_706',\n",
       "  'NDB_889',\n",
       "  'NDB_862',\n",
       "  'NDB_694',\n",
       "  'NDB_751',\n",
       "  'NDB_742',\n",
       "  'NDB_958',\n",
       "  'NDB_925',\n",
       "  'NDB_712',\n",
       "  'NDB_940',\n",
       "  'NDB_934',\n",
       "  'NDB_910'],\n",
       " 647: ['NDB_755',\n",
       "  'NDB_713',\n",
       "  'NDB_725',\n",
       "  'NDB_710',\n",
       "  'NDB_971',\n",
       "  'NDB_743',\n",
       "  'NDB_683',\n",
       "  'NDB_815',\n",
       "  'NDB_965',\n",
       "  'NDB_917',\n",
       "  'NDB_728',\n",
       "  'NDB_974',\n",
       "  'NDB_746',\n",
       "  'NDB_875',\n",
       "  'NDB_773',\n",
       "  'NDB_812',\n",
       "  'NDB_716',\n",
       "  'NDB_860',\n",
       "  'NDB_680',\n",
       "  'NDB_737',\n",
       "  'NDB_698',\n",
       "  'NDB_863',\n",
       "  'NDB_878',\n",
       "  'NDB_758',\n",
       "  'NDB_653',\n",
       "  'NDB_905',\n",
       "  'NDB_866',\n",
       "  'NDB_887',\n",
       "  'NDB_752',\n",
       "  'NDB_896',\n",
       "  'NDB_989',\n",
       "  'NDB_641',\n",
       "  'NDB_899',\n",
       "  'NDB_941',\n",
       "  'NDB_647',\n",
       "  'NDB_881',\n",
       "  'NDB_665',\n",
       "  'NDB_734',\n",
       "  'NDB_935',\n",
       "  'NDB_788',\n",
       "  'NDB_779',\n",
       "  'NDB_977',\n",
       "  'NDB_836',\n",
       "  'NDB_929',\n",
       "  'NDB_1028',\n",
       "  'NDB_824',\n",
       "  'NDB_818',\n",
       "  'NDB_872',\n",
       "  'NDB_926']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readout_by_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "readout_names = {}\n",
    "for _r in pb_records:\n",
    "    _rname = _r.id.split('gene_')[1].split('_')[0]\n",
    "    _rd_names = _r.id.split('readouts_[')[1].split(']')[0].split(',')\n",
    "    if _rname not in readout_names:\n",
    "        readout_names[_rname] = []\n",
    "    for _rd in _rd_names:\n",
    "        if _rd not in readout_names[_rname]:\n",
    "            if '_'+_allowed_kwds[lib_type] not in _rd:\n",
    "                readout_names[_rname].append(_rd)\n",
    "            else:\n",
    "                readout_names[_rname].append(_rd.split('_'+_allowed_kwds[lib_type])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000-mouse-genome_500'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "num_tubes = 25\n",
    "\n",
    "save_folder = os.path.join(pool_folder, 'Summary_tables')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "with open(os.path.join(save_folder, f'{lib_names[lib_id]}_{lib_type}_adaptor_sequences.csv'), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', \n",
    "                           quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    _header = ['group', 'hyb', ]\n",
    "    for _ch in readout_by_channel:\n",
    "        _header += [f\"{_ch}_bits\", f\"{_ch}_readouts\"]\n",
    "        \n",
    "    csvwriter.writerow(_header)\n",
    "    \n",
    "    for _i in range(max([len(_v) for _k,_v in readout_by_channel.items()])):\n",
    "        _row = [int((_i)/num_tubes)+1, _i%num_tubes+1,] \n",
    "        for _j, (_ch, _names) in enumerate(readout_by_channel.items()):\n",
    "            if _i >= len(_names):\n",
    "                _row += ['', '']\n",
    "            else:\n",
    "                _row += [f\"b{_i*len(readout_by_channel)+_j}\", _names[_i]]      \n",
    "        csvwriter.writerow(_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 3 fasta files\n",
      "- loading from file: \\\\10.245.74.212\\Chromatin_NAS_2\\Chromatin_Libraries\\Adaptors\\NDB_adaptors.fasta\n",
      "- loading from file: \\\\10.245.74.212\\Chromatin_NAS_2\\Chromatin_Libraries\\Adaptors\\Stv_adaptors.fasta\n",
      "- loading from file: \\\\10.245.74.212\\Chromatin_NAS_2\\Chromatin_Libraries\\Adaptors\\20200121_extend_stv_adaptors.fasta\n"
     ]
    }
   ],
   "source": [
    "# find adaptors\n",
    "reload(library_tools.sequences)\n",
    "#library_tools.sequences.fasta_reader()\n",
    "\n",
    "adaptor_folder = r'\\\\10.245.74.212\\Chromatin_NAS_2\\Chromatin_Libraries\\Adaptors'\n",
    "adaptor_files = [os.path.join(adaptor_folder, _fl) for _fl in os.listdir(adaptor_folder) \n",
    "                 if _fl.split(os.extsep)[-1]=='fasta' and _fl.split(os.extsep)[-2][-9:] == '_adaptors']\n",
    "adaptors = library_tools.sequences.fasta_reader(adaptor_files, True).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find used adaptors and generate IDT batch order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "selected_adaptors = {}\n",
    "\n",
    "for _ch, _rnames in readout_by_channel.items():\n",
    "    selected_adaptors[_ch] = []\n",
    "    for _rname in _rnames:\n",
    "        _matched_adaptors = [_adt for _adt in adaptors if _rname in _adt.id]\n",
    "        if len(_matched_adaptors) == 1:\n",
    "            _matched_adaptor = copy(_matched_adaptors[0])\n",
    "            _matched_adaptor.id = _matched_adaptor.id+'rc'\n",
    "            _matched_adaptor.description = \"\"\n",
    "\n",
    "            selected_adaptors[_ch].append(_matched_adaptor)\n",
    "        else:\n",
    "            print(_rname)\n",
    "            \n",
    "readout_usage_folder = os.path.dirname(readout_usage_file)\n",
    "# generate csv file to order in IDT\n",
    "import csv\n",
    "\n",
    "with open(os.path.join(save_folder, f'{lib_names[lib_id]}_{lib_type}_adaptor_idt_order_tubes.csv'), 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', lineterminator='\\n',\n",
    "                       quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    # write header\n",
    "    _header = ['Name', 'Sequence', 'Scale', 'Purification']\n",
    "    csvwriter.writerow(_header)\n",
    "    # write sequence\n",
    "    for _ch, _adaptors in selected_adaptors.items():\n",
    "        for _adaptor in _adaptors:\n",
    "            _info = [_adaptor.id, str(_adaptor.seq), '25nm', 'STD']\n",
    "            csvwriter.writerow(_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Color_Usage.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hyb', '750', '647', '488', '405']\n",
      "['H0C1', 'c0', 'c1', 'beads', 'DAPI']\n",
      "['H1C2', 'c2', 'c3', 'beads']\n",
      "['H2C3', 'c4', 'c5', 'beads']\n",
      "['H3C4', 'c6', 'c7', 'beads']\n",
      "['H4C5', 'c8', 'c9', 'beads']\n",
      "['H5C6', 'c10', 'c11', 'beads']\n",
      "['H6C7', 'c12', 'c13', 'beads']\n",
      "['H7C8', 'c14', 'c15', 'beads']\n",
      "['H8C9', 'c16', 'c17', 'beads']\n",
      "['H9C10', 'c18', 'c19', 'beads']\n",
      "['H10C11', 'c20', 'c21', 'beads']\n",
      "['H11C12', 'c22', 'c23', 'beads']\n",
      "['H12C13', 'c24', 'c25', 'beads']\n",
      "['H13C14', 'c26', 'c27', 'beads']\n",
      "['H14C15', 'c28', 'c29', 'beads']\n",
      "['H15C16', 'c30', 'c31', 'beads']\n",
      "['H16C17', 'c32', 'c33', 'beads']\n",
      "['H17C18', 'c34', 'c35', 'beads']\n",
      "['H18C19', 'c36', 'c37', 'beads']\n",
      "['H19C20', 'c38', 'c39', 'beads']\n",
      "['H20C21', 'c40', 'c41', 'beads']\n",
      "['H21C22', 'c42', 'c43', 'beads']\n",
      "['H22C23', 'c44', 'c45', 'beads']\n",
      "['H23C24', 'c46', 'c47', 'beads']\n",
      "['H24C25', 'c48', 'c49', 'beads']\n",
      "['H25C26', 'c50', 'c51', 'beads']\n",
      "['H26C27', 'c52', 'c53', 'beads']\n",
      "['H27C28', 'c54', 'c55', 'beads']\n",
      "['H28C29', 'c56', 'c57', 'beads']\n",
      "['H29C30', 'c58', 'c59', 'beads']\n",
      "['H30C31', 'c60', 'c61', 'beads']\n",
      "['H31C32', 'c62', 'c63', 'beads']\n",
      "['H32C33', 'c64', 'c65', 'beads']\n",
      "['H33C34', 'c66', 'c67', 'beads']\n",
      "['H34C35', 'c68', 'c69', 'beads']\n",
      "['H35C36', 'c70', 'c71', 'beads']\n",
      "['H36C37', 'c72', 'c73', 'beads']\n",
      "['H37C38', 'c74', 'c75', 'beads']\n",
      "['H38C39', 'c76', 'c77', 'beads']\n",
      "['H39C40', 'c78', 'c79', 'beads']\n",
      "['H40C41', 'c80', 'c81', 'beads']\n",
      "['H41C42', 'c82', 'c83', 'beads']\n",
      "['H42C43', 'c84', 'c85', 'beads']\n",
      "['H43C44', 'c86', 'c87', 'beads']\n",
      "['H44C45', 'c88', 'c89', 'beads']\n",
      "['H45C46', 'c90', 'c91', 'beads']\n",
      "['H46C47', 'c92', 'c93', 'beads']\n",
      "['H47C48', 'c94', 'c95', 'beads']\n",
      "['H48C49', 'c96', 'c97', 'beads']\n",
      "['H49C50', 'c98', '', 'beads']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "drift_channel = '488'\n",
    "dapi_channel = '405'\n",
    "ref_hyb = 0\n",
    "\n",
    "chrom_labels = {}\n",
    "\n",
    "with open(os.path.join(save_folder, f'{lib_names[lib_id]}_{lib_type}_Color_Usage.csv'), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', \n",
    "                           quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    # write header\n",
    "    _header = ['Hyb']\n",
    "    for _ch in readout_by_channel:\n",
    "        _header .append(str(_ch))\n",
    "    _header.append(drift_channel)\n",
    "    _header.append(dapi_channel)\n",
    "    print(_header)\n",
    "    csvwriter.writerow(_header)\n",
    "    \n",
    "    # write reference frame\n",
    "    if len(chrom_labels) > 0:\n",
    "        _ref_row = ['H0R0']\n",
    "        for _ch in readout_by_channel:\n",
    "            if str(_ch) in chrom_labels:\n",
    "                _ref_row.append(chrom_labels[str(_ch)]+'_chrom')\n",
    "            else:\n",
    "                _ref_row.append(\"\")\n",
    "        _ref_row.append('beads')\n",
    "        _ref_row.append('DAPI')\n",
    "        print(_ref_row)\n",
    "        csvwriter.writerow(_ref_row)\n",
    "    \n",
    "    \n",
    "    for _i in range(max([len(_v) for _k,_v in readout_by_channel.items()])):\n",
    "        _row = [f\"H{int(_i)}C{int(_i)+1}\",] \n",
    "        for _j, (_ch, _names) in enumerate(readout_by_channel.items()):\n",
    "            if _i >= len(_names):\n",
    "                _row += ['']\n",
    "            else:\n",
    "                _row += [f\"{_allowed_kwds[lib_type]}{_i*len(readout_by_channel)+_j}\"]\n",
    "            \n",
    "        _row.append(\"beads\")\n",
    "        # append for ref\n",
    "        if _i == ref_hyb:\n",
    "            _row.append('DAPI')\n",
    "        #\n",
    "        print(_row)\n",
    "        csvwriter.writerow(_row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save region_positions for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'region_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-96cbb72cd1e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcsvwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'region'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'chr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'start'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'midpoint'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0m_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_info\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mregion_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         csvwriter.writerow([_i, \n\u001b[0;32m     11\u001b[0m                             \u001b[0m_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'chr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'region_info' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(os.path.join(save_folder, f'{lib_names[lib_id]}_{lib_type}_Region_Positions.csv'), 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',', \n",
    "                           quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    # write header\n",
    "    csvwriter.writerow(['region', 'chr', 'start', 'end', 'midpoint',])\n",
    "    \n",
    "    for _i,_info in region_info.items():\n",
    "        csvwriter.writerow([_i, \n",
    "                            _info['chr'], \n",
    "                            _info['start'],\n",
    "                            _info['end'],\n",
    "                            _info['mid'],\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loc_1:3740000-3760000_gene_1_pb_23_pos_2742_strand_-_readouts_[NDB_856_c,NDB_946_c,NDB_935_c]_primers_[W1A03_primer_2,W1A10_primer_9]_library_1000-mouse-genome_500_library_1000-mouse-genome_500'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb_records[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_position_df = pd.DataFrame(columns=['id', 'region', 'chr', 'start', 'end', 'strand']).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, region, chr, start, end, strand]\n",
       "Index: []"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_record = pb_records[0]\n",
    "if 'res_' in _record.id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id region  chr start  end strand\n",
       "0  test    NaN  NaN   NaN  NaN    NaN"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_position_df.append({'id':'test'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>region</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, region, chr, start, end, strand]\n",
       "Index: []"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_position_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _r in pb_records:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>strand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [region, chr, start, end, strand]\n",
       "Index: []"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_position_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
