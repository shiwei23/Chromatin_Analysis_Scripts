{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Library design for CTP02, \n",
    "\n",
    "## PCDH 10kb DNA library, - strand\n",
    "by Pu Zheng\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#minimum imports:\n",
    "import time,os,sys,glob\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import khmer\n",
    "sys.path.append(r'/n/home13/pzheng/Documents/python-functions/python-functions-library')\n",
    "\n",
    "from LibraryConstruction import fastaread,fastawrite,fastacombine\n",
    "import LibraryDesigner as ld\n",
    "import LibraryConstruction as lc\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.SeqRecord import SeqRecord "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load previously designed probes, generate pb_records and pb_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file: /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-02/PCDH_10kb-/PCDH_10kb_minus.csv\n",
      "-- Save pb_lists\n",
      "-- Save pb_records\n"
     ]
    }
   ],
   "source": [
    "# dir\n",
    "master_dir = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-02/PCDH_10kb-';\n",
    "# input filename\n",
    "pb_filename = 'PCDH_10kb_minus.csv';\n",
    "\n",
    "pb_records, gene_pb_dic = [],{}; # initialize\n",
    "\n",
    "import csv\n",
    "with open(master_dir+os.sep+pb_filename,'rU') as handle:\n",
    "    print \"read file:\", master_dir+os.sep+pb_filename\n",
    "    _csvreader = csv.reader(handle, delimiter=',') # reader\n",
    "    # check if has header\n",
    "    _has_header = csv.Sniffer().has_header(handle.readline())\n",
    "    handle.seek(0)  # Rewind.\n",
    "    if _has_header:\n",
    "        next(_csvreader)  # Skip header row.\n",
    "    for row in _csvreader:\n",
    "        _name = row[0];\n",
    "        _seq = row[1].upper()\n",
    "        pb_records.append(SeqRecord(Seq(_seq,alphabet=IUPAC.unambiguous_dna),id=_name, name=_name,description=''))\n",
    "        \n",
    "        # if DNA\n",
    "        gene_id = int(_name.split('reg_')[1].split(\"_\")[0])\n",
    "        # if RNA\n",
    "        #gene_id = _name.split('gene_')[1].split(\"_\")[0]\n",
    "        \n",
    "        pb_info = {'reg_index':gene_id, 'total_seq':_seq, 'total_name':_name};\n",
    "        if gene_id not in gene_pb_dic.keys():\n",
    "            gene_pb_dic[gene_id] = [pb_info];\n",
    "        else:\n",
    "            gene_pb_dic[gene_id].append(pb_info);\n",
    "# define pb_lists, match format\n",
    "pb_lists = gene_pb_dic.values()\n",
    "\n",
    "# save\n",
    "save_dir = 'final_probes'\n",
    "if not os.path.exists(master_dir+os.sep+save_dir):\n",
    "    os.makedirs(master_dir+os.sep+save_dir)\n",
    "print \"-- Save pb_lists\"\n",
    "pickle.dump(pb_lists, open(master_dir+os.sep+save_dir+os.sep+'list.pkl', 'w'));\n",
    "print \"-- Save pb_records\"\n",
    "with open(master_dir+os.sep+save_dir+os.sep+'candidate_probes.fasta', \"w\") as output_handle:\n",
    "    SeqIO.write(pb_records, output_handle, 'fasta');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read barcode Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barcodes loaded: Stv: 201, NDB: 1052\n"
     ]
    }
   ],
   "source": [
    "# read all Stv barcodes\n",
    "barcode_dir = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Barcodes';\n",
    "\n",
    "#stv_adaptor = [1,2,17,62,77,78,79,80,81,82,83,84] # barcodes saved for adaptors\n",
    "#stv_bad = [34,38,41] # barcodes performed badly\n",
    "#stv_mask = stv_adaptor + stv_bad \n",
    "stv_mask = []\n",
    "\n",
    "with open(barcode_dir+os.sep+'Stvs.fasta', \"rU\") as handle:\n",
    "    stv_barcodes = [];\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        if int(record.id.split('_')[1]) not in stv_mask:\n",
    "            stv_barcodes.append(record);\n",
    "\n",
    "# read all NDB barcodes\n",
    "ndb_mask = [];\n",
    "\n",
    "with open(barcode_dir+os.sep+'NDBs.fasta', \"rU\") as handle:\n",
    "    ndb_barcodes = [];\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        if int(record.id.split('_')[1]) not in ndb_mask:\n",
    "            ndb_barcodes.append(record);\n",
    "print \"Barcodes loaded: Stv: \"+str(len(stv_barcodes))+\", NDB: \"+str(len(ndb_barcodes));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PCR primers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primers loaded: forward: 12, reverse: 9\n",
      "- forward primer: ID: W1A07_primer_6\n",
      "Name: W1A07_primer_6\n",
      "Description: W1A07_primer_6\n",
      "Number of features: 0\n",
      "Seq('CGCAAACTGGTGCGGAAGGC', SingleLetterAlphabet())\n",
      "- reverse primer: ID: W1A12_primer_11\n",
      "Name: W1A12_primer_11\n",
      "Description: W1A12_primer_11\n",
      "Number of features: 0\n",
      "Seq('TAATACGACTCACTATAGGGCCATTGCCCGCGAGGTCGAG', SingleLetterAlphabet())\n"
     ]
    }
   ],
   "source": [
    "primer_dir = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Primers';\n",
    "fwd_primer_filename = 'forward_primers_keep.fasta';\n",
    "rev_primer_filename = 'reverse_primers_keep.fasta';\n",
    "\n",
    "# read all forward primers\n",
    "with open(primer_dir+os.sep+fwd_primer_filename, \"rU\") as handle:\n",
    "    fwd_primers = [];\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        fwd_primers.append(record);\n",
    "# read all forward primers\n",
    "with open(primer_dir+os.sep+rev_primer_filename, \"rU\") as handle:\n",
    "    rev_primers = [];\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        rev_primers.append(record);\n",
    "print \"Primers loaded: forward: \"+str(len(fwd_primers))+\", reverse: \"+str(len(rev_primers));    \n",
    "\n",
    "# primers\n",
    "fprimer = fwd_primers[3];\n",
    "print '- forward primer:', fprimer\n",
    "rprimer = rev_primers[5];\n",
    "print '- reverse primer:', rprimer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Check_Probes(pb_records, pb_lists, master_dir, \n",
    "                 fwd_primer,rev_primer,\n",
    "                 stv_barcodes, ndb_barcodes,\n",
    "                 RNA=False,RNA_padding=6,\n",
    "                 add_rand_gap=0, total_bc=3, barcode_len=20, \n",
    "                 target_len=42, word_size=17, \n",
    "                 max_internal_hits=5, max_genome_hits=200,\n",
    "                 index_folder=r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Indeces/human/hg38',\n",
    "                 save_dir=r'final_probes', save=True, verbose=True):\n",
    "    '''Functions to check probe quality\n",
    "    Inputs:\n",
    "        pb_records: probe information in biopython format, list of SeqRecords\n",
    "        pb_lists: list of lists of probe information dictionary, list of list\n",
    "        master_dir: directory of this sub library, string\n",
    "        fwd_primer: forward primer in biopython format, SeqRecord\n",
    "        rev_primer: reverse primer in biopython format, SeqRecord\n",
    "        stv_barcodes: stv_barcodes in biopython format, list of SeqRecord\n",
    "        ndb_barcodes: ndb_barcodes in biopython format, list of SeqRecord\n",
    "        (optional)\n",
    "        RNA: whether this library is for RNA or not, bool(false)\n",
    "        add_rand_gap: number of random bases between barcodes, int(0)\n",
    "        total_bc: number of barcodes per probe, int(3)\n",
    "        barcode_len: length of barcode binding site on probe, int(20)\n",
    "        target_len: length of targeting region on probe, int(42)\n",
    "        word_size: word size for indeces and for probe designer, int(17)\n",
    "        max_internal_hit: maximal internal k-mer allowed, int(5)\n",
    "        max_genome_hits: maximal genome k-mer allowed, int(200)\n",
    "        index_folder: full directory to indeces, string\n",
    "        save_dir: sub directory for saving, under master_dir, string\n",
    "        save: whether save, bool(True)\n",
    "        verbose: say something during checking probes, bool(True)\n",
    "    Output:\n",
    "        kept_records: all seq records that passed filter\n",
    "        _size_from_rec: size of each region/gene, dic\n",
    "        '''\n",
    "    # imports\n",
    "    import os,glob,sys\n",
    "    sys.path.append(r'/n/home13/pzheng/Documents/python-functions/python-functions-library')\n",
    "    from LibraryConstruction import fastaread,fastawrite,fastacombine\n",
    "    import LibraryDesigner as ld\n",
    "    import numpy as np\n",
    "    \n",
    "    def _check_primer_usage(pb_records=pb_records, fwd_primer=fwd_primer, rev_primer=rev_primer,\n",
    "                            _RNA=RNA, _RNA_padding=RNA_padding,\n",
    "                            _verbose=verbose):\n",
    "        '''Check whether forward or reverse primer are used in all probes'''\n",
    "        if _verbose:\n",
    "            print \"-- Checking primer usage, total probes:\", len(pb_records)\n",
    "        fwd_len = len(fwd_primer.seq);\n",
    "        rev_len = len(rev_primer.seq[-20:].reverse_complement());\n",
    "        \n",
    "        for record in pb_records:\n",
    "            if _RNA:\n",
    "                fp = record.seq[_RNA_padding : _RNA_padding+fwd_len];\n",
    "                rp = record.seq[-rev_len-_RNA_padding: -RNA_padding];\n",
    "            else:\n",
    "                fp = record.seq[:fwd_len].upper();\n",
    "                rp = record.seq[-rev_len:]\n",
    "            # checking\n",
    "            if fp != fwd_primer.seq:\n",
    "                if _verbose:\n",
    "                    print \"--- Forward primer incorrect in\", record\n",
    "                return False\n",
    "            if rp != rev_primer.seq[-20:].reverse_complement():\n",
    "                if _verbose:\n",
    "                    print \"--- Forward primer incorrect in\", record\n",
    "                return False\n",
    "        return True # if no error applies\n",
    "    \n",
    "    def _check_region_size(pb_records, pb_lists=pb_lists, _RNA=RNA):\n",
    "        '''Generate a dirctionary '''\n",
    "        # get original region size\n",
    "        _reg_size_dic = {}\n",
    "        for lst in pb_lists:\n",
    "            _reg_size_dic[lst[0]['reg_index']] = len(lst);\n",
    "        # get region size from probe names\n",
    "        _size_from_rec = {}\n",
    "        for record in pb_records:\n",
    "            if _RNA:\n",
    "                reg_id = record.id.split('gene_')[1].split('_')[0];\n",
    "            else:\n",
    "                reg_id = int(record.id.split('reg_')[1].split('_')[0]);\n",
    "            if reg_id not in _size_from_rec.keys():\n",
    "                _size_from_rec[reg_id] = 1; # if not in key, create\n",
    "            else:\n",
    "                _size_from_rec[reg_id] += 1; # otherwise, add count\n",
    "        # compare\n",
    "        _match = True;\n",
    "        for k,v in sorted(_size_from_rec.items()):\n",
    "            if k not in _reg_size_dic.keys():\n",
    "                print \"region list and region id in probes not match for\", k\n",
    "                _match = False\n",
    "                break\n",
    "            else:\n",
    "                if v != _reg_size_dic[k]:\n",
    "                    print \"region size doesn't match for:\", k\n",
    "                    _match = False\n",
    "                    break\n",
    "    \n",
    "        return _reg_size_dic, _match;\n",
    "    \n",
    "\n",
    "    def _check_region_to_barcode(pb_records=pb_records, stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes,\n",
    "                                 total_bc=total_bc, _RNA=RNA):\n",
    "        '''Generate map from region id to barcodes used in this region'''\n",
    "        import re\n",
    "        _reg_to_barcode = {}\n",
    "        for record in pb_records:\n",
    "            # region id\n",
    "            if _RNA:\n",
    "                reg_id = record.id.split('gene_')[1].split('_')[0];\n",
    "            else:\n",
    "                reg_id = int(record.id.split('reg_')[1].split('_')[0]);\n",
    "            # put reg_id into reg_to_barcode dic\n",
    "            if reg_id not in _reg_to_barcode.keys():\n",
    "                # barcode ids\n",
    "                stv_matches = re.findall('\\'STV_(.+?)\\'', record.id.upper(), re.DOTALL)\n",
    "                ndb_matches = re.findall('\\'NDB_(.+?)\\'', record.id.upper(), re.DOTALL)\n",
    "                stv_names = ['Stv_'+str(stv_id) for stv_id in stv_matches]\n",
    "                ndb_names = ['NDB_'+str(ndb_id) for ndb_id in ndb_matches]\n",
    "                _reg_to_barcode[reg_id] = stv_names+ndb_names\n",
    "        \n",
    "        ## barcode check\n",
    "        _barcode_check = True;\n",
    "        # barcode names\n",
    "        bc_names = [stv.id.upper() for stv in stv_barcodes] + [ndb.id.upper() for ndb in ndb_barcodes]\n",
    "        # search through previous dictionary\n",
    "        for reg,bcs in sorted(_reg_to_barcode.items()):\n",
    "            for bc in bcs:\n",
    "                if bc.upper() not in bc_names:\n",
    "                    print \"-- Wrong barcode name for barcode: \"+str(bc)+\", region: \"+str(reg)\n",
    "                    print bc\n",
    "                    _barcode_check = False\n",
    "                    break\n",
    "        \n",
    "        return _reg_to_barcode, _barcode_check;\n",
    "        \n",
    "    def _parsing_probe_sequence(record, fwd_primer=fwd_primer, rev_primer=rev_primer,\n",
    "                                add_rand_gap=add_rand_gap, barcode_len=barcode_len, target_len=target_len,\n",
    "                                _RNA=RNA, _RNA_padding=RNA_padding):\n",
    "        '''parse a probe sequence to acquire all barcode binding sites'''\n",
    "        # take in a seq record, parse the sequence and return a list of all included barcodes (20mer,RC)\n",
    "        barcode_list = [];\n",
    "        if RNA:\n",
    "            _main_seq = record.seq[_RNA_padding+len(fwd_primer.seq):-20-_RNA_padding];\n",
    "        else:\n",
    "            _main_seq = record.seq[len(fwd_primer.seq):-20];\n",
    "        \n",
    "        \n",
    "        # trim first 2 barcodes\n",
    "        for i in range(2):\n",
    "            barcode_list.append(_main_seq[:barcode_len]);\n",
    "            _main_seq = _main_seq[(barcode_len+add_rand_gap):];\n",
    "        # trim all barcodes from the end\n",
    "        while len(_main_seq) > target_len:\n",
    "            barcode_list.append(_main_seq[-barcode_len:]);\n",
    "            _main_seq = _main_seq[:-(barcode_len+add_rand_gap)];\n",
    "        \n",
    "        return barcode_list;\n",
    "    \n",
    "    def _finding_barcode_name(barcode_list, stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes, \n",
    "                              barcode_len=barcode_len, total_bc=total_bc):\n",
    "        '''Given barcode list generated by parsing probe, return a list of barcode names'''\n",
    "        _name_list = [];\n",
    "        for bc_site in barcode_list:\n",
    "            for bc in stv_barcodes+ndb_barcodes:\n",
    "                if bc.seq[-barcode_len:] == bc_site.reverse_complement():\n",
    "                    _name_list.append(bc.id);\n",
    "                    break;\n",
    "        \n",
    "        if len(_name_list) < total_bc:\n",
    "            print \"-- Failed in finding some barcodes.\"\n",
    "            print barcode_list, _name_list\n",
    "        return _name_list;\n",
    "    \n",
    "    \n",
    "    def _check_barcode_to_region(reg_to_barcode, \n",
    "                                 pb_records=pb_records, stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes, _RNA=RNA):\n",
    "        '''Generate map from barcode id to region id'''\n",
    "        _barcode_to_reg = {}\n",
    "        _reg_id_exists = []\n",
    "        for record in pb_records:\n",
    "            # region id\n",
    "            if _RNA:\n",
    "                reg_id = record.id.split('gene_')[1].split('_')[0];\n",
    "            else:\n",
    "                reg_id = int(record.id.split('reg_')[1].split('_')[0]);\n",
    "\n",
    "            if reg_id in _reg_id_exists:\n",
    "                continue;\n",
    "            else:\n",
    "                _barcode_list = _parsing_probe_sequence(record)\n",
    "                _name_list = _finding_barcode_name(_barcode_list)\n",
    "                for _n in _name_list:\n",
    "                    if _n not in _barcode_to_reg.keys(): # create if not in dic\n",
    "                        _barcode_to_reg[_n] = [reg_id]\n",
    "                    else: # otherwise, append\n",
    "                        _barcode_to_reg[_n].append(reg_id)\n",
    "            _reg_id_exists.append(reg_id)\n",
    "        ## check region distribution\n",
    "        # invert dic from reg_to_barcode\n",
    "        _inv_dic = {}\n",
    "        for reg,bcs in sorted(reg_to_barcode.items()):\n",
    "            for bc in bcs:\n",
    "                if bc not in _inv_dic.keys():\n",
    "                    _inv_dic[bc] = [reg];\n",
    "                else:\n",
    "                    _inv_dic[bc].append(reg);\n",
    "        # compare\n",
    "        _region_check=True\n",
    "        for bc, regs in sorted(_inv_dic.items()):\n",
    "            if bc not in _barcode_to_reg.keys():\n",
    "                print \"-- \"+str(bc)+\" not in barcode_to_region dic!\"\n",
    "                print '---',bc\n",
    "                _region_check = False\n",
    "                break\n",
    "            else:\n",
    "                for reg in regs:\n",
    "                    if reg not in _barcode_to_reg[bc]:\n",
    "                        print \"-- some barcode in \"+str(regs)+\" not compatible with \"+str(bc)+\" in barcode_to_region dic!\"\n",
    "                        _region_check = False\n",
    "                        break\n",
    "                for reg in _barcode_to_reg[bc]:\n",
    "                    if reg not in regs:\n",
    "                        print \"-- some barcode in \"+str(bc)+\" not compatible with \"+str(regs)+\" in barcode_to_region dic!\"\n",
    "                        _region_check = False\n",
    "                        break\n",
    "                    \n",
    "        return _barcode_to_reg, _region_check\n",
    "    \n",
    "    def _check_barcode_to_color(pb_records=pb_records, stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes, \n",
    "                                stv_color=True, ndb_color=False,\n",
    "                                _save=save, master_dir=master_dir, save_dir=save_dir):\n",
    "        '''If multi_color is applied, generate a barcode_to_color dic for adaptor design'''\n",
    "        if 'color' not in str(pb_records[0].id):\n",
    "            print \"-- color check not applied\";\n",
    "            return False\n",
    "        elif not stv_color and not ndb_color:\n",
    "            print \"-- color check turned off in both stv and ndb\";\n",
    "            return False\n",
    "        else:\n",
    "            # get barcodes\n",
    "            _barcode_names = []\n",
    "            if stv_color: # if stv has multi-color\n",
    "                _barcode_names += [bc.id for bc in stv_barcodes];\n",
    "            if ndb_color: # if ndb has multi-color\n",
    "                _barcode_names += [bc.id for bc in ndb_barcodes];\n",
    "            # initialize color dic\n",
    "            _barcode_to_color = {};\n",
    "            _exist_regs = [];\n",
    "            # search through all probes\n",
    "            for record in pb_records:\n",
    "                # reg_id\n",
    "                if _RNA:\n",
    "                    reg_id = record.id.split('gene_')[1].split('_')[0];\n",
    "                else:\n",
    "                    reg_id = int(record.id.split('reg_')[1].split('_')[0]);\n",
    "                \n",
    "                if _reg_id in _exist_regs:\n",
    "                    continue\n",
    "                else: \n",
    "                    _exist_regs.append(_reg_id);\n",
    "                _color = int(str(record.id).split('color_')[1])\n",
    "                _barcode_list = _parsing_probe_sequence(record)\n",
    "                _name_list = _finding_barcode_name(_barcode_list)\n",
    "                \n",
    "                for _name in _name_list:\n",
    "                    if _name in _barcode_names:\n",
    "                        if _name not in _barcode_to_color.keys():\n",
    "                            _barcode_to_color[_name] = [_color]\n",
    "                        else:\n",
    "                            _barcode_to_color[_name].append(_color);\n",
    "            # keep the unique colors\n",
    "            _barcode_to_unique_color = {}\n",
    "            for k,v in sorted(_barcode_to_color.items()):\n",
    "                _barcode_to_unique_color[k] = np.unique(v)\n",
    "            if _save:\n",
    "                import csv\n",
    "                # mkdir if not exist for this region\n",
    "                if not os.path.exists(master_dir+os.sep+save_dir):\n",
    "                    os.makedirs(master_dir+os.sep+save_dir)\n",
    "                with open(master_dir+os.sep+save_dir+os.sep+'color-usage.csv','w') as output_handle:\n",
    "                    fieldnames = ['barcode', 'color']\n",
    "                    writer = csv.DictWriter(output_handle, fieldnames=fieldnames)\n",
    "                    writer.writeheader()\n",
    "                    for _barcode, _color in sorted(_barcode_to_unique_color.items(), key=lambda (k,v):int(k.split('_')[1])):\n",
    "                        writer.writerow({'barcode': _barcode, 'color': _color})\n",
    "                \n",
    "        return _barcode_to_unique_color\n",
    "                            \n",
    "    \n",
    "    def _construct_internal_map(master_dir=master_dir, save_dir=save_dir, word_size=word_size):\n",
    "        '''Using functions in LibraryDesign, compute an internal khmer map'''\n",
    "        _int_map = khmer.Countgraph(word_size, 1e9, 2) \n",
    "        _int_map.set_use_bigcount(True)\n",
    "        _nms,_seqs = fastaread(master_dir+os.sep+save_dir+os.sep+'candidate_probes.fasta')\n",
    "        for _seq in _seqs:\n",
    "            _int_map.consume(_seq.upper())\n",
    "        return _int_map\n",
    "    \n",
    "    def _check_barcode_in_probes(barcode_to_reg, reg_size_dic, int_map, \n",
    "                                 stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes,\n",
    "                                 barcode_len=barcode_len, max_internal_hits=max_internal_hits):\n",
    "        '''Check barcode appearance in probes, whether that match barcode_to_region scheme'''\n",
    "        _barcode_in_probes = {}\n",
    "        for bc_name, regs in sorted(barcode_to_reg.items()):\n",
    "            bc = None\n",
    "            for _bc in stv_barcodes+ndb_barcodes:\n",
    "                if bc_name == _bc.id:\n",
    "                    bc = _bc\n",
    "                    break\n",
    "            bc_hits = int_map.get_kmer_counts( str(bc.seq[-barcode_len:].reverse_complement()).upper());\n",
    "            if max(bc_hits) - min(bc_hits) > max_internal_hits:\n",
    "                print \"-- Barcode: \"+str(bc)+\" has more off-target in different part of itself!\"\n",
    "                return False\n",
    "            else:\n",
    "                regs,reg_cts = np.unique(regs, return_counts=True);\n",
    "                bc_in_probe = 0;\n",
    "                for reg,ct in zip(regs,reg_cts):\n",
    "                    bc_in_probe += reg_size_dic[reg] * ct;\n",
    "                if max(bc_hits) - bc_in_probe > max_internal_hits:\n",
    "                    print \"-- Barcode: \"+str(bc)+\" has more off-target than threshold!\"\n",
    "                    return False\n",
    "            _barcode_in_probes[bc_name] = bc_in_probe;\n",
    "        return _barcode_in_probes, True\n",
    "    \n",
    "    def _check_between_probes(int_map, pb_lists=pb_lists, pb_records=pb_records):\n",
    "        pass \n",
    "    \n",
    "    def _check_against_genome(pb_records=pb_records, max_genome_hits=max_genome_hits, index_folder=index_folder):\n",
    "        '''Use Khmer to compare probe against genome'''\n",
    "        hg38 = khmer.load_countgraph(index_folder+os.sep+'full_word17_.kmer')\n",
    "        _failed_num = 0;\n",
    "        _keep_pb_records = [];\n",
    "        for record in pb_records:\n",
    "            _kmer_hits = hg38.get_kmer_counts(str(record.seq).upper());\n",
    "            if sum(_kmer_hits) > max_genome_hits:\n",
    "                print '-- Max_genome_hits is: '+str(max_genome_hits)+\", this seq got hits: \"+ str(sum(_kmer_hits))\n",
    "                _failed_num += 1;\n",
    "            else:\n",
    "                _keep_pb_records.append(record);\n",
    "                \n",
    "        return _keep_pb_records, _failed_num # if nothing goes wrong\n",
    "    \n",
    "    def _plot_info():\n",
    "        pass\n",
    "            \n",
    "    ## check primers\n",
    "    primer_usage = _check_primer_usage()\n",
    "    if verbose:\n",
    "        print \"\\n- 1.Passing primer usage check? -\", primer_usage\n",
    "    \n",
    "    ## check region size\n",
    "    reg_size_dic, size_match = _check_region_size(pb_records)\n",
    "    if verbose:\n",
    "        print \"\\n- 2.Passing region size check? -\", size_match    \n",
    "        for k,v in sorted(reg_size_dic.items()):\n",
    "            print k,':',v\n",
    "        \n",
    "    ## check region to barcode\n",
    "    reg_to_barcode, reg2bc = _check_region_to_barcode()\n",
    "    if verbose:\n",
    "        print \"\\n- 3.Passing region to barcode mapping check? -\", reg2bc    \n",
    "        for k,v in sorted(reg_to_barcode.items(), key=lambda (k,v):k):\n",
    "            print k,':',v\n",
    "        \n",
    "    ## check barcode to region (this step must be run after step 3) \n",
    "    barcode_to_reg, bc2reg = _check_barcode_to_region(reg_to_barcode)\n",
    "    if verbose:\n",
    "        print \"\\n- 4.Passing barcode to region mapping check? -\", bc2reg    \n",
    "        for k,v in sorted(barcode_to_reg.items(), key=lambda (k,v):[k[0],int(k.split('_')[1])]):\n",
    "            print k,':',v\n",
    "    \n",
    "    ## check barcode to region (this step must be run after step 3) \n",
    "    barcode_to_color = _check_barcode_to_color()\n",
    "    if verbose and barcode_to_color:\n",
    "        print \"\\n- 5.Calculating barcode to color dictionary.\"\n",
    "        for k,v in sorted(barcode_to_color.items(), key=lambda (k,v):[k[0],int(k.split('_')[1])]):\n",
    "            print k,':',v    \n",
    "    \n",
    "    \n",
    "    ## Construct an internal map\n",
    "    int_map = _construct_internal_map();\n",
    "    if verbose:\n",
    "        print \"\\n- 6.Constructing internal khmer map\";\n",
    "    \n",
    "    ## Check barcodes total counts in probes\n",
    "    barcode_in_probes, _bc_counting = _check_barcode_in_probes(barcode_to_reg, reg_size_dic, int_map)\n",
    "    if verbose:\n",
    "        print \"\\n- 7.Passing if counting barcode appearance times in probes\", _bc_counting;    \n",
    "\n",
    "    ## Check against each other    \n",
    "    \n",
    "    ## Check against genome\n",
    "    kept_records, failed_num = _check_against_genome();\n",
    "    if verbose:\n",
    "        print \"\\n- 8.Probes not passing through genome filter:\", failed_num;  \n",
    "    \n",
    "    # check region size for kept probes\n",
    "    kept_size_dic, kept_match = _check_region_size(kept_records);\n",
    "    if verbose:\n",
    "        print \"\\n- 9.Re-check region size:\"\n",
    "        for k,v in sorted(kept_size_dic.items()):\n",
    "            print k,':',v\n",
    "        print \"--- total number of probes:\", len(kept_records);\n",
    "        \n",
    "    if save:\n",
    "        pb_savefile = master_dir + os.sep + save_dir + os.sep + 'filtered_probes.fasta';\n",
    "        if verbose:\n",
    "            print \"\\n- 10.Saving probes to:\", pb_savefile\n",
    "        with open(pb_savefile, 'w') as output_handle:\n",
    "            SeqIO.write(kept_records, output_handle, 'fasta');  \n",
    "        \n",
    "    return kept_records, kept_size_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Checking primer usage, total probes: 7543\n",
      "\n",
      "- 1.Passing primer usage check? - True\n",
      "\n",
      "- 2.Passing region size check? - True\n",
      "1 : 16\n",
      "2 : 23\n",
      "3 : 26\n",
      "4 : 53\n",
      "5 : 46\n",
      "6 : 47\n",
      "7 : 56\n",
      "8 : 59\n",
      "9 : 17\n",
      "10 : 40\n",
      "11 : 46\n",
      "12 : 49\n",
      "13 : 45\n",
      "14 : 37\n",
      "15 : 50\n",
      "16 : 53\n",
      "17 : 42\n",
      "18 : 56\n",
      "19 : 51\n",
      "20 : 50\n",
      "21 : 47\n",
      "22 : 54\n",
      "23 : 60\n",
      "24 : 31\n",
      "25 : 35\n",
      "26 : 9\n",
      "27 : 11\n",
      "28 : 8\n",
      "29 : 8\n",
      "30 : 20\n",
      "31 : 38\n",
      "32 : 69\n",
      "33 : 45\n",
      "34 : 27\n",
      "35 : 38\n",
      "36 : 21\n",
      "37 : 23\n",
      "38 : 21\n",
      "39 : 54\n",
      "40 : 71\n",
      "41 : 50\n",
      "42 : 63\n",
      "43 : 54\n",
      "44 : 55\n",
      "45 : 56\n",
      "46 : 50\n",
      "47 : 55\n",
      "48 : 42\n",
      "49 : 60\n",
      "50 : 42\n",
      "51 : 29\n",
      "52 : 47\n",
      "53 : 30\n",
      "54 : 55\n",
      "55 : 45\n",
      "56 : 36\n",
      "57 : 68\n",
      "58 : 29\n",
      "59 : 41\n",
      "60 : 28\n",
      "61 : 34\n",
      "62 : 42\n",
      "63 : 40\n",
      "64 : 60\n",
      "65 : 48\n",
      "66 : 46\n",
      "67 : 43\n",
      "68 : 42\n",
      "69 : 9\n",
      "70 : 25\n",
      "71 : 47\n",
      "72 : 37\n",
      "73 : 29\n",
      "74 : 43\n",
      "75 : 31\n",
      "76 : 38\n",
      "77 : 45\n",
      "78 : 43\n",
      "79 : 37\n",
      "80 : 53\n",
      "81 : 50\n",
      "82 : 50\n",
      "83 : 47\n",
      "84 : 43\n",
      "85 : 40\n",
      "86 : 53\n",
      "87 : 30\n",
      "88 : 54\n",
      "89 : 44\n",
      "90 : 42\n",
      "91 : 56\n",
      "92 : 30\n",
      "93 : 49\n",
      "94 : 48\n",
      "95 : 49\n",
      "96 : 54\n",
      "97 : 56\n",
      "98 : 31\n",
      "99 : 44\n",
      "100 : 49\n",
      "101 : 50\n",
      "102 : 56\n",
      "103 : 40\n",
      "104 : 41\n",
      "105 : 60\n",
      "106 : 38\n",
      "107 : 54\n",
      "108 : 34\n",
      "109 : 41\n",
      "110 : 47\n",
      "111 : 47\n",
      "112 : 54\n",
      "113 : 54\n",
      "114 : 46\n",
      "115 : 59\n",
      "116 : 40\n",
      "117 : 60\n",
      "118 : 64\n",
      "119 : 65\n",
      "120 : 52\n",
      "121 : 69\n",
      "122 : 42\n",
      "123 : 58\n",
      "124 : 63\n",
      "125 : 54\n",
      "126 : 57\n",
      "127 : 52\n",
      "128 : 57\n",
      "129 : 52\n",
      "130 : 59\n",
      "131 : 60\n",
      "132 : 61\n",
      "133 : 49\n",
      "134 : 47\n",
      "135 : 53\n",
      "136 : 32\n",
      "137 : 25\n",
      "138 : 14\n",
      "139 : 21\n",
      "140 : 14\n",
      "141 : 35\n",
      "142 : 69\n",
      "143 : 43\n",
      "144 : 77\n",
      "145 : 72\n",
      "146 : 44\n",
      "147 : 42\n",
      "148 : 57\n",
      "149 : 65\n",
      "150 : 63\n",
      "151 : 61\n",
      "152 : 58\n",
      "153 : 46\n",
      "154 : 20\n",
      "155 : 20\n",
      "156 : 31\n",
      "157 : 26\n",
      "158 : 58\n",
      "159 : 65\n",
      "160 : 49\n",
      "161 : 51\n",
      "162 : 59\n",
      "163 : 55\n",
      "164 : 57\n",
      "165 : 46\n",
      "166 : 35\n",
      "167 : 48\n",
      "168 : 52\n",
      "\n",
      "- 3.Passing region to barcode mapping check? - True\n",
      "1 : ['Stv_4']\n",
      "2 : ['Stv_4']\n",
      "3 : ['Stv_5']\n",
      "4 : ['Stv_5']\n",
      "5 : ['Stv_6']\n",
      "6 : ['Stv_6']\n",
      "7 : ['Stv_7']\n",
      "8 : ['Stv_7']\n",
      "9 : ['Stv_8']\n",
      "10 : ['Stv_8']\n",
      "11 : ['Stv_9']\n",
      "12 : ['Stv_9']\n",
      "13 : ['Stv_10']\n",
      "14 : ['Stv_10']\n",
      "15 : ['Stv_11']\n",
      "16 : ['Stv_11']\n",
      "17 : ['Stv_12']\n",
      "18 : ['Stv_12']\n",
      "19 : ['Stv_13']\n",
      "20 : ['Stv_13']\n",
      "21 : ['Stv_14']\n",
      "22 : ['Stv_14']\n",
      "23 : ['Stv_15']\n",
      "24 : ['Stv_15']\n",
      "25 : ['Stv_16']\n",
      "26 : ['Stv_16']\n",
      "27 : ['Stv_18']\n",
      "28 : ['Stv_18']\n",
      "29 : ['Stv_19']\n",
      "30 : ['Stv_19']\n",
      "31 : ['Stv_20']\n",
      "32 : ['Stv_20']\n",
      "33 : ['Stv_21']\n",
      "34 : ['Stv_21']\n",
      "35 : ['Stv_22']\n",
      "36 : ['Stv_22']\n",
      "37 : ['Stv_23']\n",
      "38 : ['Stv_23']\n",
      "39 : ['Stv_24']\n",
      "40 : ['Stv_24']\n",
      "41 : ['Stv_25']\n",
      "42 : ['Stv_25']\n",
      "43 : ['Stv_26']\n",
      "44 : ['Stv_26']\n",
      "45 : ['Stv_27']\n",
      "46 : ['Stv_27']\n",
      "47 : ['Stv_28']\n",
      "48 : ['Stv_28']\n",
      "49 : ['Stv_29']\n",
      "50 : ['Stv_29']\n",
      "51 : ['Stv_30']\n",
      "52 : ['Stv_30']\n",
      "53 : ['Stv_31']\n",
      "54 : ['Stv_31']\n",
      "55 : ['Stv_32']\n",
      "56 : ['Stv_32']\n",
      "57 : ['Stv_33']\n",
      "58 : ['Stv_33']\n",
      "59 : ['Stv_35']\n",
      "60 : ['Stv_35']\n",
      "61 : ['Stv_36']\n",
      "62 : ['Stv_36']\n",
      "63 : ['Stv_37']\n",
      "64 : ['Stv_37']\n",
      "65 : ['Stv_39']\n",
      "66 : ['Stv_39']\n",
      "67 : ['Stv_40']\n",
      "68 : ['Stv_40']\n",
      "69 : ['Stv_42']\n",
      "70 : ['Stv_42']\n",
      "71 : ['Stv_44']\n",
      "72 : ['Stv_44']\n",
      "73 : ['Stv_45']\n",
      "74 : ['Stv_45']\n",
      "75 : ['Stv_46']\n",
      "76 : ['Stv_46']\n",
      "77 : ['Stv_47']\n",
      "78 : ['Stv_47']\n",
      "79 : ['Stv_48']\n",
      "80 : ['Stv_48']\n",
      "81 : ['Stv_50']\n",
      "82 : ['Stv_50']\n",
      "83 : ['Stv_52']\n",
      "84 : ['Stv_52']\n",
      "85 : ['Stv_53']\n",
      "86 : ['Stv_53']\n",
      "87 : ['Stv_54']\n",
      "88 : ['Stv_54']\n",
      "89 : ['Stv_59']\n",
      "90 : ['Stv_59']\n",
      "91 : ['Stv_60']\n",
      "92 : ['Stv_60']\n",
      "93 : ['Stv_61']\n",
      "94 : ['Stv_61']\n",
      "95 : ['Stv_63']\n",
      "96 : ['Stv_63']\n",
      "97 : ['Stv_64']\n",
      "98 : ['Stv_64']\n",
      "99 : ['Stv_65']\n",
      "100 : ['Stv_65']\n",
      "101 : ['Stv_70']\n",
      "102 : ['Stv_70']\n",
      "103 : ['Stv_74']\n",
      "104 : ['Stv_74']\n",
      "105 : ['Stv_77']\n",
      "106 : ['Stv_77']\n",
      "107 : ['Stv_86']\n",
      "108 : ['Stv_86']\n",
      "109 : ['Stv_87']\n",
      "110 : ['Stv_87']\n",
      "111 : ['Stv_88']\n",
      "112 : ['Stv_88']\n",
      "113 : ['Stv_90']\n",
      "114 : ['Stv_90']\n",
      "115 : ['Stv_91']\n",
      "116 : ['Stv_91']\n",
      "117 : ['Stv_94']\n",
      "118 : ['Stv_94']\n",
      "119 : ['Stv_95']\n",
      "120 : ['Stv_95']\n",
      "121 : ['Stv_99']\n",
      "122 : ['Stv_99']\n",
      "123 : ['Stv_100']\n",
      "124 : ['Stv_100']\n",
      "125 : ['Stv_102']\n",
      "126 : ['Stv_102']\n",
      "127 : ['Stv_104']\n",
      "128 : ['Stv_104']\n",
      "129 : ['Stv_105']\n",
      "130 : ['Stv_105']\n",
      "131 : ['Stv_107']\n",
      "132 : ['Stv_107']\n",
      "133 : ['Stv_109']\n",
      "134 : ['Stv_109']\n",
      "135 : ['Stv_111']\n",
      "136 : ['Stv_111']\n",
      "137 : ['Stv_118']\n",
      "138 : ['Stv_118']\n",
      "139 : ['Stv_119']\n",
      "140 : ['Stv_119']\n",
      "141 : ['Stv_120']\n",
      "142 : ['Stv_120']\n",
      "143 : ['Stv_121']\n",
      "144 : ['Stv_121']\n",
      "145 : ['Stv_124']\n",
      "146 : ['Stv_124']\n",
      "147 : ['Stv_125']\n",
      "148 : ['Stv_125']\n",
      "149 : ['Stv_127']\n",
      "150 : ['Stv_127']\n",
      "151 : ['Stv_129']\n",
      "152 : ['Stv_129']\n",
      "153 : ['Stv_130']\n",
      "154 : ['Stv_130']\n",
      "155 : ['Stv_131']\n",
      "156 : ['Stv_131']\n",
      "157 : ['Stv_133']\n",
      "158 : ['Stv_133']\n",
      "159 : ['Stv_136']\n",
      "160 : ['Stv_136']\n",
      "161 : ['Stv_140']\n",
      "162 : ['Stv_140']\n",
      "163 : ['Stv_142']\n",
      "164 : ['Stv_142']\n",
      "165 : ['Stv_146']\n",
      "166 : ['Stv_146']\n",
      "167 : ['Stv_182']\n",
      "168 : ['Stv_182']\n",
      "\n",
      "- 4.Passing barcode to region mapping check? - True\n",
      "Stv_4 : [1, 1, 1, 2, 2, 2]\n",
      "Stv_5 : [3, 3, 3, 4, 4, 4]\n",
      "Stv_6 : [5, 5, 5, 6, 6, 6]\n",
      "Stv_7 : [7, 7, 7, 8, 8, 8]\n",
      "Stv_8 : [9, 9, 9, 10, 10, 10]\n",
      "Stv_9 : [11, 11, 11, 12, 12, 12]\n",
      "Stv_10 : [13, 13, 13, 14, 14, 14]\n",
      "Stv_11 : [15, 15, 15, 16, 16, 16]\n",
      "Stv_12 : [17, 17, 17, 18, 18, 18]\n",
      "Stv_13 : [19, 19, 19, 20, 20, 20]\n",
      "Stv_14 : [21, 21, 21, 22, 22, 22]\n",
      "Stv_15 : [23, 23, 23, 24, 24, 24]\n",
      "Stv_16 : [25, 25, 25, 26, 26, 26]\n",
      "Stv_18 : [27, 27, 27, 28, 28, 28]\n",
      "Stv_19 : [29, 29, 29, 30, 30, 30]\n",
      "Stv_20 : [31, 31, 31, 32, 32, 32]\n",
      "Stv_21 : [33, 33, 33, 34, 34, 34]\n",
      "Stv_22 : [35, 35, 35, 36, 36, 36]\n",
      "Stv_23 : [37, 37, 37, 38, 38, 38]\n",
      "Stv_24 : [39, 39, 39, 40, 40, 40]\n",
      "Stv_25 : [41, 41, 41, 42, 42, 42]\n",
      "Stv_26 : [43, 43, 43, 44, 44, 44]\n",
      "Stv_27 : [45, 45, 45, 46, 46, 46]\n",
      "Stv_28 : [47, 47, 47, 48, 48, 48]\n",
      "Stv_29 : [49, 49, 49, 50, 50, 50]\n",
      "Stv_30 : [51, 51, 51, 52, 52, 52]\n",
      "Stv_31 : [53, 53, 53, 54, 54, 54]\n",
      "Stv_32 : [55, 55, 55, 56, 56, 56]\n",
      "Stv_33 : [57, 57, 57, 58, 58, 58]\n",
      "Stv_35 : [59, 59, 59, 60, 60, 60]\n",
      "Stv_36 : [61, 61, 61, 62, 62, 62]\n",
      "Stv_37 : [63, 63, 63, 64, 64, 64]\n",
      "Stv_39 : [65, 65, 65, 66, 66, 66]\n",
      "Stv_40 : [67, 67, 67, 68, 68, 68]\n",
      "Stv_42 : [69, 69, 69, 70, 70, 70]\n",
      "Stv_44 : [71, 71, 71, 72, 72, 72]\n",
      "Stv_45 : [73, 73, 73, 74, 74, 74]\n",
      "Stv_46 : [75, 75, 75, 76, 76, 76]\n",
      "Stv_47 : [77, 77, 77, 78, 78, 78]\n",
      "Stv_48 : [79, 79, 79, 80, 80, 80]\n",
      "Stv_50 : [81, 81, 81, 82, 82, 82]\n",
      "Stv_52 : [83, 83, 83, 84, 84, 84]\n",
      "Stv_53 : [85, 85, 85, 86, 86, 86]\n",
      "Stv_54 : [87, 87, 87, 88, 88, 88]\n",
      "Stv_59 : [89, 89, 89, 90, 90, 90]\n",
      "Stv_60 : [91, 91, 91, 92, 92, 92]\n",
      "Stv_61 : [93, 93, 93, 94, 94, 94]\n",
      "Stv_63 : [95, 95, 95, 96, 96, 96]\n",
      "Stv_64 : [97, 97, 97, 98, 98, 98]\n",
      "Stv_65 : [99, 99, 99, 100, 100, 100]\n",
      "Stv_70 : [101, 101, 101, 102, 102, 102]\n",
      "Stv_74 : [103, 103, 103, 104, 104, 104]\n",
      "Stv_77 : [105, 105, 105, 106, 106, 106]\n",
      "Stv_86 : [107, 107, 107, 108, 108, 108]\n",
      "Stv_87 : [109, 109, 109, 110, 110, 110]\n",
      "Stv_88 : [111, 111, 111, 112, 112, 112]\n",
      "Stv_90 : [113, 113, 113, 114, 114, 114]\n",
      "Stv_91 : [115, 115, 115, 116, 116, 116]\n",
      "Stv_94 : [117, 117, 117, 118, 118, 118]\n",
      "Stv_95 : [119, 119, 119, 120, 120, 120]\n",
      "Stv_99 : [121, 121, 121, 122, 122, 122]\n",
      "Stv_100 : [123, 123, 123, 124, 124, 124]\n",
      "Stv_102 : [125, 125, 125, 126, 126, 126]\n",
      "Stv_104 : [127, 127, 127, 128, 128, 128]\n",
      "Stv_105 : [129, 129, 129, 130, 130, 130]\n",
      "Stv_107 : [131, 131, 131, 132, 132, 132]\n",
      "Stv_109 : [133, 133, 133, 134, 134, 134]\n",
      "Stv_111 : [135, 135, 135, 136, 136, 136]\n",
      "Stv_118 : [137, 137, 137, 138, 138, 138]\n",
      "Stv_119 : [139, 139, 139, 140, 140, 140]\n",
      "Stv_120 : [141, 141, 141, 142, 142, 142]\n",
      "Stv_121 : [143, 143, 143, 144, 144, 144]\n",
      "Stv_124 : [145, 145, 145, 146, 146, 146]\n",
      "Stv_125 : [147, 147, 147, 148, 148, 148]\n",
      "Stv_127 : [149, 149, 149, 150, 150, 150]\n",
      "Stv_129 : [151, 151, 151, 152, 152, 152]\n",
      "Stv_130 : [153, 153, 153, 154, 154, 154]\n",
      "Stv_131 : [155, 155, 155, 156, 156, 156]\n",
      "Stv_133 : [157, 157, 157, 158, 158, 158]\n",
      "Stv_136 : [159, 159, 159, 160, 160, 160]\n",
      "Stv_140 : [161, 161, 161, 162, 162, 162]\n",
      "Stv_142 : [163, 163, 163, 164, 164, 164]\n",
      "Stv_146 : [165, 165, 165, 166, 166, 166]\n",
      "Stv_182 : [167, 167, 167, 168, 168, 168]\n",
      "-- color check not applied\n",
      "\n",
      "- 6.Constructing internal khmer map\n",
      "\n",
      "- 7.Passing if counting barcode appearance times in probes True\n",
      "-- Max_genome_hits is: 200, this seq got hits: 232\n",
      "-- Max_genome_hits is: 200, this seq got hits: 233\n",
      "-- Max_genome_hits is: 200, this seq got hits: 467\n",
      "-- Max_genome_hits is: 200, this seq got hits: 716\n",
      "-- Max_genome_hits is: 200, this seq got hits: 256\n",
      "-- Max_genome_hits is: 200, this seq got hits: 438\n",
      "-- Max_genome_hits is: 200, this seq got hits: 1731\n",
      "-- Max_genome_hits is: 200, this seq got hits: 237\n",
      "-- Max_genome_hits is: 200, this seq got hits: 250\n",
      "-- Max_genome_hits is: 200, this seq got hits: 220\n",
      "-- Max_genome_hits is: 200, this seq got hits: 248\n",
      "-- Max_genome_hits is: 200, this seq got hits: 224\n",
      "-- Max_genome_hits is: 200, this seq got hits: 232\n",
      "-- Max_genome_hits is: 200, this seq got hits: 202\n",
      "-- Max_genome_hits is: 200, this seq got hits: 325\n",
      "-- Max_genome_hits is: 200, this seq got hits: 202\n",
      "-- Max_genome_hits is: 200, this seq got hits: 211\n",
      "-- Max_genome_hits is: 200, this seq got hits: 202\n",
      "-- Max_genome_hits is: 200, this seq got hits: 1443\n",
      "-- Max_genome_hits is: 200, this seq got hits: 418\n",
      "-- Max_genome_hits is: 200, this seq got hits: 280\n",
      "-- Max_genome_hits is: 200, this seq got hits: 230\n",
      "-- Max_genome_hits is: 200, this seq got hits: 226\n",
      "-- Max_genome_hits is: 200, this seq got hits: 330\n",
      "-- Max_genome_hits is: 200, this seq got hits: 249\n",
      "-- Max_genome_hits is: 200, this seq got hits: 647\n",
      "-- Max_genome_hits is: 200, this seq got hits: 2273\n",
      "-- Max_genome_hits is: 200, this seq got hits: 633\n",
      "-- Max_genome_hits is: 200, this seq got hits: 247\n",
      "-- Max_genome_hits is: 200, this seq got hits: 1159\n",
      "-- Max_genome_hits is: 200, this seq got hits: 254\n",
      "-- Max_genome_hits is: 200, this seq got hits: 265\n",
      "-- Max_genome_hits is: 200, this seq got hits: 203\n",
      "-- Max_genome_hits is: 200, this seq got hits: 235\n",
      "-- Max_genome_hits is: 200, this seq got hits: 335\n",
      "-- Max_genome_hits is: 200, this seq got hits: 210\n",
      "-- Max_genome_hits is: 200, this seq got hits: 276\n",
      "-- Max_genome_hits is: 200, this seq got hits: 212\n",
      "-- Max_genome_hits is: 200, this seq got hits: 214\n",
      "-- Max_genome_hits is: 200, this seq got hits: 207\n",
      "-- Max_genome_hits is: 200, this seq got hits: 205\n",
      "-- Max_genome_hits is: 200, this seq got hits: 204\n",
      "-- Max_genome_hits is: 200, this seq got hits: 285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Max_genome_hits is: 200, this seq got hits: 352\n",
      "-- Max_genome_hits is: 200, this seq got hits: 231\n",
      "-- Max_genome_hits is: 200, this seq got hits: 294\n",
      "-- Max_genome_hits is: 200, this seq got hits: 596\n",
      "-- Max_genome_hits is: 200, this seq got hits: 733\n",
      "-- Max_genome_hits is: 200, this seq got hits: 236\n",
      "-- Max_genome_hits is: 200, this seq got hits: 867\n",
      "-- Max_genome_hits is: 200, this seq got hits: 370\n",
      "-- Max_genome_hits is: 200, this seq got hits: 214\n",
      "-- Max_genome_hits is: 200, this seq got hits: 205\n",
      "-- Max_genome_hits is: 200, this seq got hits: 231\n",
      "-- Max_genome_hits is: 200, this seq got hits: 202\n",
      "-- Max_genome_hits is: 200, this seq got hits: 769\n",
      "-- Max_genome_hits is: 200, this seq got hits: 499\n",
      "-- Max_genome_hits is: 200, this seq got hits: 374\n",
      "-- Max_genome_hits is: 200, this seq got hits: 595\n",
      "-- Max_genome_hits is: 200, this seq got hits: 234\n",
      "-- Max_genome_hits is: 200, this seq got hits: 253\n",
      "-- Max_genome_hits is: 200, this seq got hits: 271\n",
      "-- Max_genome_hits is: 200, this seq got hits: 220\n",
      "-- Max_genome_hits is: 200, this seq got hits: 1729\n",
      "-- Max_genome_hits is: 200, this seq got hits: 1077\n",
      "-- Max_genome_hits is: 200, this seq got hits: 385\n",
      "-- Max_genome_hits is: 200, this seq got hits: 220\n",
      "-- Max_genome_hits is: 200, this seq got hits: 306\n",
      "-- Max_genome_hits is: 200, this seq got hits: 349\n",
      "\n",
      "- 8.Probes not passing through genome filter: 69\n",
      "region size doesn't match for: 2\n",
      "\n",
      "- 9.Re-check region size:\n",
      "1 : 16\n",
      "2 : 23\n",
      "3 : 26\n",
      "4 : 53\n",
      "5 : 46\n",
      "6 : 47\n",
      "7 : 56\n",
      "8 : 59\n",
      "9 : 17\n",
      "10 : 40\n",
      "11 : 46\n",
      "12 : 49\n",
      "13 : 45\n",
      "14 : 37\n",
      "15 : 50\n",
      "16 : 53\n",
      "17 : 42\n",
      "18 : 56\n",
      "19 : 51\n",
      "20 : 50\n",
      "21 : 47\n",
      "22 : 54\n",
      "23 : 60\n",
      "24 : 31\n",
      "25 : 35\n",
      "26 : 9\n",
      "27 : 11\n",
      "28 : 8\n",
      "29 : 8\n",
      "30 : 20\n",
      "31 : 38\n",
      "32 : 69\n",
      "33 : 45\n",
      "34 : 27\n",
      "35 : 38\n",
      "36 : 21\n",
      "37 : 23\n",
      "38 : 21\n",
      "39 : 54\n",
      "40 : 71\n",
      "41 : 50\n",
      "42 : 63\n",
      "43 : 54\n",
      "44 : 55\n",
      "45 : 56\n",
      "46 : 50\n",
      "47 : 55\n",
      "48 : 42\n",
      "49 : 60\n",
      "50 : 42\n",
      "51 : 29\n",
      "52 : 47\n",
      "53 : 30\n",
      "54 : 55\n",
      "55 : 45\n",
      "56 : 36\n",
      "57 : 68\n",
      "58 : 29\n",
      "59 : 41\n",
      "60 : 28\n",
      "61 : 34\n",
      "62 : 42\n",
      "63 : 40\n",
      "64 : 60\n",
      "65 : 48\n",
      "66 : 46\n",
      "67 : 43\n",
      "68 : 42\n",
      "69 : 9\n",
      "70 : 25\n",
      "71 : 47\n",
      "72 : 37\n",
      "73 : 29\n",
      "74 : 43\n",
      "75 : 31\n",
      "76 : 38\n",
      "77 : 45\n",
      "78 : 43\n",
      "79 : 37\n",
      "80 : 53\n",
      "81 : 50\n",
      "82 : 50\n",
      "83 : 47\n",
      "84 : 43\n",
      "85 : 40\n",
      "86 : 53\n",
      "87 : 30\n",
      "88 : 54\n",
      "89 : 44\n",
      "90 : 42\n",
      "91 : 56\n",
      "92 : 30\n",
      "93 : 49\n",
      "94 : 48\n",
      "95 : 49\n",
      "96 : 54\n",
      "97 : 56\n",
      "98 : 31\n",
      "99 : 44\n",
      "100 : 49\n",
      "101 : 50\n",
      "102 : 56\n",
      "103 : 40\n",
      "104 : 41\n",
      "105 : 60\n",
      "106 : 38\n",
      "107 : 54\n",
      "108 : 34\n",
      "109 : 41\n",
      "110 : 47\n",
      "111 : 47\n",
      "112 : 54\n",
      "113 : 54\n",
      "114 : 46\n",
      "115 : 59\n",
      "116 : 40\n",
      "117 : 60\n",
      "118 : 64\n",
      "119 : 65\n",
      "120 : 52\n",
      "121 : 69\n",
      "122 : 42\n",
      "123 : 58\n",
      "124 : 63\n",
      "125 : 54\n",
      "126 : 57\n",
      "127 : 52\n",
      "128 : 57\n",
      "129 : 52\n",
      "130 : 59\n",
      "131 : 60\n",
      "132 : 61\n",
      "133 : 49\n",
      "134 : 47\n",
      "135 : 53\n",
      "136 : 32\n",
      "137 : 25\n",
      "138 : 14\n",
      "139 : 21\n",
      "140 : 14\n",
      "141 : 35\n",
      "142 : 69\n",
      "143 : 43\n",
      "144 : 77\n",
      "145 : 72\n",
      "146 : 44\n",
      "147 : 42\n",
      "148 : 57\n",
      "149 : 65\n",
      "150 : 63\n",
      "151 : 61\n",
      "152 : 58\n",
      "153 : 46\n",
      "154 : 20\n",
      "155 : 20\n",
      "156 : 31\n",
      "157 : 26\n",
      "158 : 58\n",
      "159 : 65\n",
      "160 : 49\n",
      "161 : 51\n",
      "162 : 59\n",
      "163 : 55\n",
      "164 : 57\n",
      "165 : 46\n",
      "166 : 35\n",
      "167 : 48\n",
      "168 : 52\n",
      "--- total number of probes: 7474\n",
      "\n",
      "- 10.Saving probes to: /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-02/PCDH_10kb-/final_probes/filtered_probes.fasta\n"
     ]
    }
   ],
   "source": [
    "kept_records, kept_size_dic = Check_Probes(pb_records, pb_lists, master_dir, target_len=42,\n",
    "                                           RNA=False,RNA_padding=0,\n",
    "                                        fwd_primer=fprimer, rev_primer=rprimer,\n",
    "                                        stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
