{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library design for CTP-03, Chr21\n",
    "\n",
    "by Pu Zheng\n",
    "\n",
    "This library design is for human chr21\n",
    "\n",
    "complementary for SI-14 Chr21 small, removing tad barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#minimum imports:\n",
    "import time,os,sys,glob\n",
    "import numpy as np\n",
    "import khmer\n",
    "sys.path.append(r'/n/home13/pzheng/Documents/python-functions/python-functions-library')\n",
    "\n",
    "from LibraryConstruction import fastaread,fastawrite,fastacombine\n",
    "import LibraryDesigner as ld\n",
    "import LibraryConstruction as lc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Post Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 keep 400 probes in the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_101.pbr: 343\n",
      "reg_102.pbr: 399\n",
      "reg_103.pbr: 400\n",
      "reg_121.pbr: 370\n",
      "reg_122.pbr: 400\n",
      "reg_123.pbr: 400\n",
      "reg_130.pbr: 400\n",
      "reg_131.pbr: 257\n",
      "reg_132.pbr: 278\n",
      "reg_156.pbr: 363\n",
      "reg_157.pbr: 281\n",
      "reg_195.pbr: 216\n",
      "reg_196.pbr: 386\n",
      "reg_209.pbr: 215\n",
      "reg_211.pbr: 239\n",
      "reg_213.pbr: 216\n",
      "reg_266.pbr: 221\n",
      "reg_281.pbr: 400\n",
      "reg_282.pbr: 367\n",
      "reg_283.pbr: 400\n",
      "reg_284.pbr: 400\n",
      "reg_285.pbr: 400\n",
      "reg_286.pbr: 400\n",
      "reg_287.pbr: 400\n",
      "reg_288.pbr: 400\n",
      "reg_289.pbr: 334\n",
      "reg_290.pbr: 400\n",
      "reg_291.pbr: 400\n",
      "reg_292.pbr: 400\n",
      "reg_293.pbr: 400\n",
      "reg_294.pbr: 400\n",
      "reg_295.pbr: 400\n",
      "reg_296.pbr: 400\n",
      "reg_297.pbr: 400\n",
      "reg_298.pbr: 400\n",
      "reg_299.pbr: 400\n",
      "reg_300.pbr: 400\n",
      "reg_301.pbr: 400\n",
      "reg_302.pbr: 400\n",
      "reg_303.pbr: 400\n",
      "reg_304.pbr: 400\n",
      "reg_305.pbr: 400\n",
      "reg_306.pbr: 400\n",
      "reg_307.pbr: 400\n",
      "reg_308.pbr: 400\n",
      "reg_309.pbr: 400\n",
      "reg_310.pbr: 400\n",
      "reg_311.pbr: 400\n",
      "reg_312.pbr: 400\n",
      "reg_313.pbr: 400\n",
      "reg_314.pbr: 400\n",
      "reg_315.pbr: 400\n",
      "reg_316.pbr: 400\n",
      "reg_317.pbr: 400\n",
      "reg_318.pbr: 400\n",
      "reg_319.pbr: 395\n",
      "reg_320.pbr: 400\n",
      "reg_321.pbr: 400\n",
      "reg_322.pbr: 400\n",
      "reg_323.pbr: 400\n",
      "reg_324.pbr: 400\n",
      "reg_325.pbr: 400\n",
      "reg_326.pbr: 400\n",
      "reg_327.pbr: 400\n",
      "reg_328.pbr: 400\n",
      "reg_329.pbr: 400\n",
      "reg_330.pbr: 400\n",
      "reg_331.pbr: 400\n",
      "reg_332.pbr: 400\n",
      "reg_333.pbr: 400\n",
      "reg_334.pbr: 400\n",
      "reg_335.pbr: 400\n",
      "reg_336.pbr: 400\n",
      "reg_337.pbr: 400\n",
      "reg_338.pbr: 400\n",
      "reg_339.pbr: 400\n",
      "reg_340.pbr: 400\n",
      "reg_341.pbr: 400\n",
      "reg_342.pbr: 400\n",
      "reg_343.pbr: 400\n",
      "reg_348.pbr: 400\n",
      "reg_349.pbr: 400\n",
      "reg_350.pbr: 400\n",
      "reg_351.pbr: 400\n",
      "reg_352.pbr: 400\n",
      "reg_353.pbr: 283\n",
      "reg_354.pbr: 202\n",
      "reg_355.pbr: 205\n",
      "reg_356.pbr: 400\n",
      "reg_357.pbr: 400\n",
      "reg_358.pbr: 400\n",
      "reg_359.pbr: 400\n",
      "reg_360.pbr: 400\n",
      "reg_361.pbr: 400\n",
      "reg_362.pbr: 400\n",
      "reg_363.pbr: 400\n",
      "reg_364.pbr: 400\n",
      "reg_365.pbr: 400\n",
      "reg_366.pbr: 400\n",
      "reg_367.pbr: 400\n",
      "reg_368.pbr: 400\n",
      "reg_369.pbr: 400\n",
      "reg_370.pbr: 400\n",
      "reg_371.pbr: 400\n",
      "reg_372.pbr: 400\n",
      "reg_373.pbr: 400\n",
      "reg_374.pbr: 400\n",
      "reg_375.pbr: 400\n",
      "reg_376.pbr: 400\n",
      "reg_377.pbr: 400\n",
      "reg_378.pbr: 400\n",
      "reg_379.pbr: 400\n",
      "reg_380.pbr: 400\n",
      "reg_381.pbr: 400\n",
      "reg_382.pbr: 400\n",
      "reg_383.pbr: 400\n",
      "reg_384.pbr: 400\n",
      "reg_385.pbr: 400\n",
      "reg_386.pbr: 400\n",
      "reg_387.pbr: 400\n",
      "reg_388.pbr: 400\n",
      "reg_389.pbr: 400\n",
      "reg_390.pbr: 400\n",
      "reg_391.pbr: 400\n",
      "reg_392.pbr: 400\n",
      "reg_393.pbr: 400\n",
      "reg_394.pbr: 400\n",
      "reg_395.pbr: 400\n",
      "reg_396.pbr: 400\n",
      "reg_397.pbr: 400\n",
      "reg_398.pbr: 400\n",
      "reg_399.pbr: 400\n",
      "reg_400.pbr: 400\n",
      "reg_401.pbr: 400\n",
      "reg_402.pbr: 400\n",
      "reg_403.pbr: 400\n",
      "reg_404.pbr: 400\n",
      "reg_405.pbr: 400\n",
      "reg_406.pbr: 400\n",
      "reg_407.pbr: 400\n",
      "reg_408.pbr: 400\n",
      "reg_409.pbr: 400\n",
      "reg_410.pbr: 400\n",
      "reg_411.pbr: 400\n",
      "reg_412.pbr: 400\n",
      "reg_413.pbr: 400\n",
      "reg_414.pbr: 400\n",
      "reg_415.pbr: 400\n",
      "reg_416.pbr: 400\n",
      "reg_417.pbr: 400\n",
      "reg_418.pbr: 400\n",
      "reg_419.pbr: 400\n",
      "reg_420.pbr: 400\n",
      "reg_421.pbr: 400\n",
      "reg_422.pbr: 400\n",
      "reg_423.pbr: 400\n",
      "reg_424.pbr: 400\n",
      "reg_425.pbr: 400\n",
      "reg_426.pbr: 400\n",
      "reg_427.pbr: 400\n",
      "reg_428.pbr: 400\n",
      "reg_429.pbr: 400\n",
      "reg_430.pbr: 400\n",
      "reg_431.pbr: 400\n",
      "reg_432.pbr: 400\n",
      "reg_433.pbr: 400\n",
      "reg_434.pbr: 400\n",
      "reg_435.pbr: 400\n",
      "reg_436.pbr: 400\n",
      "reg_437.pbr: 400\n",
      "reg_438.pbr: 400\n",
      "reg_439.pbr: 400\n",
      "reg_440.pbr: 400\n",
      "reg_441.pbr: 400\n",
      "reg_442.pbr: 400\n",
      "reg_443.pbr: 268\n",
      "reg_445.pbr: 222\n",
      "reg_446.pbr: 240\n",
      "reg_447.pbr: 400\n",
      "reg_448.pbr: 400\n",
      "reg_449.pbr: 400\n",
      "reg_450.pbr: 400\n",
      "reg_451.pbr: 400\n",
      "reg_452.pbr: 400\n",
      "reg_453.pbr: 400\n",
      "reg_454.pbr: 400\n",
      "reg_455.pbr: 400\n",
      "reg_456.pbr: 400\n",
      "reg_457.pbr: 400\n",
      "reg_458.pbr: 400\n",
      "reg_459.pbr: 400\n",
      "reg_460.pbr: 400\n",
      "reg_461.pbr: 400\n",
      "reg_462.pbr: 400\n",
      "reg_463.pbr: 400\n",
      "reg_464.pbr: 400\n",
      "reg_465.pbr: 400\n",
      "reg_466.pbr: 400\n",
      "reg_467.pbr: 400\n",
      "reg_468.pbr: 400\n",
      "reg_469.pbr: 400\n",
      "reg_470.pbr: 400\n",
      "reg_471.pbr: 400\n",
      "reg_472.pbr: 400\n",
      "reg_473.pbr: 400\n",
      "reg_474.pbr: 400\n",
      "reg_475.pbr: 400\n",
      "reg_476.pbr: 400\n",
      "reg_477.pbr: 400\n",
      "reg_478.pbr: 400\n",
      "reg_479.pbr: 400\n",
      "reg_480.pbr: 400\n",
      "reg_481.pbr: 400\n",
      "reg_482.pbr: 400\n",
      "reg_483.pbr: 400\n",
      "reg_484.pbr: 400\n",
      "reg_485.pbr: 400\n",
      "reg_486.pbr: 400\n",
      "reg_487.pbr: 400\n",
      "reg_488.pbr: 400\n",
      "reg_489.pbr: 400\n",
      "reg_490.pbr: 400\n",
      "reg_491.pbr: 400\n",
      "reg_492.pbr: 400\n",
      "reg_493.pbr: 400\n",
      "reg_494.pbr: 400\n",
      "reg_495.pbr: 400\n",
      "reg_496.pbr: 400\n",
      "reg_497.pbr: 400\n",
      "reg_498.pbr: 400\n",
      "reg_499.pbr: 400\n",
      "reg_500.pbr: 400\n",
      "reg_501.pbr: 400\n",
      "reg_502.pbr: 400\n",
      "reg_503.pbr: 400\n",
      "reg_504.pbr: 400\n",
      "reg_505.pbr: 400\n",
      "reg_506.pbr: 400\n",
      "reg_507.pbr: 400\n",
      "reg_508.pbr: 400\n",
      "reg_509.pbr: 400\n",
      "reg_510.pbr: 400\n",
      "reg_511.pbr: 400\n",
      "reg_512.pbr: 400\n",
      "reg_513.pbr: 400\n",
      "reg_514.pbr: 400\n",
      "reg_515.pbr: 400\n",
      "reg_516.pbr: 400\n",
      "reg_517.pbr: 400\n",
      "reg_518.pbr: 400\n",
      "reg_519.pbr: 400\n",
      "reg_520.pbr: 400\n",
      "reg_521.pbr: 400\n",
      "reg_522.pbr: 400\n",
      "reg_523.pbr: 400\n",
      "reg_524.pbr: 400\n",
      "reg_525.pbr: 400\n",
      "reg_526.pbr: 400\n",
      "reg_527.pbr: 400\n",
      "reg_528.pbr: 400\n",
      "reg_529.pbr: 400\n",
      "reg_530.pbr: 400\n",
      "reg_531.pbr: 400\n",
      "reg_532.pbr: 400\n",
      "reg_533.pbr: 400\n",
      "reg_534.pbr: 400\n",
      "reg_535.pbr: 400\n",
      "reg_536.pbr: 400\n",
      "reg_537.pbr: 400\n",
      "reg_538.pbr: 400\n",
      "reg_539.pbr: 400\n",
      "reg_540.pbr: 400\n",
      "reg_541.pbr: 400\n",
      "reg_542.pbr: 400\n",
      "reg_543.pbr: 400\n",
      "reg_544.pbr: 400\n",
      "reg_545.pbr: 400\n",
      "reg_546.pbr: 400\n",
      "reg_547.pbr: 400\n",
      "reg_548.pbr: 400\n",
      "reg_549.pbr: 400\n",
      "reg_550.pbr: 400\n",
      "reg_551.pbr: 400\n",
      "reg_552.pbr: 400\n",
      "reg_553.pbr: 400\n",
      "reg_554.pbr: 400\n",
      "reg_555.pbr: 400\n",
      "reg_556.pbr: 400\n",
      "reg_557.pbr: 400\n",
      "reg_559.pbr: 216\n",
      "reg_560.pbr: 329\n",
      "reg_561.pbr: 255\n",
      "reg_562.pbr: 400\n",
      "reg_563.pbr: 400\n",
      "reg_564.pbr: 400\n",
      "reg_565.pbr: 400\n",
      "reg_566.pbr: 400\n",
      "reg_567.pbr: 400\n",
      "reg_568.pbr: 400\n",
      "reg_569.pbr: 400\n",
      "reg_570.pbr: 400\n",
      "reg_571.pbr: 400\n",
      "reg_572.pbr: 400\n",
      "reg_573.pbr: 400\n",
      "reg_574.pbr: 400\n",
      "reg_575.pbr: 400\n",
      "reg_576.pbr: 400\n",
      "reg_577.pbr: 400\n",
      "reg_578.pbr: 400\n",
      "reg_579.pbr: 400\n",
      "reg_580.pbr: 400\n",
      "reg_581.pbr: 400\n",
      "reg_582.pbr: 400\n",
      "reg_583.pbr: 400\n",
      "reg_584.pbr: 400\n",
      "reg_585.pbr: 400\n",
      "reg_586.pbr: 400\n",
      "reg_587.pbr: 400\n",
      "reg_588.pbr: 400\n",
      "reg_589.pbr: 400\n",
      "reg_590.pbr: 400\n",
      "reg_591.pbr: 400\n",
      "reg_592.pbr: 400\n",
      "reg_593.pbr: 400\n",
      "reg_594.pbr: 400\n",
      "reg_595.pbr: 400\n",
      "reg_596.pbr: 400\n",
      "reg_597.pbr: 400\n",
      "reg_598.pbr: 400\n",
      "reg_599.pbr: 400\n",
      "reg_600.pbr: 400\n",
      "reg_601.pbr: 400\n",
      "reg_602.pbr: 400\n",
      "reg_603.pbr: 400\n",
      "reg_604.pbr: 400\n",
      "reg_605.pbr: 400\n",
      "reg_606.pbr: 400\n",
      "reg_607.pbr: 400\n",
      "reg_608.pbr: 400\n",
      "reg_609.pbr: 400\n",
      "reg_610.pbr: 400\n",
      "reg_611.pbr: 400\n",
      "reg_612.pbr: 400\n",
      "reg_613.pbr: 400\n",
      "reg_614.pbr: 400\n",
      "reg_615.pbr: 400\n",
      "reg_616.pbr: 400\n",
      "reg_617.pbr: 400\n",
      "reg_618.pbr: 400\n",
      "reg_619.pbr: 400\n",
      "reg_620.pbr: 400\n",
      "reg_621.pbr: 400\n",
      "reg_622.pbr: 400\n",
      "reg_623.pbr: 400\n",
      "reg_624.pbr: 400\n",
      "reg_625.pbr: 400\n",
      "reg_626.pbr: 400\n",
      "reg_627.pbr: 400\n",
      "reg_628.pbr: 400\n",
      "reg_629.pbr: 400\n",
      "reg_630.pbr: 400\n",
      "reg_631.pbr: 400\n",
      "reg_632.pbr: 400\n",
      "reg_633.pbr: 400\n",
      "reg_634.pbr: 400\n",
      "reg_635.pbr: 400\n",
      "reg_636.pbr: 400\n",
      "reg_637.pbr: 400\n",
      "reg_638.pbr: 400\n",
      "reg_639.pbr: 400\n",
      "reg_640.pbr: 400\n",
      "reg_641.pbr: 400\n",
      "reg_642.pbr: 400\n",
      "reg_643.pbr: 400\n",
      "reg_644.pbr: 400\n",
      "reg_645.pbr: 400\n",
      "reg_646.pbr: 400\n",
      "reg_647.pbr: 400\n",
      "reg_648.pbr: 400\n",
      "reg_649.pbr: 400\n",
      "reg_650.pbr: 400\n",
      "reg_651.pbr: 400\n",
      "reg_652.pbr: 400\n",
      "reg_653.pbr: 400\n",
      "reg_654.pbr: 400\n",
      "reg_655.pbr: 400\n",
      "reg_656.pbr: 400\n",
      "reg_657.pbr: 385\n",
      "reg_658.pbr: 400\n",
      "reg_659.pbr: 400\n",
      "reg_660.pbr: 400\n",
      "reg_661.pbr: 400\n",
      "reg_662.pbr: 400\n",
      "reg_663.pbr: 400\n",
      "reg_664.pbr: 400\n",
      "reg_665.pbr: 400\n",
      "reg_666.pbr: 400\n",
      "reg_667.pbr: 400\n",
      "reg_668.pbr: 400\n",
      "reg_669.pbr: 291\n",
      "reg_670.pbr: 213\n",
      "reg_671.pbr: 400\n",
      "reg_672.pbr: 400\n",
      "reg_673.pbr: 400\n",
      "reg_674.pbr: 400\n",
      "reg_675.pbr: 400\n",
      "reg_676.pbr: 400\n",
      "reg_677.pbr: 400\n",
      "reg_678.pbr: 400\n",
      "reg_679.pbr: 400\n",
      "reg_680.pbr: 400\n",
      "reg_681.pbr: 400\n",
      "reg_682.pbr: 400\n",
      "reg_683.pbr: 400\n",
      "reg_684.pbr: 400\n",
      "reg_685.pbr: 400\n",
      "reg_686.pbr: 400\n",
      "reg_687.pbr: 400\n",
      "reg_688.pbr: 400\n",
      "reg_689.pbr: 297\n",
      "reg_690.pbr: 259\n",
      "reg_691.pbr: 400\n",
      "reg_692.pbr: 400\n",
      "reg_693.pbr: 400\n",
      "reg_694.pbr: 400\n",
      "reg_695.pbr: 400\n",
      "reg_696.pbr: 400\n",
      "reg_697.pbr: 400\n",
      "reg_698.pbr: 400\n",
      "reg_699.pbr: 400\n",
      "reg_700.pbr: 400\n",
      "reg_701.pbr: 400\n",
      "reg_702.pbr: 400\n",
      "reg_703.pbr: 400\n",
      "reg_704.pbr: 400\n",
      "reg_705.pbr: 400\n",
      "reg_706.pbr: 400\n",
      "reg_707.pbr: 400\n",
      "reg_708.pbr: 400\n",
      "reg_709.pbr: 400\n",
      "reg_710.pbr: 400\n",
      "reg_711.pbr: 400\n",
      "reg_712.pbr: 400\n",
      "reg_713.pbr: 400\n",
      "reg_714.pbr: 400\n",
      "reg_715.pbr: 400\n",
      "reg_716.pbr: 400\n",
      "reg_717.pbr: 400\n",
      "reg_718.pbr: 400\n",
      "reg_719.pbr: 400\n",
      "reg_720.pbr: 400\n",
      "reg_721.pbr: 400\n",
      "reg_722.pbr: 400\n",
      "reg_723.pbr: 395\n",
      "reg_724.pbr: 400\n",
      "reg_725.pbr: 400\n",
      "reg_726.pbr: 400\n",
      "reg_727.pbr: 330\n",
      "reg_728.pbr: 400\n",
      "reg_729.pbr: 400\n",
      "reg_730.pbr: 400\n",
      "reg_731.pbr: 400\n",
      "reg_732.pbr: 400\n",
      "reg_733.pbr: 400\n",
      "reg_734.pbr: 400\n",
      "reg_735.pbr: 400\n",
      "reg_736.pbr: 400\n",
      "reg_737.pbr: 400\n",
      "reg_738.pbr: 400\n",
      "reg_739.pbr: 400\n",
      "reg_740.pbr: 400\n",
      "reg_741.pbr: 400\n",
      "reg_742.pbr: 400\n",
      "reg_743.pbr: 400\n",
      "reg_744.pbr: 400\n",
      "reg_745.pbr: 400\n",
      "reg_746.pbr: 400\n",
      "reg_747.pbr: 329\n",
      "reg_748.pbr: 400\n",
      "reg_749.pbr: 400\n",
      "reg_750.pbr: 400\n",
      "reg_751.pbr: 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_752.pbr: 400\n",
      "reg_753.pbr: 400\n",
      "reg_754.pbr: 400\n",
      "reg_755.pbr: 400\n",
      "reg_756.pbr: 400\n",
      "reg_757.pbr: 400\n",
      "reg_758.pbr: 400\n",
      "reg_759.pbr: 400\n",
      "reg_760.pbr: 400\n",
      "reg_761.pbr: 400\n",
      "reg_762.pbr: 400\n",
      "reg_763.pbr: 400\n",
      "reg_764.pbr: 400\n",
      "reg_765.pbr: 400\n",
      "reg_766.pbr: 400\n",
      "reg_767.pbr: 400\n",
      "reg_768.pbr: 400\n",
      "reg_769.pbr: 400\n",
      "reg_770.pbr: 400\n",
      "reg_771.pbr: 400\n",
      "reg_772.pbr: 400\n",
      "reg_773.pbr: 400\n",
      "reg_774.pbr: 400\n",
      "reg_775.pbr: 400\n",
      "reg_776.pbr: 400\n",
      "reg_777.pbr: 400\n",
      "reg_778.pbr: 400\n",
      "reg_779.pbr: 400\n",
      "reg_780.pbr: 400\n",
      "reg_781.pbr: 400\n",
      "reg_782.pbr: 400\n",
      "reg_783.pbr: 400\n",
      "reg_784.pbr: 400\n",
      "reg_785.pbr: 400\n",
      "reg_786.pbr: 400\n",
      "reg_787.pbr: 400\n",
      "reg_788.pbr: 400\n",
      "reg_789.pbr: 400\n",
      "reg_790.pbr: 400\n",
      "reg_791.pbr: 400\n",
      "reg_792.pbr: 400\n",
      "reg_793.pbr: 400\n",
      "reg_794.pbr: 400\n",
      "reg_795.pbr: 400\n",
      "reg_796.pbr: 400\n",
      "reg_797.pbr: 400\n",
      "reg_798.pbr: 400\n",
      "reg_799.pbr: 400\n",
      "reg_800.pbr: 400\n",
      "reg_801.pbr: 400\n",
      "reg_802.pbr: 400\n",
      "reg_803.pbr: 400\n",
      "reg_804.pbr: 400\n",
      "reg_805.pbr: 400\n",
      "reg_806.pbr: 400\n",
      "reg_807.pbr: 400\n",
      "reg_808.pbr: 400\n",
      "reg_809.pbr: 400\n",
      "reg_810.pbr: 400\n",
      "reg_811.pbr: 400\n",
      "reg_812.pbr: 400\n",
      "reg_813.pbr: 400\n",
      "reg_814.pbr: 400\n",
      "reg_815.pbr: 400\n",
      "reg_816.pbr: 400\n",
      "reg_817.pbr: 400\n",
      "reg_818.pbr: 400\n",
      "reg_819.pbr: 400\n",
      "reg_820.pbr: 400\n",
      "reg_821.pbr: 400\n",
      "reg_822.pbr: 400\n",
      "reg_823.pbr: 400\n",
      "reg_824.pbr: 400\n",
      "reg_825.pbr: 400\n",
      "reg_826.pbr: 400\n",
      "reg_827.pbr: 400\n",
      "reg_828.pbr: 400\n",
      "reg_829.pbr: 400\n",
      "reg_830.pbr: 400\n",
      "reg_831.pbr: 400\n",
      "reg_832.pbr: 400\n",
      "reg_833.pbr: 400\n",
      "reg_834.pbr: 400\n",
      "reg_835.pbr: 400\n",
      "reg_836.pbr: 400\n",
      "reg_837.pbr: 400\n",
      "reg_838.pbr: 400\n",
      "reg_839.pbr: 400\n",
      "reg_840.pbr: 400\n",
      "reg_841.pbr: 400\n",
      "reg_842.pbr: 400\n",
      "reg_843.pbr: 400\n",
      "reg_844.pbr: 400\n",
      "reg_845.pbr: 400\n",
      "reg_846.pbr: 400\n",
      "reg_847.pbr: 400\n",
      "reg_848.pbr: 400\n",
      "reg_849.pbr: 400\n",
      "reg_850.pbr: 400\n",
      "reg_851.pbr: 400\n",
      "reg_852.pbr: 400\n",
      "reg_853.pbr: 400\n",
      "reg_854.pbr: 400\n",
      "reg_855.pbr: 400\n",
      "reg_856.pbr: 400\n",
      "reg_857.pbr: 400\n",
      "reg_858.pbr: 400\n",
      "reg_859.pbr: 366\n",
      "reg_860.pbr: 372\n",
      "reg_861.pbr: 400\n",
      "reg_862.pbr: 400\n",
      "reg_863.pbr: 278\n",
      "reg_864.pbr: 400\n",
      "reg_866.pbr: 400\n",
      "reg_867.pbr: 400\n",
      "reg_868.pbr: 400\n",
      "reg_869.pbr: 400\n",
      "reg_870.pbr: 400\n",
      "reg_871.pbr: 319\n",
      "reg_872.pbr: 400\n",
      "reg_873.pbr: 400\n",
      "reg_874.pbr: 400\n",
      "reg_875.pbr: 400\n",
      "reg_876.pbr: 400\n",
      "reg_877.pbr: 400\n",
      "reg_878.pbr: 400\n",
      "reg_879.pbr: 400\n",
      "reg_880.pbr: 400\n",
      "reg_881.pbr: 400\n",
      "reg_882.pbr: 400\n",
      "reg_883.pbr: 400\n",
      "reg_884.pbr: 400\n",
      "reg_885.pbr: 400\n",
      "reg_886.pbr: 400\n",
      "reg_887.pbr: 400\n",
      "reg_888.pbr: 400\n",
      "reg_889.pbr: 400\n",
      "reg_890.pbr: 400\n",
      "reg_891.pbr: 400\n",
      "reg_892.pbr: 400\n",
      "reg_893.pbr: 400\n",
      "reg_894.pbr: 400\n",
      "reg_895.pbr: 400\n",
      "reg_896.pbr: 400\n",
      "reg_897.pbr: 400\n",
      "reg_898.pbr: 400\n",
      "reg_899.pbr: 400\n",
      "reg_900.pbr: 400\n",
      "reg_901.pbr: 400\n",
      "reg_902.pbr: 400\n",
      "reg_903.pbr: 400\n",
      "reg_904.pbr: 400\n",
      "reg_905.pbr: 400\n",
      "reg_906.pbr: 400\n",
      "reg_907.pbr: 400\n",
      "reg_908.pbr: 400\n",
      "reg_909.pbr: 400\n",
      "reg_910.pbr: 400\n",
      "reg_911.pbr: 400\n",
      "reg_912.pbr: 400\n",
      "reg_913.pbr: 400\n",
      "reg_914.pbr: 400\n",
      "reg_915.pbr: 400\n",
      "reg_916.pbr: 400\n",
      "reg_917.pbr: 400\n",
      "reg_918.pbr: 400\n",
      "reg_919.pbr: 400\n",
      "reg_920.pbr: 400\n",
      "reg_921.pbr: 400\n",
      "reg_922.pbr: 400\n",
      "reg_923.pbr: 400\n",
      "reg_924.pbr: 340\n",
      "reg_925.pbr: 400\n",
      "reg_926.pbr: 400\n",
      "reg_927.pbr: 400\n",
      "reg_928.pbr: 400\n",
      "reg_929.pbr: 400\n",
      "reg_930.pbr: 400\n",
      "reg_931.pbr: 400\n",
      "reg_932.pbr: 400\n",
      "reg_933.pbr: 400\n",
      "reg_934.pbr: 400\n",
      "- Total probe number: 261674\n"
     ]
    }
   ],
   "source": [
    "# Used directories\n",
    "old_probe_folder=r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/SI-14/chr21';\n",
    "old_report_dir = r'/reports/merged'; # if merged\n",
    "\n",
    "# get previous outputs\n",
    "max_pb_num = 400;\n",
    "min_pb_num = 200;\n",
    "\n",
    "# Save directory\n",
    "report_folder = old_probe_folder + old_report_dir;\n",
    "save_folder = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-'+str(max_pb_num) # if merged\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder);\n",
    "files = glob.glob(report_folder+os.sep+r'*.pbr')\n",
    "total_prob_num = 0;\n",
    "for _file in sorted(files):\n",
    "    # load probe report\n",
    "    pbde = ld.pb_reports_class()\n",
    "    pbde.load_pbr(_file)\n",
    "    #change save file directory\n",
    "    pbde.save_file = save_folder + os.sep + os.path.basename(pbde.save_file);\n",
    "    # check length\n",
    "    if len(pbde.pb_reports_keep) < min_pb_num:\n",
    "        continue\n",
    "    else:\n",
    "        if len(pbde.pb_reports_keep) > max_pb_num:\n",
    "            # get region length\n",
    "            _start, _end = pbde.pb_reports_keep.values()[0]['reg_name'].split(':')[1].split('_')[0].split('-')\n",
    "            _reg_len = int(_end) - int(_start)\n",
    "            # initialize centered_dic\n",
    "            centered_pb_dic = {}\n",
    "            ct = 0;\n",
    "            for key, value in sorted(pbde.pb_reports_keep.items(), key=lambda (k,v): abs(v['pb_index']-int(_reg_len/2))):\n",
    "                centered_pb_dic[key] = value;\n",
    "                ct += 1;\n",
    "                if ct >= max_pb_num:\n",
    "                    break\n",
    "            pbde.pb_reports_keep = centered_pb_dic # during saving, its automatically sorted, so I didn't sort it again\n",
    "        total_prob_num += len(pbde.pb_reports_keep); # save total probe number\n",
    "        print os.path.basename(pbde.save_file)+\": \"+str(len(pbde.pb_reports_keep));\n",
    "        pbde.save_csv()\n",
    "        pbde.save_pbrs()\n",
    "        pbde.plots()\n",
    "print \"- Total probe number:\", total_prob_num;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Assign region into TADs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Match_TADs(master_folder, TAD_ref, report_folder,\n",
    "              verbose=True, save=True):\n",
    "    '''Function to match regions with a TAD reference\n",
    "    Input: \n",
    "    master_folder: master directory for the whole dataset, string\n",
    "    TAD_ref: filename for TAD reference, string\n",
    "    report_folder: directory for probe reports, string'''\n",
    "    import os, glob, sys\n",
    "    import LibraryDesigner as ld\n",
    "    import numpy as np\n",
    "    import cPickle as pickle\n",
    "    \n",
    "    def Read_TAD_ref(master_folder=master_folder, TAD_ref=TAD_ref):\n",
    "        _tad_dics = [];\n",
    "        with open(master_folder+os.sep+TAD_ref) as _ref_handle:\n",
    "            _lines = _ref_handle.readlines();\n",
    "            for _line in _lines:\n",
    "                _chrom = _line.split(':')[0]\n",
    "                _reg_str = _line.split(':')[1].split('\\n')[0];\n",
    "                _start,_stop = _reg_str.split('-');\n",
    "                _tad_dic = {'chr':_chrom, 'start':int(_start), 'stop':int(_stop)}\n",
    "                _tad_dics.append(_tad_dic);\n",
    "        return sorted(_tad_dics, key=lambda d:d['start']);\n",
    "    \n",
    "    def Region_to_TAD(tad_dics, report_filename):\n",
    "        _pb = ld.pb_reports_class()\n",
    "        _pb.load_pbr(report_filename)\n",
    "        # get its region status\n",
    "        _reg_id = int(_pb.pb_reports_keep.values()[0]['reg_name'].split('reg')[1].split('_')[1])\n",
    "        _chrom = _pb.pb_reports_keep.values()[0]['reg_name'].split(':')[0]\n",
    "        _start, _stop = _pb.pb_reports_keep.values()[0]['reg_name'].split(':')[1].split('_')[0].split('-')\n",
    "        _start = int(_start);\n",
    "        _stop = int(_stop);\n",
    "        if _start > _stop:\n",
    "            _start, _stop = _stop, _start\n",
    "        _reg_len = abs(_stop - _start)\n",
    "        # initialize tad identity of this region\n",
    "        _tad_id = -1;\n",
    "        for i in range(len(tad_dics)):\n",
    "            _dic = tad_dics[i];\n",
    "            if _chrom == _dic['chr']:\n",
    "                _overlap = min(_stop, _dic['stop']) - max(_start, _dic['start']);\n",
    "                if _overlap > _reg_len / 2:\n",
    "                    _tad_id = i; # assign tad id\n",
    "                    break\n",
    "    \n",
    "        return _reg_id, _tad_id, len(_pb.pb_reports_keep)\n",
    "    \n",
    "    def Extra_Region_Assigning(tad_id_dic):\n",
    "        '''Try to assign region to TADs as much as possible\n",
    "        '''\n",
    "        # calculate how many region has been assigned to each TAD\n",
    "        _v,_c = np.unique(tad_id_dic.values(),return_counts=True)\n",
    "        _reg_num_dic = dict(zip(_v,_c)) # dictionary for region number of each TAD\n",
    "\n",
    "        # maximum gap size to be filled\n",
    "        _gap_max = 4 \n",
    "\n",
    "        # new_id_dic\n",
    "        _new_id_dic = tad_id_dic.copy();\n",
    "\n",
    "        # Starting filling gaps!\n",
    "        _gap = 0;\n",
    "        _prev_value = -1;\n",
    "        for _key, _value in sorted(_new_id_dic.items()):\n",
    "            # start a gap \n",
    "            if _gap == 0 and _value == -1: \n",
    "                _prev_tad = _prev_value\n",
    "                _gap = 1; # turn on gap\n",
    "                _key_ingap = [_key] # start recording keys in gap\n",
    "\n",
    "            # continue a gap\n",
    "            elif _gap == 1 and _value == -1:\n",
    "                _key_ingap.append(_key)\n",
    "\n",
    "            # stop a gap!\n",
    "            elif _gap == 1 and _value > -1:\n",
    "                _gap = 0; # stop counting gap\n",
    "                _next_tad = _value \n",
    "                # if the gap is not huge, try to make up\n",
    "                if len(_key_ingap) <= _gap_max: \n",
    "                    if _prev_tad == -1: # don't fill any gap at beginning\n",
    "                        continue \n",
    "                    elif len(_key_ingap)/2*2 == len(_key_ingap): # gap size is even number\n",
    "                        for i in range(len(_key_ingap)/2):\n",
    "                            _new_id_dic[_key_ingap[i]] = _prev_tad\n",
    "                            _new_id_dic[_key_ingap[i+len(_key_ingap)/2]] = _next_tad\n",
    "                    else: # gap size is odd number\n",
    "                        for i in range(len(_key_ingap)/2):\n",
    "                            _new_id_dic[_key_ingap[i]] = _prev_tad\n",
    "                            _new_id_dic[_key_ingap[i+len(_key_ingap)/2+1]] = _next_tad\n",
    "                        if _reg_num_dic[_prev_tad] <= _reg_num_dic[_next_tad]:\n",
    "                            _new_id_dic[_key_ingap[len(_key_ingap)/2]] = _prev_tad\n",
    "                        else:\n",
    "                            _new_id_dic[_key_ingap[len(_key_ingap)/2]] = _next_tad\n",
    "\n",
    "            _prev_value = _value # store previous tad info\n",
    "\n",
    "        return _new_id_dic   \n",
    "    \n",
    "    def Save_dics(master_folder, tad_dics, reg_len_dic, new_id_dic):\n",
    "        # save tad dics\n",
    "        tad_dic_file = open(master_folder+os.sep+'TAD_dic_list.pkl','w');\n",
    "        pickle.dump(tad_dics, tad_dic_file);\n",
    "        tad_dic_file.close()\n",
    "        # save region length dic\n",
    "        reg_len_dic_file = open(master_folder+os.sep+'region_length.pkl','w');\n",
    "        pickle.dump(reg_len_dic, reg_len_dic_file);\n",
    "        reg_len_dic_file.close()        \n",
    "        # save region_to_tad dic\n",
    "        reg_to_tad_file = open(master_folder+os.sep+'region_to_TAD.pkl','w');\n",
    "        pickle.dump(new_id_dic, reg_to_tad_file);\n",
    "        reg_to_tad_file.close() \n",
    "\n",
    "    if verbose:\n",
    "        print '- Start reading TAD reference', TAD_ref\n",
    "    tad_dics = Read_TAD_ref()\n",
    "    \n",
    "    if verbose:\n",
    "        print '- Start reading probe reports'\n",
    "\n",
    "    files = glob.glob(report_folder+os.sep+r'*.pbr')\n",
    "    tad_id_dic = {} # store assigned tad id\n",
    "    reg_len_dic = {} # store number of probes in each region\n",
    "    \n",
    "    for _file in sorted(files):\n",
    "        reg_id, tad_id, reg_len = Region_to_TAD(tad_dics, _file)\n",
    "        tad_id_dic[reg_id] = tad_id; # update tad id dic\n",
    "        reg_len_dic[reg_id] = reg_len; # update region length dic\n",
    "        if verbose:\n",
    "            print '--', os.path.basename(_file), 'tad_id:', tad_id, 'size:', reg_len\n",
    "\n",
    "            \n",
    "    new_id_dic = Extra_Region_Assigning(tad_id_dic)\n",
    "    \n",
    "    if save:\n",
    "        Save_dics(master_folder=master_folder,\n",
    "                 tad_dics=tad_dics,\n",
    "                 reg_len_dic=reg_len_dic,\n",
    "                 new_id_dic=new_id_dic);\n",
    "\n",
    "    \n",
    "    return tad_dics, tad_id_dic, reg_len_dic, new_id_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Start reading TAD reference chr21_TADs.bed\n",
      "- Start reading probe reports\n",
      "-- reg_101.pbr tad_id: -1 size: 343\n",
      "-- reg_102.pbr tad_id: -1 size: 399\n",
      "-- reg_103.pbr tad_id: -1 size: 400\n",
      "-- reg_121.pbr tad_id: -1 size: 370\n",
      "-- reg_122.pbr tad_id: -1 size: 400\n",
      "-- reg_123.pbr tad_id: -1 size: 400\n",
      "-- reg_130.pbr tad_id: -1 size: 400\n",
      "-- reg_131.pbr tad_id: -1 size: 257\n",
      "-- reg_132.pbr tad_id: -1 size: 278\n",
      "-- reg_156.pbr tad_id: -1 size: 363\n",
      "-- reg_157.pbr tad_id: -1 size: 281\n",
      "-- reg_195.pbr tad_id: -1 size: 216\n",
      "-- reg_196.pbr tad_id: -1 size: 386\n",
      "-- reg_209.pbr tad_id: 0 size: 215\n",
      "-- reg_211.pbr tad_id: 0 size: 239\n",
      "-- reg_213.pbr tad_id: 0 size: 216\n",
      "-- reg_266.pbr tad_id: 1 size: 221\n",
      "-- reg_281.pbr tad_id: 1 size: 400\n",
      "-- reg_282.pbr tad_id: 1 size: 367\n",
      "-- reg_283.pbr tad_id: 1 size: 400\n",
      "-- reg_284.pbr tad_id: 1 size: 400\n",
      "-- reg_285.pbr tad_id: 1 size: 400\n",
      "-- reg_286.pbr tad_id: 1 size: 400\n",
      "-- reg_287.pbr tad_id: 1 size: 400\n",
      "-- reg_288.pbr tad_id: 1 size: 400\n",
      "-- reg_289.pbr tad_id: 1 size: 334\n",
      "-- reg_290.pbr tad_id: 1 size: 400\n",
      "-- reg_291.pbr tad_id: 1 size: 400\n",
      "-- reg_292.pbr tad_id: 1 size: 400\n",
      "-- reg_293.pbr tad_id: 1 size: 400\n",
      "-- reg_294.pbr tad_id: 1 size: 400\n",
      "-- reg_295.pbr tad_id: 1 size: 400\n",
      "-- reg_296.pbr tad_id: 1 size: 400\n",
      "-- reg_297.pbr tad_id: 1 size: 400\n",
      "-- reg_298.pbr tad_id: 1 size: 400\n",
      "-- reg_299.pbr tad_id: 1 size: 400\n",
      "-- reg_300.pbr tad_id: 1 size: 400\n",
      "-- reg_301.pbr tad_id: 1 size: 400\n",
      "-- reg_302.pbr tad_id: 1 size: 400\n",
      "-- reg_303.pbr tad_id: 1 size: 400\n",
      "-- reg_304.pbr tad_id: 1 size: 400\n",
      "-- reg_305.pbr tad_id: 1 size: 400\n",
      "-- reg_306.pbr tad_id: 1 size: 400\n",
      "-- reg_307.pbr tad_id: 1 size: 400\n",
      "-- reg_308.pbr tad_id: 1 size: 400\n",
      "-- reg_309.pbr tad_id: 1 size: 400\n",
      "-- reg_310.pbr tad_id: 1 size: 400\n",
      "-- reg_311.pbr tad_id: 1 size: 400\n",
      "-- reg_312.pbr tad_id: 1 size: 400\n",
      "-- reg_313.pbr tad_id: 1 size: 400\n",
      "-- reg_314.pbr tad_id: 1 size: 400\n",
      "-- reg_315.pbr tad_id: 1 size: 400\n",
      "-- reg_316.pbr tad_id: 1 size: 400\n",
      "-- reg_317.pbr tad_id: 1 size: 400\n",
      "-- reg_318.pbr tad_id: 2 size: 400\n",
      "-- reg_319.pbr tad_id: 2 size: 395\n",
      "-- reg_320.pbr tad_id: 2 size: 400\n",
      "-- reg_321.pbr tad_id: 2 size: 400\n",
      "-- reg_322.pbr tad_id: 2 size: 400\n",
      "-- reg_323.pbr tad_id: 2 size: 400\n",
      "-- reg_324.pbr tad_id: 2 size: 400\n",
      "-- reg_325.pbr tad_id: 2 size: 400\n",
      "-- reg_326.pbr tad_id: 2 size: 400\n",
      "-- reg_327.pbr tad_id: 2 size: 400\n",
      "-- reg_328.pbr tad_id: 2 size: 400\n",
      "-- reg_329.pbr tad_id: 2 size: 400\n",
      "-- reg_330.pbr tad_id: 2 size: 400\n",
      "-- reg_331.pbr tad_id: 2 size: 400\n",
      "-- reg_332.pbr tad_id: 2 size: 400\n",
      "-- reg_333.pbr tad_id: 2 size: 400\n",
      "-- reg_334.pbr tad_id: 2 size: 400\n",
      "-- reg_335.pbr tad_id: 2 size: 400\n",
      "-- reg_336.pbr tad_id: 2 size: 400\n",
      "-- reg_337.pbr tad_id: 2 size: 400\n",
      "-- reg_338.pbr tad_id: 2 size: 400\n",
      "-- reg_339.pbr tad_id: 2 size: 400\n",
      "-- reg_340.pbr tad_id: 2 size: 400\n",
      "-- reg_341.pbr tad_id: 2 size: 400\n",
      "-- reg_342.pbr tad_id: 2 size: 400\n",
      "-- reg_343.pbr tad_id: 2 size: 400\n",
      "-- reg_348.pbr tad_id: 2 size: 400\n",
      "-- reg_349.pbr tad_id: 2 size: 400\n",
      "-- reg_350.pbr tad_id: 2 size: 400\n",
      "-- reg_351.pbr tad_id: 2 size: 400\n",
      "-- reg_352.pbr tad_id: 2 size: 400\n",
      "-- reg_353.pbr tad_id: 2 size: 283\n",
      "-- reg_354.pbr tad_id: 2 size: 202\n",
      "-- reg_355.pbr tad_id: 2 size: 205\n",
      "-- reg_356.pbr tad_id: 2 size: 400\n",
      "-- reg_357.pbr tad_id: 2 size: 400\n",
      "-- reg_358.pbr tad_id: 2 size: 400\n",
      "-- reg_359.pbr tad_id: 2 size: 400\n",
      "-- reg_360.pbr tad_id: 2 size: 400\n",
      "-- reg_361.pbr tad_id: -1 size: 400\n",
      "-- reg_362.pbr tad_id: 3 size: 400\n",
      "-- reg_363.pbr tad_id: 3 size: 400\n",
      "-- reg_364.pbr tad_id: 3 size: 400\n",
      "-- reg_365.pbr tad_id: 3 size: 400\n",
      "-- reg_366.pbr tad_id: 3 size: 400\n",
      "-- reg_367.pbr tad_id: 3 size: 400\n",
      "-- reg_368.pbr tad_id: 3 size: 400\n",
      "-- reg_369.pbr tad_id: 3 size: 400\n",
      "-- reg_370.pbr tad_id: 3 size: 400\n",
      "-- reg_371.pbr tad_id: 3 size: 400\n",
      "-- reg_372.pbr tad_id: 3 size: 400\n",
      "-- reg_373.pbr tad_id: 3 size: 400\n",
      "-- reg_374.pbr tad_id: 3 size: 400\n",
      "-- reg_375.pbr tad_id: 3 size: 400\n",
      "-- reg_376.pbr tad_id: 3 size: 400\n",
      "-- reg_377.pbr tad_id: 3 size: 400\n",
      "-- reg_378.pbr tad_id: 3 size: 400\n",
      "-- reg_379.pbr tad_id: 3 size: 400\n",
      "-- reg_380.pbr tad_id: 3 size: 400\n",
      "-- reg_381.pbr tad_id: 3 size: 400\n",
      "-- reg_382.pbr tad_id: 3 size: 400\n",
      "-- reg_383.pbr tad_id: 3 size: 400\n",
      "-- reg_384.pbr tad_id: 3 size: 400\n",
      "-- reg_385.pbr tad_id: 3 size: 400\n",
      "-- reg_386.pbr tad_id: 3 size: 400\n",
      "-- reg_387.pbr tad_id: 3 size: 400\n",
      "-- reg_388.pbr tad_id: 3 size: 400\n",
      "-- reg_389.pbr tad_id: 3 size: 400\n",
      "-- reg_390.pbr tad_id: 3 size: 400\n",
      "-- reg_391.pbr tad_id: 3 size: 400\n",
      "-- reg_392.pbr tad_id: 3 size: 400\n",
      "-- reg_393.pbr tad_id: 3 size: 400\n",
      "-- reg_394.pbr tad_id: 3 size: 400\n",
      "-- reg_395.pbr tad_id: 3 size: 400\n",
      "-- reg_396.pbr tad_id: 3 size: 400\n",
      "-- reg_397.pbr tad_id: 3 size: 400\n",
      "-- reg_398.pbr tad_id: 3 size: 400\n",
      "-- reg_399.pbr tad_id: 3 size: 400\n",
      "-- reg_400.pbr tad_id: 3 size: 400\n",
      "-- reg_401.pbr tad_id: 3 size: 400\n",
      "-- reg_402.pbr tad_id: 3 size: 400\n",
      "-- reg_403.pbr tad_id: 3 size: 400\n",
      "-- reg_404.pbr tad_id: 3 size: 400\n",
      "-- reg_405.pbr tad_id: 3 size: 400\n",
      "-- reg_406.pbr tad_id: 3 size: 400\n",
      "-- reg_407.pbr tad_id: 3 size: 400\n",
      "-- reg_408.pbr tad_id: 3 size: 400\n",
      "-- reg_409.pbr tad_id: 3 size: 400\n",
      "-- reg_410.pbr tad_id: 3 size: 400\n",
      "-- reg_411.pbr tad_id: 3 size: 400\n",
      "-- reg_412.pbr tad_id: 3 size: 400\n",
      "-- reg_413.pbr tad_id: 3 size: 400\n",
      "-- reg_414.pbr tad_id: 3 size: 400\n",
      "-- reg_415.pbr tad_id: 3 size: 400\n",
      "-- reg_416.pbr tad_id: 3 size: 400\n",
      "-- reg_417.pbr tad_id: -1 size: 400\n",
      "-- reg_418.pbr tad_id: -1 size: 400\n",
      "-- reg_419.pbr tad_id: -1 size: 400\n",
      "-- reg_420.pbr tad_id: 4 size: 400\n",
      "-- reg_421.pbr tad_id: 4 size: 400\n",
      "-- reg_422.pbr tad_id: 4 size: 400\n",
      "-- reg_423.pbr tad_id: 4 size: 400\n",
      "-- reg_424.pbr tad_id: 4 size: 400\n",
      "-- reg_425.pbr tad_id: 4 size: 400\n",
      "-- reg_426.pbr tad_id: 4 size: 400\n",
      "-- reg_427.pbr tad_id: 4 size: 400\n",
      "-- reg_428.pbr tad_id: 4 size: 400\n",
      "-- reg_429.pbr tad_id: 4 size: 400\n",
      "-- reg_430.pbr tad_id: 4 size: 400\n",
      "-- reg_431.pbr tad_id: 4 size: 400\n",
      "-- reg_432.pbr tad_id: 4 size: 400\n",
      "-- reg_433.pbr tad_id: 4 size: 400\n",
      "-- reg_434.pbr tad_id: 4 size: 400\n",
      "-- reg_435.pbr tad_id: 4 size: 400\n",
      "-- reg_436.pbr tad_id: 4 size: 400\n",
      "-- reg_437.pbr tad_id: 4 size: 400\n",
      "-- reg_438.pbr tad_id: 4 size: 400\n",
      "-- reg_439.pbr tad_id: 4 size: 400\n",
      "-- reg_440.pbr tad_id: 4 size: 400\n",
      "-- reg_441.pbr tad_id: 4 size: 400\n",
      "-- reg_442.pbr tad_id: 4 size: 400\n",
      "-- reg_443.pbr tad_id: 4 size: 268\n",
      "-- reg_445.pbr tad_id: 4 size: 222\n",
      "-- reg_446.pbr tad_id: 4 size: 240\n",
      "-- reg_447.pbr tad_id: 4 size: 400\n",
      "-- reg_448.pbr tad_id: 4 size: 400\n",
      "-- reg_449.pbr tad_id: 4 size: 400\n",
      "-- reg_450.pbr tad_id: 4 size: 400\n",
      "-- reg_451.pbr tad_id: 4 size: 400\n",
      "-- reg_452.pbr tad_id: 4 size: 400\n",
      "-- reg_453.pbr tad_id: 4 size: 400\n",
      "-- reg_454.pbr tad_id: 4 size: 400\n",
      "-- reg_455.pbr tad_id: 4 size: 400\n",
      "-- reg_456.pbr tad_id: 4 size: 400\n",
      "-- reg_457.pbr tad_id: 4 size: 400\n",
      "-- reg_458.pbr tad_id: 4 size: 400\n",
      "-- reg_459.pbr tad_id: 4 size: 400\n",
      "-- reg_460.pbr tad_id: 4 size: 400\n",
      "-- reg_461.pbr tad_id: 4 size: 400\n",
      "-- reg_462.pbr tad_id: 4 size: 400\n",
      "-- reg_463.pbr tad_id: 4 size: 400\n",
      "-- reg_464.pbr tad_id: 4 size: 400\n",
      "-- reg_465.pbr tad_id: 4 size: 400\n",
      "-- reg_466.pbr tad_id: 4 size: 400\n",
      "-- reg_467.pbr tad_id: 4 size: 400\n",
      "-- reg_468.pbr tad_id: 4 size: 400\n",
      "-- reg_469.pbr tad_id: 4 size: 400\n",
      "-- reg_470.pbr tad_id: 4 size: 400\n",
      "-- reg_471.pbr tad_id: 4 size: 400\n",
      "-- reg_472.pbr tad_id: 4 size: 400\n",
      "-- reg_473.pbr tad_id: 4 size: 400\n",
      "-- reg_474.pbr tad_id: 4 size: 400\n",
      "-- reg_475.pbr tad_id: 4 size: 400\n",
      "-- reg_476.pbr tad_id: 4 size: 400\n",
      "-- reg_477.pbr tad_id: 4 size: 400\n",
      "-- reg_478.pbr tad_id: 4 size: 400\n",
      "-- reg_479.pbr tad_id: 4 size: 400\n",
      "-- reg_480.pbr tad_id: 4 size: 400\n",
      "-- reg_481.pbr tad_id: 4 size: 400\n",
      "-- reg_482.pbr tad_id: 5 size: 400\n",
      "-- reg_483.pbr tad_id: 5 size: 400\n",
      "-- reg_484.pbr tad_id: 5 size: 400\n",
      "-- reg_485.pbr tad_id: 5 size: 400\n",
      "-- reg_486.pbr tad_id: 5 size: 400\n",
      "-- reg_487.pbr tad_id: 5 size: 400\n",
      "-- reg_488.pbr tad_id: 5 size: 400\n",
      "-- reg_489.pbr tad_id: 5 size: 400\n",
      "-- reg_490.pbr tad_id: 5 size: 400\n",
      "-- reg_491.pbr tad_id: 5 size: 400\n",
      "-- reg_492.pbr tad_id: 5 size: 400\n",
      "-- reg_493.pbr tad_id: 5 size: 400\n",
      "-- reg_494.pbr tad_id: 5 size: 400\n",
      "-- reg_495.pbr tad_id: 5 size: 400\n",
      "-- reg_496.pbr tad_id: 5 size: 400\n",
      "-- reg_497.pbr tad_id: 5 size: 400\n",
      "-- reg_498.pbr tad_id: 5 size: 400\n",
      "-- reg_499.pbr tad_id: 5 size: 400\n",
      "-- reg_500.pbr tad_id: 5 size: 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- reg_501.pbr tad_id: 5 size: 400\n",
      "-- reg_502.pbr tad_id: 5 size: 400\n",
      "-- reg_503.pbr tad_id: 5 size: 400\n",
      "-- reg_504.pbr tad_id: 5 size: 400\n",
      "-- reg_505.pbr tad_id: 5 size: 400\n",
      "-- reg_506.pbr tad_id: 5 size: 400\n",
      "-- reg_507.pbr tad_id: 5 size: 400\n",
      "-- reg_508.pbr tad_id: 5 size: 400\n",
      "-- reg_509.pbr tad_id: 5 size: 400\n",
      "-- reg_510.pbr tad_id: 5 size: 400\n",
      "-- reg_511.pbr tad_id: 5 size: 400\n",
      "-- reg_512.pbr tad_id: 5 size: 400\n",
      "-- reg_513.pbr tad_id: 5 size: 400\n",
      "-- reg_514.pbr tad_id: 6 size: 400\n",
      "-- reg_515.pbr tad_id: 6 size: 400\n",
      "-- reg_516.pbr tad_id: 6 size: 400\n",
      "-- reg_517.pbr tad_id: 6 size: 400\n",
      "-- reg_518.pbr tad_id: 6 size: 400\n",
      "-- reg_519.pbr tad_id: 6 size: 400\n",
      "-- reg_520.pbr tad_id: 6 size: 400\n",
      "-- reg_521.pbr tad_id: 6 size: 400\n",
      "-- reg_522.pbr tad_id: 6 size: 400\n",
      "-- reg_523.pbr tad_id: 6 size: 400\n",
      "-- reg_524.pbr tad_id: 6 size: 400\n",
      "-- reg_525.pbr tad_id: 6 size: 400\n",
      "-- reg_526.pbr tad_id: 6 size: 400\n",
      "-- reg_527.pbr tad_id: 6 size: 400\n",
      "-- reg_528.pbr tad_id: 6 size: 400\n",
      "-- reg_529.pbr tad_id: 6 size: 400\n",
      "-- reg_530.pbr tad_id: 6 size: 400\n",
      "-- reg_531.pbr tad_id: 6 size: 400\n",
      "-- reg_532.pbr tad_id: 6 size: 400\n",
      "-- reg_533.pbr tad_id: 6 size: 400\n",
      "-- reg_534.pbr tad_id: 6 size: 400\n",
      "-- reg_535.pbr tad_id: -1 size: 400\n",
      "-- reg_536.pbr tad_id: 7 size: 400\n",
      "-- reg_537.pbr tad_id: 7 size: 400\n",
      "-- reg_538.pbr tad_id: 7 size: 400\n",
      "-- reg_539.pbr tad_id: 7 size: 400\n",
      "-- reg_540.pbr tad_id: 7 size: 400\n",
      "-- reg_541.pbr tad_id: 7 size: 400\n",
      "-- reg_542.pbr tad_id: 7 size: 400\n",
      "-- reg_543.pbr tad_id: 7 size: 400\n",
      "-- reg_544.pbr tad_id: 7 size: 400\n",
      "-- reg_545.pbr tad_id: 7 size: 400\n",
      "-- reg_546.pbr tad_id: 7 size: 400\n",
      "-- reg_547.pbr tad_id: 7 size: 400\n",
      "-- reg_548.pbr tad_id: 7 size: 400\n",
      "-- reg_549.pbr tad_id: 7 size: 400\n",
      "-- reg_550.pbr tad_id: 7 size: 400\n",
      "-- reg_551.pbr tad_id: 7 size: 400\n",
      "-- reg_552.pbr tad_id: 7 size: 400\n",
      "-- reg_553.pbr tad_id: 7 size: 400\n",
      "-- reg_554.pbr tad_id: 7 size: 400\n",
      "-- reg_555.pbr tad_id: 8 size: 400\n",
      "-- reg_556.pbr tad_id: 8 size: 400\n",
      "-- reg_557.pbr tad_id: 8 size: 400\n",
      "-- reg_559.pbr tad_id: 8 size: 216\n",
      "-- reg_560.pbr tad_id: 8 size: 329\n",
      "-- reg_561.pbr tad_id: 8 size: 255\n",
      "-- reg_562.pbr tad_id: 8 size: 400\n",
      "-- reg_563.pbr tad_id: 8 size: 400\n",
      "-- reg_564.pbr tad_id: 8 size: 400\n",
      "-- reg_565.pbr tad_id: 8 size: 400\n",
      "-- reg_566.pbr tad_id: 8 size: 400\n",
      "-- reg_567.pbr tad_id: 8 size: 400\n",
      "-- reg_568.pbr tad_id: 8 size: 400\n",
      "-- reg_569.pbr tad_id: 8 size: 400\n",
      "-- reg_570.pbr tad_id: 8 size: 400\n",
      "-- reg_571.pbr tad_id: 8 size: 400\n",
      "-- reg_572.pbr tad_id: 8 size: 400\n",
      "-- reg_573.pbr tad_id: 8 size: 400\n",
      "-- reg_574.pbr tad_id: 8 size: 400\n",
      "-- reg_575.pbr tad_id: 8 size: 400\n",
      "-- reg_576.pbr tad_id: 8 size: 400\n",
      "-- reg_577.pbr tad_id: 8 size: 400\n",
      "-- reg_578.pbr tad_id: 8 size: 400\n",
      "-- reg_579.pbr tad_id: 8 size: 400\n",
      "-- reg_580.pbr tad_id: 8 size: 400\n",
      "-- reg_581.pbr tad_id: 8 size: 400\n",
      "-- reg_582.pbr tad_id: 9 size: 400\n",
      "-- reg_583.pbr tad_id: 9 size: 400\n",
      "-- reg_584.pbr tad_id: 9 size: 400\n",
      "-- reg_585.pbr tad_id: 9 size: 400\n",
      "-- reg_586.pbr tad_id: 9 size: 400\n",
      "-- reg_587.pbr tad_id: 9 size: 400\n",
      "-- reg_588.pbr tad_id: 9 size: 400\n",
      "-- reg_589.pbr tad_id: -1 size: 400\n",
      "-- reg_590.pbr tad_id: 10 size: 400\n",
      "-- reg_591.pbr tad_id: 10 size: 400\n",
      "-- reg_592.pbr tad_id: 10 size: 400\n",
      "-- reg_593.pbr tad_id: 10 size: 400\n",
      "-- reg_594.pbr tad_id: 10 size: 400\n",
      "-- reg_595.pbr tad_id: 10 size: 400\n",
      "-- reg_596.pbr tad_id: 10 size: 400\n",
      "-- reg_597.pbr tad_id: 10 size: 400\n",
      "-- reg_598.pbr tad_id: 10 size: 400\n",
      "-- reg_599.pbr tad_id: 10 size: 400\n",
      "-- reg_600.pbr tad_id: 10 size: 400\n",
      "-- reg_601.pbr tad_id: 10 size: 400\n",
      "-- reg_602.pbr tad_id: 10 size: 400\n",
      "-- reg_603.pbr tad_id: 10 size: 400\n",
      "-- reg_604.pbr tad_id: 10 size: 400\n",
      "-- reg_605.pbr tad_id: 10 size: 400\n",
      "-- reg_606.pbr tad_id: 10 size: 400\n",
      "-- reg_607.pbr tad_id: 10 size: 400\n",
      "-- reg_608.pbr tad_id: 10 size: 400\n",
      "-- reg_609.pbr tad_id: 10 size: 400\n",
      "-- reg_610.pbr tad_id: 10 size: 400\n",
      "-- reg_611.pbr tad_id: 10 size: 400\n",
      "-- reg_612.pbr tad_id: 10 size: 400\n",
      "-- reg_613.pbr tad_id: 10 size: 400\n",
      "-- reg_614.pbr tad_id: 10 size: 400\n",
      "-- reg_615.pbr tad_id: 10 size: 400\n",
      "-- reg_616.pbr tad_id: 10 size: 400\n",
      "-- reg_617.pbr tad_id: 10 size: 400\n",
      "-- reg_618.pbr tad_id: 10 size: 400\n",
      "-- reg_619.pbr tad_id: 10 size: 400\n",
      "-- reg_620.pbr tad_id: 10 size: 400\n",
      "-- reg_621.pbr tad_id: 10 size: 400\n",
      "-- reg_622.pbr tad_id: -1 size: 400\n",
      "-- reg_623.pbr tad_id: 11 size: 400\n",
      "-- reg_624.pbr tad_id: 11 size: 400\n",
      "-- reg_625.pbr tad_id: 11 size: 400\n",
      "-- reg_626.pbr tad_id: 11 size: 400\n",
      "-- reg_627.pbr tad_id: 11 size: 400\n",
      "-- reg_628.pbr tad_id: 11 size: 400\n",
      "-- reg_629.pbr tad_id: 11 size: 400\n",
      "-- reg_630.pbr tad_id: 11 size: 400\n",
      "-- reg_631.pbr tad_id: 11 size: 400\n",
      "-- reg_632.pbr tad_id: 11 size: 400\n",
      "-- reg_633.pbr tad_id: 11 size: 400\n",
      "-- reg_634.pbr tad_id: 12 size: 400\n",
      "-- reg_635.pbr tad_id: 12 size: 400\n",
      "-- reg_636.pbr tad_id: 12 size: 400\n",
      "-- reg_637.pbr tad_id: 12 size: 400\n",
      "-- reg_638.pbr tad_id: 12 size: 400\n",
      "-- reg_639.pbr tad_id: 12 size: 400\n",
      "-- reg_640.pbr tad_id: 12 size: 400\n",
      "-- reg_641.pbr tad_id: 12 size: 400\n",
      "-- reg_642.pbr tad_id: 12 size: 400\n",
      "-- reg_643.pbr tad_id: 12 size: 400\n",
      "-- reg_644.pbr tad_id: 12 size: 400\n",
      "-- reg_645.pbr tad_id: 12 size: 400\n",
      "-- reg_646.pbr tad_id: 12 size: 400\n",
      "-- reg_647.pbr tad_id: 13 size: 400\n",
      "-- reg_648.pbr tad_id: 13 size: 400\n",
      "-- reg_649.pbr tad_id: 13 size: 400\n",
      "-- reg_650.pbr tad_id: 13 size: 400\n",
      "-- reg_651.pbr tad_id: 13 size: 400\n",
      "-- reg_652.pbr tad_id: 13 size: 400\n",
      "-- reg_653.pbr tad_id: 13 size: 400\n",
      "-- reg_654.pbr tad_id: -1 size: 400\n",
      "-- reg_655.pbr tad_id: -1 size: 400\n",
      "-- reg_656.pbr tad_id: -1 size: 400\n",
      "-- reg_657.pbr tad_id: 14 size: 385\n",
      "-- reg_658.pbr tad_id: 14 size: 400\n",
      "-- reg_659.pbr tad_id: 14 size: 400\n",
      "-- reg_660.pbr tad_id: 14 size: 400\n",
      "-- reg_661.pbr tad_id: 14 size: 400\n",
      "-- reg_662.pbr tad_id: 14 size: 400\n",
      "-- reg_663.pbr tad_id: 14 size: 400\n",
      "-- reg_664.pbr tad_id: 14 size: 400\n",
      "-- reg_665.pbr tad_id: 14 size: 400\n",
      "-- reg_666.pbr tad_id: 14 size: 400\n",
      "-- reg_667.pbr tad_id: 14 size: 400\n",
      "-- reg_668.pbr tad_id: 14 size: 400\n",
      "-- reg_669.pbr tad_id: 14 size: 291\n",
      "-- reg_670.pbr tad_id: 14 size: 213\n",
      "-- reg_671.pbr tad_id: -1 size: 400\n",
      "-- reg_672.pbr tad_id: 15 size: 400\n",
      "-- reg_673.pbr tad_id: 15 size: 400\n",
      "-- reg_674.pbr tad_id: 15 size: 400\n",
      "-- reg_675.pbr tad_id: 15 size: 400\n",
      "-- reg_676.pbr tad_id: 15 size: 400\n",
      "-- reg_677.pbr tad_id: 15 size: 400\n",
      "-- reg_678.pbr tad_id: 15 size: 400\n",
      "-- reg_679.pbr tad_id: 16 size: 400\n",
      "-- reg_680.pbr tad_id: 16 size: 400\n",
      "-- reg_681.pbr tad_id: 16 size: 400\n",
      "-- reg_682.pbr tad_id: 16 size: 400\n",
      "-- reg_683.pbr tad_id: 16 size: 400\n",
      "-- reg_684.pbr tad_id: 16 size: 400\n",
      "-- reg_685.pbr tad_id: 16 size: 400\n",
      "-- reg_686.pbr tad_id: 16 size: 400\n",
      "-- reg_687.pbr tad_id: 16 size: 400\n",
      "-- reg_688.pbr tad_id: 16 size: 400\n",
      "-- reg_689.pbr tad_id: 17 size: 297\n",
      "-- reg_690.pbr tad_id: 17 size: 259\n",
      "-- reg_691.pbr tad_id: 17 size: 400\n",
      "-- reg_692.pbr tad_id: 17 size: 400\n",
      "-- reg_693.pbr tad_id: 17 size: 400\n",
      "-- reg_694.pbr tad_id: 18 size: 400\n",
      "-- reg_695.pbr tad_id: 18 size: 400\n",
      "-- reg_696.pbr tad_id: 18 size: 400\n",
      "-- reg_697.pbr tad_id: 18 size: 400\n",
      "-- reg_698.pbr tad_id: 18 size: 400\n",
      "-- reg_699.pbr tad_id: 18 size: 400\n",
      "-- reg_700.pbr tad_id: 18 size: 400\n",
      "-- reg_701.pbr tad_id: 18 size: 400\n",
      "-- reg_702.pbr tad_id: 18 size: 400\n",
      "-- reg_703.pbr tad_id: 18 size: 400\n",
      "-- reg_704.pbr tad_id: 18 size: 400\n",
      "-- reg_705.pbr tad_id: 18 size: 400\n",
      "-- reg_706.pbr tad_id: 18 size: 400\n",
      "-- reg_707.pbr tad_id: 18 size: 400\n",
      "-- reg_708.pbr tad_id: 18 size: 400\n",
      "-- reg_709.pbr tad_id: 18 size: 400\n",
      "-- reg_710.pbr tad_id: 18 size: 400\n",
      "-- reg_711.pbr tad_id: 18 size: 400\n",
      "-- reg_712.pbr tad_id: 18 size: 400\n",
      "-- reg_713.pbr tad_id: 18 size: 400\n",
      "-- reg_714.pbr tad_id: 18 size: 400\n",
      "-- reg_715.pbr tad_id: 18 size: 400\n",
      "-- reg_716.pbr tad_id: 18 size: 400\n",
      "-- reg_717.pbr tad_id: 18 size: 400\n",
      "-- reg_718.pbr tad_id: 18 size: 400\n",
      "-- reg_719.pbr tad_id: 18 size: 400\n",
      "-- reg_720.pbr tad_id: 18 size: 400\n",
      "-- reg_721.pbr tad_id: 18 size: 400\n",
      "-- reg_722.pbr tad_id: 18 size: 400\n",
      "-- reg_723.pbr tad_id: 18 size: 395\n",
      "-- reg_724.pbr tad_id: 19 size: 400\n",
      "-- reg_725.pbr tad_id: 19 size: 400\n",
      "-- reg_726.pbr tad_id: 19 size: 400\n",
      "-- reg_727.pbr tad_id: 19 size: 330\n",
      "-- reg_728.pbr tad_id: -1 size: 400\n",
      "-- reg_729.pbr tad_id: 20 size: 400\n",
      "-- reg_730.pbr tad_id: 20 size: 400\n",
      "-- reg_731.pbr tad_id: 20 size: 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- reg_732.pbr tad_id: 20 size: 400\n",
      "-- reg_733.pbr tad_id: 20 size: 400\n",
      "-- reg_734.pbr tad_id: 20 size: 400\n",
      "-- reg_735.pbr tad_id: 20 size: 400\n",
      "-- reg_736.pbr tad_id: 20 size: 400\n",
      "-- reg_737.pbr tad_id: 20 size: 400\n",
      "-- reg_738.pbr tad_id: 20 size: 400\n",
      "-- reg_739.pbr tad_id: 20 size: 400\n",
      "-- reg_740.pbr tad_id: 20 size: 400\n",
      "-- reg_741.pbr tad_id: 20 size: 400\n",
      "-- reg_742.pbr tad_id: 20 size: 400\n",
      "-- reg_743.pbr tad_id: 20 size: 400\n",
      "-- reg_744.pbr tad_id: 21 size: 400\n",
      "-- reg_745.pbr tad_id: 21 size: 400\n",
      "-- reg_746.pbr tad_id: 21 size: 400\n",
      "-- reg_747.pbr tad_id: 21 size: 329\n",
      "-- reg_748.pbr tad_id: 21 size: 400\n",
      "-- reg_749.pbr tad_id: 21 size: 400\n",
      "-- reg_750.pbr tad_id: 21 size: 400\n",
      "-- reg_751.pbr tad_id: 21 size: 400\n",
      "-- reg_752.pbr tad_id: 21 size: 400\n",
      "-- reg_753.pbr tad_id: -1 size: 400\n",
      "-- reg_754.pbr tad_id: 22 size: 400\n",
      "-- reg_755.pbr tad_id: 22 size: 400\n",
      "-- reg_756.pbr tad_id: 22 size: 400\n",
      "-- reg_757.pbr tad_id: 22 size: 400\n",
      "-- reg_758.pbr tad_id: 22 size: 400\n",
      "-- reg_759.pbr tad_id: 22 size: 400\n",
      "-- reg_760.pbr tad_id: 22 size: 400\n",
      "-- reg_761.pbr tad_id: 22 size: 400\n",
      "-- reg_762.pbr tad_id: 22 size: 400\n",
      "-- reg_763.pbr tad_id: 22 size: 400\n",
      "-- reg_764.pbr tad_id: 22 size: 400\n",
      "-- reg_765.pbr tad_id: 22 size: 400\n",
      "-- reg_766.pbr tad_id: 22 size: 400\n",
      "-- reg_767.pbr tad_id: 22 size: 400\n",
      "-- reg_768.pbr tad_id: 22 size: 400\n",
      "-- reg_769.pbr tad_id: 22 size: 400\n",
      "-- reg_770.pbr tad_id: 23 size: 400\n",
      "-- reg_771.pbr tad_id: 23 size: 400\n",
      "-- reg_772.pbr tad_id: 23 size: 400\n",
      "-- reg_773.pbr tad_id: 23 size: 400\n",
      "-- reg_774.pbr tad_id: 23 size: 400\n",
      "-- reg_775.pbr tad_id: 23 size: 400\n",
      "-- reg_776.pbr tad_id: 23 size: 400\n",
      "-- reg_777.pbr tad_id: 23 size: 400\n",
      "-- reg_778.pbr tad_id: 23 size: 400\n",
      "-- reg_779.pbr tad_id: 23 size: 400\n",
      "-- reg_780.pbr tad_id: 23 size: 400\n",
      "-- reg_781.pbr tad_id: 23 size: 400\n",
      "-- reg_782.pbr tad_id: 23 size: 400\n",
      "-- reg_783.pbr tad_id: 23 size: 400\n",
      "-- reg_784.pbr tad_id: 23 size: 400\n",
      "-- reg_785.pbr tad_id: 23 size: 400\n",
      "-- reg_786.pbr tad_id: 23 size: 400\n",
      "-- reg_787.pbr tad_id: 23 size: 400\n",
      "-- reg_788.pbr tad_id: 23 size: 400\n",
      "-- reg_789.pbr tad_id: 23 size: 400\n",
      "-- reg_790.pbr tad_id: 24 size: 400\n",
      "-- reg_791.pbr tad_id: 24 size: 400\n",
      "-- reg_792.pbr tad_id: 24 size: 400\n",
      "-- reg_793.pbr tad_id: 24 size: 400\n",
      "-- reg_794.pbr tad_id: 24 size: 400\n",
      "-- reg_795.pbr tad_id: 24 size: 400\n",
      "-- reg_796.pbr tad_id: 24 size: 400\n",
      "-- reg_797.pbr tad_id: 24 size: 400\n",
      "-- reg_798.pbr tad_id: 24 size: 400\n",
      "-- reg_799.pbr tad_id: 24 size: 400\n",
      "-- reg_800.pbr tad_id: 24 size: 400\n",
      "-- reg_801.pbr tad_id: 24 size: 400\n",
      "-- reg_802.pbr tad_id: 24 size: 400\n",
      "-- reg_803.pbr tad_id: 24 size: 400\n",
      "-- reg_804.pbr tad_id: 24 size: 400\n",
      "-- reg_805.pbr tad_id: 24 size: 400\n",
      "-- reg_806.pbr tad_id: 24 size: 400\n",
      "-- reg_807.pbr tad_id: 24 size: 400\n",
      "-- reg_808.pbr tad_id: 24 size: 400\n",
      "-- reg_809.pbr tad_id: 24 size: 400\n",
      "-- reg_810.pbr tad_id: 24 size: 400\n",
      "-- reg_811.pbr tad_id: 24 size: 400\n",
      "-- reg_812.pbr tad_id: 24 size: 400\n",
      "-- reg_813.pbr tad_id: 24 size: 400\n",
      "-- reg_814.pbr tad_id: 24 size: 400\n",
      "-- reg_815.pbr tad_id: 24 size: 400\n",
      "-- reg_816.pbr tad_id: 24 size: 400\n",
      "-- reg_817.pbr tad_id: 24 size: 400\n",
      "-- reg_818.pbr tad_id: 24 size: 400\n",
      "-- reg_819.pbr tad_id: 24 size: 400\n",
      "-- reg_820.pbr tad_id: 24 size: 400\n",
      "-- reg_821.pbr tad_id: 24 size: 400\n",
      "-- reg_822.pbr tad_id: 24 size: 400\n",
      "-- reg_823.pbr tad_id: 24 size: 400\n",
      "-- reg_824.pbr tad_id: 25 size: 400\n",
      "-- reg_825.pbr tad_id: 25 size: 400\n",
      "-- reg_826.pbr tad_id: 25 size: 400\n",
      "-- reg_827.pbr tad_id: 25 size: 400\n",
      "-- reg_828.pbr tad_id: 25 size: 400\n",
      "-- reg_829.pbr tad_id: 25 size: 400\n",
      "-- reg_830.pbr tad_id: 25 size: 400\n",
      "-- reg_831.pbr tad_id: 25 size: 400\n",
      "-- reg_832.pbr tad_id: 25 size: 400\n",
      "-- reg_833.pbr tad_id: 25 size: 400\n",
      "-- reg_834.pbr tad_id: 25 size: 400\n",
      "-- reg_835.pbr tad_id: 25 size: 400\n",
      "-- reg_836.pbr tad_id: 25 size: 400\n",
      "-- reg_837.pbr tad_id: 25 size: 400\n",
      "-- reg_838.pbr tad_id: 26 size: 400\n",
      "-- reg_839.pbr tad_id: 26 size: 400\n",
      "-- reg_840.pbr tad_id: 26 size: 400\n",
      "-- reg_841.pbr tad_id: 26 size: 400\n",
      "-- reg_842.pbr tad_id: 26 size: 400\n",
      "-- reg_843.pbr tad_id: 26 size: 400\n",
      "-- reg_844.pbr tad_id: 26 size: 400\n",
      "-- reg_845.pbr tad_id: 26 size: 400\n",
      "-- reg_846.pbr tad_id: 26 size: 400\n",
      "-- reg_847.pbr tad_id: 26 size: 400\n",
      "-- reg_848.pbr tad_id: 26 size: 400\n",
      "-- reg_849.pbr tad_id: 26 size: 400\n",
      "-- reg_850.pbr tad_id: 26 size: 400\n",
      "-- reg_851.pbr tad_id: 26 size: 400\n",
      "-- reg_852.pbr tad_id: 27 size: 400\n",
      "-- reg_853.pbr tad_id: 27 size: 400\n",
      "-- reg_854.pbr tad_id: 27 size: 400\n",
      "-- reg_855.pbr tad_id: 27 size: 400\n",
      "-- reg_856.pbr tad_id: 27 size: 400\n",
      "-- reg_857.pbr tad_id: 27 size: 400\n",
      "-- reg_858.pbr tad_id: 28 size: 400\n",
      "-- reg_859.pbr tad_id: 28 size: 366\n",
      "-- reg_860.pbr tad_id: 28 size: 372\n",
      "-- reg_861.pbr tad_id: 28 size: 400\n",
      "-- reg_862.pbr tad_id: 28 size: 400\n",
      "-- reg_863.pbr tad_id: 28 size: 278\n",
      "-- reg_864.pbr tad_id: 28 size: 400\n",
      "-- reg_866.pbr tad_id: 28 size: 400\n",
      "-- reg_867.pbr tad_id: 28 size: 400\n",
      "-- reg_868.pbr tad_id: 28 size: 400\n",
      "-- reg_869.pbr tad_id: 28 size: 400\n",
      "-- reg_870.pbr tad_id: 28 size: 400\n",
      "-- reg_871.pbr tad_id: 28 size: 319\n",
      "-- reg_872.pbr tad_id: 28 size: 400\n",
      "-- reg_873.pbr tad_id: 28 size: 400\n",
      "-- reg_874.pbr tad_id: 28 size: 400\n",
      "-- reg_875.pbr tad_id: 28 size: 400\n",
      "-- reg_876.pbr tad_id: 28 size: 400\n",
      "-- reg_877.pbr tad_id: 29 size: 400\n",
      "-- reg_878.pbr tad_id: 29 size: 400\n",
      "-- reg_879.pbr tad_id: 29 size: 400\n",
      "-- reg_880.pbr tad_id: 29 size: 400\n",
      "-- reg_881.pbr tad_id: 29 size: 400\n",
      "-- reg_882.pbr tad_id: 29 size: 400\n",
      "-- reg_883.pbr tad_id: 30 size: 400\n",
      "-- reg_884.pbr tad_id: 30 size: 400\n",
      "-- reg_885.pbr tad_id: 30 size: 400\n",
      "-- reg_886.pbr tad_id: 30 size: 400\n",
      "-- reg_887.pbr tad_id: 30 size: 400\n",
      "-- reg_888.pbr tad_id: 30 size: 400\n",
      "-- reg_889.pbr tad_id: 30 size: 400\n",
      "-- reg_890.pbr tad_id: 30 size: 400\n",
      "-- reg_891.pbr tad_id: 30 size: 400\n",
      "-- reg_892.pbr tad_id: 30 size: 400\n",
      "-- reg_893.pbr tad_id: 30 size: 400\n",
      "-- reg_894.pbr tad_id: 30 size: 400\n",
      "-- reg_895.pbr tad_id: 30 size: 400\n",
      "-- reg_896.pbr tad_id: 30 size: 400\n",
      "-- reg_897.pbr tad_id: 31 size: 400\n",
      "-- reg_898.pbr tad_id: 31 size: 400\n",
      "-- reg_899.pbr tad_id: 31 size: 400\n",
      "-- reg_900.pbr tad_id: 31 size: 400\n",
      "-- reg_901.pbr tad_id: 31 size: 400\n",
      "-- reg_902.pbr tad_id: 31 size: 400\n",
      "-- reg_903.pbr tad_id: 31 size: 400\n",
      "-- reg_904.pbr tad_id: -1 size: 400\n",
      "-- reg_905.pbr tad_id: 32 size: 400\n",
      "-- reg_906.pbr tad_id: 32 size: 400\n",
      "-- reg_907.pbr tad_id: 32 size: 400\n",
      "-- reg_908.pbr tad_id: 32 size: 400\n",
      "-- reg_909.pbr tad_id: 32 size: 400\n",
      "-- reg_910.pbr tad_id: 32 size: 400\n",
      "-- reg_911.pbr tad_id: 32 size: 400\n",
      "-- reg_912.pbr tad_id: 32 size: 400\n",
      "-- reg_913.pbr tad_id: 32 size: 400\n",
      "-- reg_914.pbr tad_id: 32 size: 400\n",
      "-- reg_915.pbr tad_id: 32 size: 400\n",
      "-- reg_916.pbr tad_id: 32 size: 400\n",
      "-- reg_917.pbr tad_id: 32 size: 400\n",
      "-- reg_918.pbr tad_id: 32 size: 400\n",
      "-- reg_919.pbr tad_id: 33 size: 400\n",
      "-- reg_920.pbr tad_id: 33 size: 400\n",
      "-- reg_921.pbr tad_id: 33 size: 400\n",
      "-- reg_922.pbr tad_id: 33 size: 400\n",
      "-- reg_923.pbr tad_id: 33 size: 400\n",
      "-- reg_924.pbr tad_id: 33 size: 340\n",
      "-- reg_925.pbr tad_id: 33 size: 400\n",
      "-- reg_926.pbr tad_id: 33 size: 400\n",
      "-- reg_927.pbr tad_id: 33 size: 400\n",
      "-- reg_928.pbr tad_id: 33 size: 400\n",
      "-- reg_929.pbr tad_id: 33 size: 400\n",
      "-- reg_930.pbr tad_id: 33 size: 400\n",
      "-- reg_931.pbr tad_id: 33 size: 400\n",
      "-- reg_932.pbr tad_id: 33 size: 400\n",
      "-- reg_933.pbr tad_id: 33 size: 400\n",
      "-- reg_934.pbr tad_id: 33 size: 400\n"
     ]
    }
   ],
   "source": [
    "master_folder = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21';\n",
    "report_folder = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400'; # if merged\n",
    "\n",
    "tad_dics, tad_id_dic, reg_len_dic, new_id_dic= Match_TADs(master_folder,\n",
    "                                                          TAD_ref='chr21_TADs.bed', \n",
    "                                                          report_folder=report_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Assign color and cluster id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design from subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading sub_encodings for chr21 small\n"
     ]
    }
   ],
   "source": [
    "# dic for chr21 small sub-encoding scheme\n",
    "import cPickle as pickle\n",
    "print 'loading sub_encodings for chr21 small'\n",
    "chr21_sub_encodings = pickle.load(open(r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/sub_encoding.pkl','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can continue here!\n",
    "region_folder = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21';\n",
    "save_folder = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21';\n",
    "\n",
    "# dic for region -> tad\n",
    "if not 'new_id_dic' in vars():\n",
    "    import cPickle as pickle\n",
    "    print \"-- loading reg-tad-dic\"\n",
    "    new_id_dic = pickle.load(open(region_folder+os.sep+'region_to_TAD.pkl','r'))\n",
    "    reg_id_dic = new_id_dic\n",
    "\n",
    "sub_reg_id_dic = {};\n",
    "for k,v in sorted(new_id_dic.items()):\n",
    "    if k in chr21_sub_encodings.keys():\n",
    "        sub_reg_id_dic[k] = v;\n",
    "\n",
    "# dic for region -> it's length\n",
    "if not 'reg_len_dic' in vars():\n",
    "    import cPickle as pickle\n",
    "    print \"-- loading reg-size-dic\"\n",
    "    reg_len_dic = pickle.load(open(region_folder+os.sep+'region_length.pkl','r'))\n",
    "    reg_size_dic = reg_len_dic\n",
    "\n",
    "sub_reg_size_dic = {};\n",
    "for k,v in sorted(reg_size_dic.items()):\n",
    "    if k in chr21_sub_encodings.keys():\n",
    "        sub_reg_size_dic[k] = v;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Design_Encoding(reg_id_dic, reg_size_dic, size_threshold=200,\n",
    "                    n_color=3,\n",
    "                    n_reg=10, n_hyb=5, min_region_times=2,\n",
    "                    filling_rows=True,\n",
    "                    save=True, save_folder=r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21',\n",
    "                    verbose=True):\n",
    "    '''Design encoding scheme\n",
    "    Inputs:\n",
    "        reg_id_dic: region -> TAD dictionary, dic\n",
    "        reg_size_dic: region -> number of probe dictionary, dic\n",
    "        size_threshold: lower bound for number of probes in each region, int\n",
    "        n_color: number of colors, int\n",
    "        n_reg: number of region per decoding unit, int\n",
    "        n_hyb: number of hybes per decoding unit, int\n",
    "        min_region_times: minimum region appearing times, int\n",
    "        filling_rows: whether I should fill remaining region into last row, bool\n",
    "        save: whether save final result, bool\n",
    "        save_folder: save directory, string\n",
    "        verbose: whether say something!, bool\n",
    "    Output:\n",
    "        reg_encoding: region_number -> color=i, cluster=j, region=k, barcodes->...\n",
    "        hyb_matrix: hybridization matrix, n_reg by n_hyb\n",
    "        assign_regs: matrix of assigning region to clusters, n_color by n_cluster by n_reg\n",
    "        assign_tads: matrix of assigning tad to clusters, n_color by n_cluster by n_reg\n",
    "        '''\n",
    "    # imports\n",
    "    import numpy as np;\n",
    "    \n",
    "    def _TAD_to_Region(reg_id_dic, _reg_size_dic=reg_size_dic, _size_threshold=size_threshold, _verbose=verbose):\n",
    "        '''Function to inverse region->TAD dictionary'''\n",
    "        if _verbose:\n",
    "            print '-- Converting region->TAD dic into TAD->[regions]';\n",
    "            \n",
    "        _tad_to_region = {}\n",
    "        for k, v in reg_id_dic.iteritems():\n",
    "            if value >= 0 and _reg_size_dic[k] > _size_threshold:\n",
    "                _tad_to_region[v] = _tad_to_region.get(v, [])\n",
    "                _tad_to_region[v].append(k)   \n",
    "        _tad_to_region.pop(-1, None);\n",
    "        \n",
    "        if _verbose:\n",
    "            for k,v in sorted(_tad_to_region.items()):\n",
    "                print '---TAD: '+str(k);\n",
    "                print v;\n",
    "                \n",
    "        \n",
    "        return _tad_to_region;\n",
    "\n",
    "    def _Generate_Hyb_Matrix(n_reg=n_reg, n_hyb=n_hyb, min_region_times=min_region_times, _verbose=verbose):\n",
    "        '''Function to generate hybridization matrix\n",
    "        Input: number of regions\n",
    "               number of hybridizations\n",
    "               the minimal time that each region appears. default:1\n",
    "        Output: A hybridization matrix'''\n",
    "        if _verbose:\n",
    "            print '-- Generating hybridization matrix for region='+str(n_reg)+', hyb='+str(n_hyb);        \n",
    "        \n",
    "        # generate all possible all_codess\n",
    "        all_codes =[] # list for all possible binary all_codess\n",
    "        for i in range(2**n_hyb):\n",
    "            hybe_0 = np.zeros(n_hyb,dtype=int)\n",
    "            binrep = [int(c) for c in str(\"{0:#b}\".format(i))[2:]]\n",
    "            #print str(\"{0:#b}\".format(i))[2:]\n",
    "            hybe_0[-len(binrep):]=binrep\n",
    "            all_codes.append(hybe_0)\n",
    "        all_codes = np.array(all_codes)\n",
    "        all_codes = all_codes[np.sum(all_codes,-1)>0]\n",
    "        # Choose candicate codes\n",
    "        _code_sums = np.sum(all_codes,axis=-1) \n",
    "        _code_sums[_code_sums < min_region_times]=np.max(_code_sums)+1 # remove codes that dont satisfy minimal region showup times\n",
    "        _max_region_time = np.sort(_code_sums)[n_reg] # maximum region appearance\n",
    "        if min_region_times == _max_region_time: # Case 1: all regions has the same code\n",
    "            _nchoose = n_reg\n",
    "            _cand_codes = all_codes[_code_sums == _max_region_time];\n",
    "            _sims = []\n",
    "            for _i in range(20000):\n",
    "                _sim = _cand_codes[np.random.choice(range(len(_cand_codes)), _nchoose, replace=False)]\n",
    "                _sims.append(_sim)\n",
    "            _sim_keep = _sims[np.argmin([np.var(np.sum(_sim,axis=0)) for _sim in _sims])]\n",
    "            _hyb_matrix = np.array(list(_sim_keep))\n",
    "        else:  # Case 2: use lower-choose codes first, and then use higher codes\n",
    "            _used_codes = list(all_codes[_code_sums < _max_region_time]) # use up all shorter codes\n",
    "            _nchoose = n_reg-len(_used_codes) # other codes to be chosen\n",
    "            _cand_codes = all_codes[_code_sums == _max_region_time]\n",
    "            _sims = []\n",
    "            for _i in range(20000):\n",
    "                _sim = _cand_codes[np.random.choice(range(len(_cand_codes)), _nchoose, replace=False)]\n",
    "                _sims.append(_sim)\n",
    "            _sim_keep = _sims[np.argmin([np.var(np.sum(_sim,axis=0)) for _sim in _sims])]\n",
    "            _used_codes+=list(_sim_keep)\n",
    "            _hyb_matrix = np.array(_used_codes).astype(np.int)\n",
    "\n",
    "        return _hyb_matrix\n",
    "    \n",
    "    def _Assign_Color(_reg_encodings, _tad_to_region, _n_color=n_color, _verbose=verbose):\n",
    "        if _verbose:\n",
    "            print '-- Assigning colors for all regions';\n",
    "        _reg_colors = [[] for _color in range(_n_color)]\n",
    "        _mode_counter = 0; # used for balancing mode_n results into n categories\n",
    "        for _k,_v in _tad_to_region.iteritems():\n",
    "            for _color in range(_n_color):\n",
    "                _reg_list = _v[(_mode_counter+_color)%_n_color::_n_color];\n",
    "                _reg_colors[_color].append(_reg_list);\n",
    "                for _reg in _reg_list:\n",
    "                    _reg_encodings[_reg]['color'] = _color\n",
    "            _mode_counter += 1;\n",
    "        if _verbose:\n",
    "            for _color in range(_n_color):\n",
    "                lstlen=0\n",
    "                for lst in _reg_colors[_color]:\n",
    "                    lstlen += len(lst)\n",
    "                print '--- Number of regions in color '+str(_color)+':', lstlen\n",
    "        return _reg_encodings, _reg_colors;\n",
    "\n",
    "    def _Assign_Cluster(reg_encodings, reg_colors, n_reg=n_reg, n_color=n_color, \n",
    "                        _filling_rows=filling_rows, _verbose=verbose):\n",
    "        '''Assign regions into clusters'''\n",
    "        from math import ceil\n",
    "        from copy import copy\n",
    "        if _verbose:\n",
    "            print '-- Assigning clusters for all regions';\n",
    "            \n",
    "        # calculate number of clusters in each color\n",
    "        n_cluster = int(ceil(len(reg_encodings)/float(n_color*n_reg)))\n",
    "        # initialize matrix\n",
    "        _assign_regs = -np.ones([n_color, n_cluster, n_reg],dtype=np.int)\n",
    "        # vector to store how many clusters being assgined;\n",
    "        _assigned_cluster_num = [];\n",
    "        for _color in range(n_color):\n",
    "            _rlist = copy(sorted(reg_colors[_color],key=lambda v:-len(v)));\n",
    "            _cluster = 0;\n",
    "            while len(_rlist) >= n_reg:\n",
    "                for _reg in range(n_reg):\n",
    "                    _assign_regs[_color, _cluster, _reg] = _rlist[_reg].pop(0)\n",
    "                    # store into reg_encodings\n",
    "                    reg_encodings[_assign_regs[_color, _cluster, _reg]]['color'] = _color;\n",
    "                    reg_encodings[_assign_regs[_color, _cluster, _reg]]['cluster'] = _cluster;\n",
    "                    reg_encodings[_assign_regs[_color, _cluster, _reg]]['region'] = _reg;\n",
    "                # clean all empty lists\n",
    "                while [] in _rlist:\n",
    "                    _rlist.remove([]);\n",
    "                # sort again\n",
    "                _rlist = sorted(_rlist, key=lambda v:-len(v));\n",
    "                # next cluster\n",
    "                _cluster += 1\n",
    "            # for the left regions, store then in the last row\n",
    "            if _filling_rows:\n",
    "                _assign_regs[_color, _cluster, :len(_rlist)] = np.array(_rlist).reshape(-1) # store the rest\n",
    "                _cluster += 1;\n",
    "                for _reg in range(len(_rlist)):\n",
    "                    reg_encodings[_assign_regs[_color, _cluster, _reg]]['color'] = _color;\n",
    "                    reg_encodings[_assign_regs[_color, _cluster, _reg]]['cluster'] = _cluster;\n",
    "                    reg_encodings[_assign_regs[_color, _cluster, _reg]]['region'] = _reg;    \n",
    "            else:\n",
    "                print '-- region without decoding_barcode:',_rlist;\n",
    "                _left_regs = sum(_rlist,[]);\n",
    "                for _reg in _left_regs:\n",
    "                    reg_encodings[_reg]['color'] = _color;\n",
    "                    reg_encodings[_reg]['cluster'] = None;\n",
    "                    reg_encodings[_reg]['region'] = None;   \n",
    "            _assigned_cluster_num.append(_cluster);\n",
    "            \n",
    "        # Trim _assign_regs if not filling rows:\n",
    "        if not filling_rows:\n",
    "            print \"Number of clusters in each color:\\n\", _assigned_cluster_num;\n",
    "            _assign_regs = _assign_regs[:,:max(_assigned_cluster_num),:];\n",
    "            \n",
    "            \n",
    "        return reg_encodings, _assign_regs;\n",
    "    \n",
    "    def _Assign_Decoding_Barcodes(reg_encodings, assign_regs, hyb_matrix,\n",
    "                                  n_color=n_color, n_reg=n_reg, n_hyb=n_hyb, _verbose=verbose):\n",
    "        '''Assign barcode (orders) used for decoding'''\n",
    "        if _verbose:\n",
    "            print '-- Assigning decoding barcodes.'        \n",
    "        # Sanity check\n",
    "        if np.shape(assign_regs)[0] != n_color or np.shape(assign_regs)[2] != n_reg:\n",
    "            raise EOFError('wrong input dimension!');\n",
    "        # collect number of clusters per color\n",
    "        n_cluster = np.shape(assign_regs)[1];\n",
    "        _barcode_set = 0; # barcode to be assigned\n",
    "        for _color in range(n_color):\n",
    "            for _cluster in range(n_cluster):\n",
    "                if list(assign_regs[_color,_cluster,:]).count(-1) == len(list(assign_regs[_color,_cluster,:])): # if all regions in this cluster unassigned\n",
    "                    print 'pass'\n",
    "                    continue;\n",
    "                for _reg in range(n_reg):\n",
    "                    if assign_regs[_color,_cluster,_reg] >= 0:\n",
    "                        reg_encodings[assign_regs[_color,_cluster,_reg]]['bc_decoding'] = [n_hyb*_barcode_set+ i for i, j in enumerate(hyb_matrix[_reg]) if j == 1]\n",
    "                _barcode_set += 1; # next barcode set (size of n_hyb)\n",
    "        return reg_encodings;\n",
    "    \n",
    "    def _Check_Decoding_Barcodes(reg_encodings, hyb_matrix, _verbose=verbose):\n",
    "        '''Function to check whether decoding barcode works fine'''\n",
    "        if _verbose:\n",
    "            print '--- Checking decoding barcodes.'  \n",
    "        reg_bc_num=hyb_matrix.sum(1).max()\n",
    "        hyb_bc_num=hyb_matrix.sum(0).max()   \n",
    "        bc_list = [];\n",
    "        for k,v in reg_encodings.iteritems():\n",
    "            if v['bc_decoding'] != None:\n",
    "                if len(v['bc_decoding']) > reg_bc_num or len(v['bc_decoding']) <=0:\n",
    "                    print '--- wrong barcode size per region';\n",
    "                    return False\n",
    "                bc_list += v['bc_decoding'];\n",
    "        # record unique barcodes\n",
    "        barcodes, barcode_counts = np.unique(bc_list, return_counts=True)\n",
    "        print barcodes\n",
    "        # check barcode usage per hybe\n",
    "        validate = False not in [n<=hyb_bc_num and n>0 for n in barcode_counts]\n",
    "        print '---', validate\n",
    "        return validate\n",
    "\n",
    "    def _Assign_TAD_Barcodes(reg_encodings, _verbose=verbose):\n",
    "        '''Assign barcode (orders) used for TAD identity'''\n",
    "        if _verbose:\n",
    "            print '-- Assigning TAD barcodes.' \n",
    "        # record all decoding barcodes\n",
    "        dec_bcs = []\n",
    "        for k,v in reg_encodings.iteritems():\n",
    "            if v['bc_decoding'] != None:\n",
    "                dec_bcs += v['bc_decoding']\n",
    "        # tad barcodes should start right after\n",
    "        tad_bc_start = max(dec_bcs)+1; \n",
    "        for k,v in reg_encodings.iteritems():\n",
    "            if v['TAD']>=0:\n",
    "                reg_encodings[k]['bc_tad'] = reg_encodings[k]['TAD'] + tad_bc_start;\n",
    "        \n",
    "        return reg_encodings\n",
    "        \n",
    "            \n",
    "    def _Assign_Unique_Barcodes(reg_encodings, _verbose=verbose):\n",
    "        '''Assign barcode (orders) used for unique sequential'''\n",
    "        if _verbose:\n",
    "            print '-- Assigning unique barcodes.'\n",
    "        # record all decoding barcodes and TAD barcodes\n",
    "        used_bcs = []\n",
    "        for k,v in reg_encodings.iteritems():\n",
    "            if v['bc_decoding'] != None:\n",
    "                used_bcs += v['bc_decoding']\n",
    "            used_bcs += [v['bc_tad']]\n",
    "        # unique barcodes should start right after\n",
    "        unique_bc_start = max(used_bcs); \n",
    "        reg_new_id = 1;\n",
    "        for k,v in sorted(reg_encodings.items()):\n",
    "            reg_encodings[k]['bc_unique'] = reg_new_id + unique_bc_start;\n",
    "            reg_encodings[k]['id'] = reg_new_id;\n",
    "            reg_new_id += 1;\n",
    "        \n",
    "        return reg_encodings  \n",
    "    \n",
    "    \n",
    "    # Initialize\n",
    "    if verbose:\n",
    "        print \"- Initializing\";\n",
    "    reg_encodings = {};\n",
    "    for key, value in reg_id_dic.items():\n",
    "        if value >= 0 and reg_size_dic[key] >= size_threshold: \n",
    "            reg_encodings[key] = {'TAD':value, 'id':None, 'color':None, \\\n",
    "                                  'cluster':None, 'region': None, \\\n",
    "                                  'bc_decoding':None,\\\n",
    "                                  'bc_tad':None, 'bc_unique':None}\n",
    "    \n",
    "\n",
    "    # creat tad to region dictionary\n",
    "    if verbose:\n",
    "        print \"- Inverting region_to_tad dictionary\";\n",
    "    tad_to_region = _TAD_to_Region(reg_id_dic);\n",
    "    \n",
    "    # generate hybe matrix\n",
    "    if verbose:\n",
    "        print \"- Prepare hyb matrix\";\n",
    "    hyb_matrix = _Generate_Hyb_Matrix()\n",
    "    \n",
    "    if verbose:\n",
    "        print \"- Calculate color, cluster assignment\";    \n",
    "    # assign colors\n",
    "    reg_encodings , reg_colors = _Assign_Color(reg_encodings, tad_to_region);\n",
    "    # assign cluster\n",
    "    reg_encodings, assign_regs = _Assign_Cluster(reg_encodings, reg_colors);\n",
    "\n",
    "    \n",
    "    if verbose:\n",
    "        print \"- Assign barcodes\";    \n",
    "    # assign decoding barcodes\n",
    "    reg_encodings = _Assign_Decoding_Barcodes(reg_encodings, assign_regs, hyb_matrix)\n",
    "    # check decoding barcodes\n",
    "    decoding_check = _Check_Decoding_Barcodes(reg_encodings, hyb_matrix)\n",
    "    # assign TAD barcodes\n",
    "    reg_encodings = _Assign_TAD_Barcodes(reg_encodings)\n",
    "    # assign unique barcodes\n",
    "    reg_encodings = _Assign_Unique_Barcodes(reg_encodings)    \n",
    "    \n",
    "    \n",
    "    if save:\n",
    "        import cPickle as pickle\n",
    "        import os\n",
    "        # mkdir if not exist for save folder\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "        save_filename = save_folder + os.sep + 'total_encoding.pkl';\n",
    "        if verbose:\n",
    "            print \"- Save to file:\", save_filename\n",
    "        savefile = open(save_filename, 'w');\n",
    "        pickle.dump(reg_encodings, savefile)\n",
    "        \n",
    "    return reg_encodings, hyb_matrix, assign_regs\n",
    "\n",
    "    \n",
    "def Design_Noncoding_Sequential(reg_id_dic, reg_size_dic, threshold=200,\n",
    "                                n_color=3, save=True, verbose=True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Initializing\n",
      "- Inverting region_to_tad dictionary\n",
      "-- Converting region->TAD dic into TAD->[regions]\n",
      "---TAD: 1\n",
      "[266, 281, 299, 303, 307, 309, 312, 316, 317]\n",
      "---TAD: 2\n",
      "[319, 320, 338, 339, 350, 352, 359, 360]\n",
      "---TAD: 3\n",
      "[362, 364, 380, 384, 391, 393, 399, 403, 407, 408, 413, 414]\n",
      "---TAD: 4\n",
      "[419, 420, 438, 442, 447, 452, 458, 459, 466, 467, 472, 473, 477, 478, 480]\n",
      "---TAD: 5\n",
      "[483, 484, 506, 508, 509]\n",
      "---TAD: 6\n",
      "[514, 516, 520, 527, 528, 530]\n",
      "---TAD: 7\n",
      "[542, 543, 551, 553]\n",
      "---TAD: 8\n",
      "[556, 557, 567, 574, 575, 577]\n",
      "---TAD: 9\n",
      "[585, 587]\n",
      "---TAD: 10\n",
      "[590, 591, 609, 613, 616]\n",
      "---TAD: 11\n",
      "[622, 630, 632]\n",
      "---TAD: 12\n",
      "[635, 645]\n",
      "---TAD: 13\n",
      "[651, 653]\n",
      "---TAD: 14\n",
      "[660, 662, 663, 665, 667]\n",
      "---TAD: 15\n",
      "[674, 676]\n",
      "---TAD: 16\n",
      "[683, 684, 688]\n",
      "---TAD: 17\n",
      "[689, 693]\n",
      "---TAD: 18\n",
      "[694, 696, 713, 718, 723]\n",
      "---TAD: 19\n",
      "[725, 727, 728]\n",
      "---TAD: 20\n",
      "[729, 733, 735, 736, 740, 741]\n",
      "---TAD: 21\n",
      "[748, 750, 752, 753]\n",
      "---TAD: 22\n",
      "[756, 762, 764]\n",
      "---TAD: 23\n",
      "[775, 782, 785, 789]\n",
      "---TAD: 24\n",
      "[790, 792, 808, 818]\n",
      "---TAD: 25\n",
      "[826, 827, 830, 832]\n",
      "---TAD: 26\n",
      "[838, 842, 845, 849]\n",
      "---TAD: 27\n",
      "[853, 855, 857]\n",
      "---TAD: 28\n",
      "[872, 867]\n",
      "---TAD: 29\n",
      "[877, 881, 882]\n",
      "---TAD: 30\n",
      "[884, 894, 895]\n",
      "---TAD: 31\n",
      "[899, 901, 903]\n",
      "---TAD: 32\n",
      "[905, 909, 912, 916]\n",
      "---TAD: 33\n",
      "[931, 920, 924, 927]\n",
      "- Prepare hyb matrix\n",
      "-- Generating hybridization matrix for region=21, hyb=7\n",
      "- Calculate color, cluster assignment\n",
      "-- Assigning colors for all regions\n",
      "--- Number of regions in color 0: 49\n",
      "--- Number of regions in color 1: 50\n",
      "--- Number of regions in color 2: 51\n",
      "-- Assigning clusters for all regions\n",
      "-- region without decoding_barcode: [[458, 467, 477], [407, 414], [312], [360]]\n",
      "-- region without decoding_barcode: [[459, 472, 478], [399, 408], [316], [901], [912]]\n",
      "-- region without decoding_barcode: [[466, 473, 480], [403, 413], [317], [359], [903], [920]]\n",
      "Number of clusters in each color:\n",
      "[2, 2, 2]\n",
      "- Assign barcodes\n",
      "-- Assigning decoding barcodes.\n",
      "--- Checking decoding barcodes.\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41]\n",
      "--- True\n",
      "-- Assigning TAD barcodes.\n",
      "-- Assigning unique barcodes.\n",
      "- Save to file: /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21/total_encoding.pkl\n"
     ]
    }
   ],
   "source": [
    "reg_encodings, hyb_matrix, assign_regs = Design_Encoding(reg_id_dic=sub_reg_id_dic, reg_size_dic=sub_reg_size_dic, \n",
    "                                                         n_hyb=7, n_reg=21, filling_rows=False, \n",
    "                                                         save_folder=region_folder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[419, 380, 266, 320, 484, 520, 542, 557, 590, 662, 733, 826, 630,\n",
       "         651, 683, 693, 713, 725, 752, 756, 782],\n",
       "        [442, 393, 303, 350, 509, 530, 553, 575, 613, 667, 740, 832, 808,\n",
       "         842, 857, 872, 881, 895, 899, 909, 924]],\n",
       "\n",
       "       [[420, 362, 281, 338, 514, 567, 591, 694, 735, 748, 790, 931, 506,\n",
       "         543, 585, 632, 635, 653, 663, 674, 684],\n",
       "        [447, 384, 307, 352, 527, 577, 616, 718, 741, 753, 818, 927, 727,\n",
       "         762, 785, 827, 845, 853, 867, 882, 884]],\n",
       "\n",
       "       [[438, 364, 299, 319, 483, 516, 556, 660, 696, 729, 775, 838, 905,\n",
       "         551, 587, 609, 622, 645, 676, 688, 689],\n",
       "        [452, 391, 309, 339, 508, 528, 574, 665, 723, 736, 789, 849, 916,\n",
       "         728, 750, 764, 792, 830, 855, 877, 894]]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_regs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Design sub library encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Sub_Library_Encoding(total_encoding, hyb_matrix, assign_regs, reg_id_dic,\n",
    "                         sub_library_size,\n",
    "                         min_reg_in_tad=2, \n",
    "                         save=True, save_folder=r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21',\n",
    "                         continue_num=False,\n",
    "                         verbose=True):\n",
    "    '''Extract a sub library for total library and redesign encodings\n",
    "    Inputs:\n",
    "        _reg_encoding: region_number -> color=i, cluster=j, region=k, barcodes->...\n",
    "        hyb_matrix: hybridization matrix, n_reg by n_hyb\n",
    "        assign_regs: matrix of assigning region to clusters, n_color by n_cluster by n_reg\n",
    "        reg_id_dic: dictionary for region -> tad, dic\n",
    "        sub_library_size: number of regions in the sub library, int\n",
    "        min_reg_in_tad: criteria for selecting sub library, at least 2 regions in each new tad, int\n",
    "        save: whether save, bool\n",
    "        save_folder: directory for saving, str\n",
    "        continue_num: whether barcode id numbered continuously, False/'tad'/'decoding'/'all'\n",
    "        verbose: whether say something!, bool\n",
    "    Outputs:\n",
    "        sub_encodings: encoding scheme for sub library\n",
    "        other_encodings: encoding scheme for the rest of library\n",
    "    '''\n",
    "    # imports\n",
    "    import numpy as np;\n",
    "    \n",
    "    def _TAD_in_Cluster(_assign_regs, reg_id_dic=reg_id_dic, _verbose=verbose):\n",
    "        # input parameters\n",
    "        n_color = _assign_regs.shape[0]; # number of colors\n",
    "        n_cluster = _assign_regs.shape[1]; # number of clusters per color\n",
    "        n_reg = _assign_regs.shape[2]; # number of regions, defined by hyb matrix\n",
    "        \n",
    "        _assign_tads = -np.ones(np.shape(_assign_regs), dtype=np.int)\n",
    "        for _color in range(n_color):\n",
    "            for _cluster in range(n_cluster):\n",
    "                for _reg in range(n_reg):\n",
    "                    if _assign_regs[_color, _cluster, _reg] >= 0:\n",
    "                        _assign_tads[_color, _cluster, _reg] = reg_id_dic[_assign_regs[_color, _cluster, _reg]]\n",
    "        \n",
    "        return _assign_tads;\n",
    "    \n",
    "    def _Select_Sub_Encodings(total_encoding=total_encoding, assign_regs=assign_regs, \n",
    "                              sub_library_size=sub_library_size, min_reg_in_tad=min_reg_in_tad,\n",
    "                              _verbose=verbose):\n",
    "        from math import ceil\n",
    "        \n",
    "        if _verbose:\n",
    "            print \"-- Starting sub library searching\";\n",
    "        # convert assign_cluster into assign_tad\n",
    "        assign_tads = _TAD_in_Cluster(assign_regs);\n",
    "\n",
    "        # record parameters\n",
    "        n_color = assign_regs.shape[0]; # number of colors\n",
    "        n_cluster = assign_regs.shape[1]; # number of clusters per color\n",
    "        n_reg = assign_regs.shape[2]; # number of regions, defined by hyb matrix\n",
    "        _select_clusters = int(sub_library_size / n_reg) # number total selected clusters (in all colors)\n",
    "        if _verbose:\n",
    "            print \"--- color: \"+str(n_color), \"cluster: \"+str(n_cluster), \"region: \"+str(n_reg), \"selected clusters: \"+str(_select_clusters)\n",
    "        # Split select clusters in different colors equally\n",
    "        n_chooses = []\n",
    "        for i in range(n_color):\n",
    "            _choose =  int(ceil((_select_clusters-sum(n_chooses)) / float(n_color-i)));\n",
    "            n_chooses.append(_choose)\n",
    "        n_chooses = sorted(n_chooses)\n",
    "        n_chooses.reverse()\n",
    "        if _verbose:\n",
    "            print \"--- Choosing from each color:\", n_chooses;\n",
    "        # Randomly generate region picking\n",
    "        j=0\n",
    "        min_reg = -1;\n",
    "        while min_reg < min_reg_in_tad:\n",
    "            _cids = []; # chosen id list\n",
    "            _ctads = []; # chosen tad matrix parts\n",
    "            for i in range(n_color):\n",
    "                # chosen ids\n",
    "                _cids.append([sorted(np.random.choice(n_cluster-1, n_chooses[i], replace=False))])\n",
    "                # chosen tads\n",
    "                _ctads.append(assign_tads[i, _cids[i], :]);\n",
    "                # get unique set\n",
    "                _tads, _cts = np.unique(np.concatenate(_ctads,1), return_counts=True);\n",
    "            # start updating once all TADs show up\n",
    "            if len(_tads) == len(np.unique(assign_tads[:,:-1,:])): \n",
    "                min_reg = np.min(_cts) # the minimum occurance of TADs\n",
    "            elif min_reg_in_tad==0:\n",
    "                min_reg = np.min(_cts) # the minimum occurance of TADs\n",
    "            j+=1;\n",
    "        if _verbose:\n",
    "            print \"--- Number of searches:\", j;\n",
    "            print \"-- Finishing library searching, constructing sub library\";\n",
    "        \n",
    "        # Storing information into reg matrix\n",
    "        _sub_regs = -np.ones([n_color, n_chooses[0], n_reg]);\n",
    "        _other_regs = -np.ones([n_color, n_cluster-n_chooses[-1], n_reg]);\n",
    "        for _color in range(n_color):\n",
    "            _sub_regs[_color,:n_chooses[_color],:] = assign_regs[_color, _cids[_color],:] # sub region\n",
    "            _oid = list(set(np.arange(n_cluster)) - set(sorted(np.random.choice(22,5,replace=False)))) #other region\n",
    "            _other_regs[_color,:len(_oid),:] = assign_regs[_color, _oid, :];\n",
    "        \n",
    "        # Initialize encoding region list\n",
    "        _sub_encodings, _other_encodings = {},{};\n",
    "        for _r in np.unique(_sub_regs):\n",
    "            if _r >=0:\n",
    "                #_sub_encodings[int(_r)] = total_encoding[int(_r)];\n",
    "                _sub_encodings[int(_r)] = {'TAD':total_encoding[int(_r)]['TAD'],\n",
    "                                           'color':total_encoding[int(_r)]['color'],\n",
    "                                           'cluster':None,\n",
    "                                           'id':None,\n",
    "                                           'region':total_encoding[int(_r)]['region'],\n",
    "                                           'bc_decoding':None, 'bc_tad':None, 'bc_unique':None}\n",
    "        for _r in np.unique(_other_regs):\n",
    "            if _r >=0:\n",
    "                #_other_encodings[int(_r)] = total_encoding[int(_r)];   \n",
    "                _other_encodings[int(_r)] = {'TAD':total_encoding[int(_r)]['TAD'],\n",
    "                                             'color':total_encoding[int(_r)]['color'],\n",
    "                                             'cluster':None,\n",
    "                                             'id':None,\n",
    "                                             'region':total_encoding[int(_r)]['region'],\n",
    "                                             'bc_decoding':None, 'bc_tad':None, 'bc_unique':None}\n",
    "\n",
    "        return _sub_encodings, _sub_regs, _other_encodings, _other_regs\n",
    "    \n",
    "    \n",
    "    def _Assign_All_Barcodes(_reg_encodings, _assign_regs, _hyb_matrix=hyb_matrix, \n",
    "                             _continue_num=continue_num, _verbose=verbose):\n",
    "        '''Assembled function to update all barcodes'''\n",
    "        # record parameters\n",
    "        n_color = _assign_regs.shape[0]; # number of colors\n",
    "        n_cluster = _assign_regs.shape[1]; # number of clusters per color\n",
    "        n_reg = _assign_regs.shape[2]; # number of regions per cluster, defined by hyb matrix\n",
    "        n_hyb = _hyb_matrix.shape[1]; # number of hybes per cluster\n",
    "        if _verbose:\n",
    "            print \"--- color: \"+str(n_color), \"cluster: \"+str(n_cluster), \"region: \"+str(n_reg),\\\n",
    "                \"hybs: \"+str(n_hyb);\n",
    "        def _Assign_Decoding_Barcodes(_reg_encodings, _assign_regs=_assign_regs, _hyb_matrix=_hyb_matrix,\n",
    "                                      n_color=n_color, n_cluster=n_cluster, \n",
    "                                      n_reg=n_reg, n_hyb=n_hyb, _verbose=verbose):\n",
    "            '''Assign barcode (orders) used for decoding'''\n",
    "            if _verbose:\n",
    "                print '-- Assigning decoding barcodes.'        \n",
    "            # Sanity check\n",
    "            if np.shape(_assign_regs)[0] != n_color or np.shape(_assign_regs)[2] != n_reg:\n",
    "                raise EOFError('wrong input dimension!');\n",
    "            # collect number of clusters per color\n",
    "            _barcode_set = 0; # barcode to be assigned\n",
    "            for _color in range(n_color):\n",
    "                for _cluster in range(n_cluster):\n",
    "                    for _reg in range(n_reg):\n",
    "                        if _assign_regs[_color,_cluster,_reg] >= 0:\n",
    "                            _reg_encodings[_assign_regs[_color,_cluster,_reg]]['cluster'] = _cluster\n",
    "                            _reg_encodings[_assign_regs[_color,_cluster,_reg]]['bc_decoding'] = [n_hyb*_barcode_set+i for i, j in enumerate(_hyb_matrix[_reg]) if j == 1]\n",
    "                            #print [n_hyb*_barcode_set+i for i, j in enumerate(_hyb_matrix[_reg]) if j == 1]\n",
    "                    _barcode_set += 1; # next barcode set (size of n_hyb)\n",
    "            return _reg_encodings;\n",
    "\n",
    "        def _Assign_TAD_Barcodes(_reg_encodings, _continue_num=_continue_num, _verbose=verbose):\n",
    "            '''Assign barcode (orders) used for TAD identity'''\n",
    "            if _verbose:\n",
    "                print '-- Assigning TAD barcodes.' \n",
    "            # record all decoding barcodes\n",
    "            dec_bcs = []\n",
    "            for k,v in _reg_encodings.iteritems():\n",
    "                dec_bcs += v['bc_decoding']\n",
    "            # tad barcodes should start right after\n",
    "            if _continue_num == 'all':\n",
    "                tad_bc_start = max(dec_bcs)+1; \n",
    "            else:\n",
    "                tad_bc_start = 0;\n",
    "            for k,v in _reg_encodings.iteritems():\n",
    "                if v['TAD']>=0:\n",
    "                    _reg_encodings[k]['bc_tad'] = _reg_encodings[k]['TAD'] + tad_bc_start;\n",
    "\n",
    "            return _reg_encodings\n",
    "\n",
    "        def _Assign_Unique_Barcodes(_reg_encodings, _continue_num=_continue_num, _verbose=verbose):\n",
    "            '''Assign barcode (orders) used for unique sequential'''\n",
    "            if _verbose:\n",
    "                print '-- Assigning unique barcodes.'\n",
    "\n",
    "            # unique barcodes should start right after\n",
    "            if _continue_num == 'tad':\n",
    "                # record decoding TAD barcodes\n",
    "                used_bcs = []\n",
    "                for k,v in _reg_encodings.iteritems():\n",
    "                    used_bcs += [v['bc_tad']]\n",
    "                unique_bc_start = max(used_bcs)+1; \n",
    "            elif _continue_num == 'decoding':\n",
    "                # record decoding barcodes barcodes\n",
    "                used_bcs = []\n",
    "                for k,v in _reg_encodings.iteritems():\n",
    "                    used_bcs += v['bc_decoding']\n",
    "                unique_bc_start = max(used_bcs)+1; \n",
    "            elif  _continue_num == 'all':              \n",
    "                # record all decoding barcodes and TAD barcodes\n",
    "                used_bcs = []\n",
    "                for k,v in _reg_encodings.iteritems():\n",
    "                    used_bcs += v['bc_decoding']\n",
    "                    used_bcs += [v['bc_tad']]\n",
    "                unique_bc_start = max(used_bcs)+1; \n",
    "            else:\n",
    "                unique_bc_start = 0\n",
    "                \n",
    "            reg_new_id = 0;\n",
    "            for k,v in sorted(_reg_encodings.items()):\n",
    "                _reg_encodings[k]['bc_unique'] = reg_new_id + unique_bc_start;\n",
    "                _reg_encodings[k]['id'] = reg_new_id;\n",
    "                reg_new_id += 1;\n",
    "\n",
    "            return _reg_encodings  \n",
    "        \n",
    "        # assign decoding barcodes\n",
    "        _reg_encodings = _Assign_Decoding_Barcodes(_reg_encodings)\n",
    "        # assign TAD barcodes\n",
    "        _reg_encodings = _Assign_TAD_Barcodes(_reg_encodings, _continue_num=_continue_num)\n",
    "        # assign unique barcodes\n",
    "        _reg_encodings = _Assign_Unique_Barcodes(_reg_encodings, _continue_num=_continue_num)    \n",
    "    \n",
    "        return _reg_encodings\n",
    "    \n",
    "    \n",
    "    # Select sub library\n",
    "    if verbose:\n",
    "        print \"- Select sub library.\"\n",
    "    sub_encodings, sub_regs, other_encodings, other_regs= _Select_Sub_Encodings()\n",
    "    # Re_assign barcodes\n",
    "    if verbose:\n",
    "        print \"- Reassign barcodes for sub library.\"\n",
    "        print \"-- continue numbering:\", continue_num;\n",
    "    sub_encodings = _Assign_All_Barcodes(sub_encodings, sub_regs);\n",
    "    if verbose:\n",
    "        print \"- Reassign barcodes for the rest of library.\"\n",
    "        print \"-- continue numbering:\", continue_num;\n",
    "    other_encodings = _Assign_All_Barcodes(other_encodings, other_regs);    \n",
    "    \n",
    "    if save:\n",
    "        import cPickle as pickle\n",
    "        import os\n",
    "        sub_filename = save_folder + os.sep + 'sub_encoding.pkl';\n",
    "        other_filename = save_folder + os.sep + 'other_encoding.pkl';\n",
    "        if verbose:\n",
    "            print \"- Save to file:\", sub_filename, other_filename\n",
    "        # save\n",
    "        pickle.dump(sub_encodings, open(sub_filename,'w'))\n",
    "        pickle.dump(other_encodings, open(other_filename,'w'))\n",
    "    \n",
    "    return sub_encodings, other_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21\n",
      "- Select sub library.\n",
      "-- Starting sub library searching\n",
      "--- color: 3 cluster: 2 region: 21 selected clusters: 2\n",
      "--- Choosing from each color: [1, 1, 0]\n",
      "--- Number of searches: 1\n",
      "-- Finishing library searching, constructing sub library\n",
      "- Reassign barcodes for sub library.\n",
      "-- continue numbering: tad\n",
      "--- color: 3 cluster: 1 region: 21 hybs: 7\n",
      "-- Assigning decoding barcodes.\n",
      "-- Assigning TAD barcodes.\n",
      "-- Assigning unique barcodes.\n",
      "- Reassign barcodes for the rest of library.\n",
      "-- continue numbering: tad\n",
      "--- color: 3 cluster: 2 region: 21 hybs: 7\n",
      "-- Assigning decoding barcodes.\n",
      "-- Assigning TAD barcodes.\n",
      "-- Assigning unique barcodes.\n",
      "- Save to file: /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21/sub_encoding.pkl /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21/other_encoding.pkl\n"
     ]
    }
   ],
   "source": [
    "print region_folder\n",
    "sub_encodings, other_encodings = Sub_Library_Encoding(reg_encodings, hyb_matrix, assign_regs, reg_id_dic, 42, \n",
    "                                                      min_reg_in_tad=0,\n",
    "                                                      continue_num='tad',\n",
    "                                                      save_folder=region_folder);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Patch Barcode Sequence to Reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimal imports for biopython\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import os,glob,time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Read barcode Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barcodes loaded: Stv: 21, NDB: 1052\n"
     ]
    }
   ],
   "source": [
    "# read all Stv barcodes\n",
    "barcode_dir = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Barcodes';\n",
    "\n",
    "#stv_adaptor = [1,2,17,62,77,78,79,80,81,82,83,84] # barcodes saved for adaptors\n",
    "#stv_bad = [34,38,41] # barcodes performed badly\n",
    "#stv_mask = stv_adaptor + stv_bad \n",
    "stv_mask = []\n",
    "\n",
    "with open(barcode_dir+os.sep+'top_Stvs_select21.fasta', \"rU\") as handle:\n",
    "    stv_barcodes = [];\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        if int(record.id.split('_')[1]) not in stv_mask:\n",
    "            stv_barcodes.append(record);\n",
    "\n",
    "# read all NDB barcodes\n",
    "ndb_mask = [];\n",
    "\n",
    "with open(barcode_dir+os.sep+'NDBs.fasta', \"rU\") as handle:\n",
    "    ndb_barcodes = [];\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        if int(record.id.split('_')[1]) not in ndb_mask:\n",
    "            ndb_barcodes.append(record);\n",
    "print \"Barcodes loaded: Stv: \"+str(len(stv_barcodes))+\", NDB: \"+str(len(ndb_barcodes));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Read all PCR primers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primers loaded: forward: 12, reverse: 9\n"
     ]
    }
   ],
   "source": [
    "primer_dir = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Primers';\n",
    "fwd_primer_filename = 'forward_primers_keep.fasta';\n",
    "rev_primer_filename = 'reverse_primers_keep.fasta';\n",
    "\n",
    "# read all forward primers\n",
    "with open(primer_dir+os.sep+fwd_primer_filename, \"rU\") as handle:\n",
    "    fwd_primers = [];\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        fwd_primers.append(record);\n",
    "# read all forward primers\n",
    "with open(primer_dir+os.sep+rev_primer_filename, \"rU\") as handle:\n",
    "    rev_primers = [];\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        rev_primers.append(record);\n",
    "print \"Primers loaded: forward: \"+str(len(fwd_primers))+\", reverse: \"+str(len(rev_primers));        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 read all probe reports and generate primary probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- forward primer: ID: W1A03_primer_2\n",
      "Name: W1A03_primer_2\n",
      "Description: W1A03_primer_2\n",
      "Number of features: 0\n",
      "Seq('CCCGCAATGGCTGACAACCG', SingleLetterAlphabet())\n",
      "- reverse primer: ID: W1A10_primer_9\n",
      "Name: W1A10_primer_9\n",
      "Description: W1A10_primer_9\n",
      "Number of features: 0\n",
      "Seq('TAATACGACTCACTATAGGGATTGCCGCATGGTTTCCG', SingleLetterAlphabet())\n"
     ]
    }
   ],
   "source": [
    "# Important inputs for patching barcodes\n",
    "barcode_source = {'bc_unique':'ndb',\n",
    "                  'bc_decoding':'stv'};\n",
    "barcode_order = ['bc_decoding', 'bc_unique'];\n",
    "\n",
    "# master directory\n",
    "master_dir =r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21';\n",
    "report_folder = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400'; # if merged\n",
    "save_folder = r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21/final_probes'; # if merged\n",
    "\n",
    "# primer sets\n",
    "fprimer = fwd_primers[1];\n",
    "print '- forward primer:', fprimer\n",
    "rprimer = rev_primers[4];\n",
    "print '- reverse primer:', rprimer\n",
    "\n",
    "# dic for sub-encoding scheme\n",
    "if not 'sub_encodings' in vars():\n",
    "    import cPickle as pickle\n",
    "    print 'loading sub_encodings'\n",
    "    sub_encodings = pickle.load(open(master_dir+os.sep+'sub_encoding.pkl','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Patch_Barcodes(reg_encodings, \n",
    "                   fwd_primer,rev_primer,\n",
    "                   barcode_source, \n",
    "                   barcode_order,\n",
    "                   stv_barcodes, ndb_barcodes, barcode_starts={'stv':1,'ndb':1},\n",
    "                   report_folder=r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged',\n",
    "                   save_folder=r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/final_probes',\n",
    "                   add_rand_gap=0,\n",
    "                   save=True, verbose=True):\n",
    "    '''Function to patch barcodes to designed probes\n",
    "    Inputs:\n",
    "        reg_encodings: encoding scheme for the barcode, dictionary(generated previously)\n",
    "        fwd_primer: forward primer,20mer, biopython SeqRecord\n",
    "        rev_primer: reverse primer,40mer(rc), last 20mer-rc should be used\n",
    "        barcode_source: dictionary to determine the source of barcodes, dictionary\n",
    "        barcode_order: list to determine numbering order of barcodes, list\n",
    "        stv_barcodes: old barcodes,30mer, biopython SeqRecord list\n",
    "        ndb_barcodes: new barcodes,30mer, biopython SeqRecord list\n",
    "        barcode_starts: id of the first unused barcode, dictionary\n",
    "        report_folder: directory for probe reports, string\n",
    "        save_folder: directory for save files, string\n",
    "        add_rand_gap: whether adding (or length) of random gaps between barcodes, int\n",
    "        save: whether save, bool\n",
    "        verbose: whether say something, bool\n",
    "    Outputs:\n",
    "        total library SeqRecord\n",
    "        '''\n",
    "    # minimal imports\n",
    "    from Bio import SeqIO\n",
    "    from Bio.Seq import Seq\n",
    "    from Bio.Alphabet import IUPAC\n",
    "    from Bio.SeqRecord import SeqRecord \n",
    "    import numpy as np;\n",
    "    import glob, os, sys, time\n",
    "    import LibraryDesigner as ld\n",
    "    \n",
    "    # check inputs:\n",
    "    if verbose:\n",
    "        print \"- Check inputs\"\n",
    "    # check barcode_source\n",
    "    barcode_types = reg_encodings.values()[0].keys();\n",
    "    for k, v in barcode_source.iteritems():\n",
    "        if k not in barcode_types:\n",
    "            raise ValueError('wrong barcode_source input!');\n",
    "    # check barcode_order\n",
    "    for _name in barcode_order:\n",
    "        if _name not in barcode_types:\n",
    "            raise ValueError('wrong barcode_order input!');\n",
    "            \n",
    "    # filter stv_barcodes and ndb_barcodes\n",
    "    if verbose:\n",
    "        print \"- check barcode starts: \", barcode_starts\n",
    "    _stv_barcodes, _ndb_barcodes = [],[];\n",
    "    for record in stv_barcodes:\n",
    "        if not int(record.id.split('_')[1]) < barcode_starts['stv']:\n",
    "            _stv_barcodes.append(record)\n",
    "    for record in ndb_barcodes:\n",
    "        if not int(record.id.split('_')[1]) < barcode_starts['ndb']:\n",
    "            _ndb_barcodes.append(record)\n",
    "    \n",
    "    def _generating_file_encoding(_report_folder=report_folder, \n",
    "                                  _reg_encodings=reg_encodings, _verbose=verbose):\n",
    "        '''Convert region id encoding scheme into filename encoding scheme, change keys\n",
    "        Inputs: \n",
    "            report_folder\n",
    "            reg_encodings\n",
    "            verbose\n",
    "        Output:\n",
    "            pb_files\n",
    "            file_encodings'''\n",
    "        # load probe reports:\n",
    "        _pb_files = [fl for fl in glob.glob(_report_folder+os.sep+r'*.pbr') if int(os.path.basename(fl).split('_')[1].split('.')[0]) in _reg_encodings.keys()]\n",
    "        if _verbose:\n",
    "            print \"- Load probe reports, total_num:\", len(_pb_files);\n",
    "        # save to file_encodings\n",
    "        _file_encodings = {};\n",
    "        for fl in _pb_files:\n",
    "            _file_encodings[fl] = _reg_encodings[int(os.path.basename(fl).split('_')[1].split('.')[0])];\n",
    "        \n",
    "        return _pb_files, _file_encodings;\n",
    "    \n",
    "\n",
    "    \n",
    "    def _patch_barcode_per_file(_file, _file_encodings, \n",
    "                                _fwd_primer=fwd_primer, _rev_primer=rev_primer,\n",
    "                                _barcode_source=barcode_source, _stv_barcodes=stv_barcodes, _ndb_barcodes=ndb_barcodes,\n",
    "                                _add_rand_gap=add_rand_gap, _verbose=verbose):\n",
    "        from random import choice\n",
    "        import os\n",
    "        if _verbose:\n",
    "            print \"-- patch barcodes :\", _file\n",
    "        # load probe report\n",
    "        _pb = ld.pb_reports_class()\n",
    "        _pb.load_pbr(_file)\n",
    "        \n",
    "        # extract encoding info:\n",
    "        _encoding = _file_encodings[_file];\n",
    "        \n",
    "        # initialize, save all infos here\n",
    "        _plist = [];\n",
    "        _precords = [];\n",
    "        for _info in _pb.pb_reports_keep.values():\n",
    "            _tmp_info = _info.copy();\n",
    "\n",
    "            # extract all encoding info from reg_encodings\n",
    "            _tmp_info['reg_index'] = _encoding['id']\n",
    "            _tmp_info['color'] = _encoding['color']\n",
    "            if 'gene' in _encoding.keys():\n",
    "                _tmp_info['gene'] = _encoding['gene']\n",
    "\n",
    "            # extract barcode info\n",
    "            _islist = False; # variable used for later design\n",
    "            for _k,_v in _barcode_source.iteritems():\n",
    "                if isinstance(_encoding[_k], list):\n",
    "                    _islist = _k; # variable used for later design\n",
    "                    _bcs = [];\n",
    "                    for _bid in _encoding[_k]:\n",
    "                        if _v == 'stv':\n",
    "                            _bcs.append(_stv_barcodes[_bid]);\n",
    "                        elif _v == 'ndb':\n",
    "                            _bcs.append(_ndb_barcodes[_bid]);\n",
    "                    _tmp_info[_k] = _bcs;\n",
    "                else:\n",
    "                    if _v == 'stv':\n",
    "                        _tmp_info[_k] =_stv_barcodes[_encoding[_k]];\n",
    "                    elif _v == 'ndb':\n",
    "                        _tmp_info[_k] =_ndb_barcodes[_encoding[_k]];\n",
    "            # extract primer info:\n",
    "            _tmp_info['fwd_primer'] = _fwd_primer;\n",
    "            _tmp_info['rev_primer'] = _rev_primer;\n",
    "\n",
    "            ## generate_whole sequence\n",
    "            # fwd_primer(20)\n",
    "            # barcode 1 [from list, 1], (reverse-complement of last 20)\n",
    "            # barcode 2, (reverse-complement of last 20)\n",
    "            # target sequence\n",
    "            # barcode 3, (reverse-complement of last 20)\n",
    "            # barcode 4 [from list, 1], (reverse-complement of last 20)\n",
    "            # rev_primer, (reverse-complement of last 20)\n",
    "            _seq_list = []; # start\n",
    "            _seq_list.append(_tmp_info['fwd_primer'].seq) # fwd primer\n",
    "            if _islist:\n",
    "                _seq_list += [_bc.seq[-20:].reverse_complement() for _bc in _tmp_info[_islist]]; # list barcodes, usually for decoding\n",
    "                for _k,_v in _barcode_source.iteritems():\n",
    "                    if _k != _islist:\n",
    "                        _seq_list.insert(-1, _tmp_info[_k].seq[-20:].reverse_complement()) # other barcodes\n",
    "                _seq_list.insert(-2, Seq(_tmp_info['seq']) ) # target sequence in the middle\n",
    "            else:\n",
    "                for _k,_v in _barcode_source.iteritems():\n",
    "                    _seq_list.append(_tmp_info[_k].seq[-20:].reverse_complement()) # other barcodes\n",
    "                _seq_list.insert(-2, Seq(_tmp_info['seq']) ) # target sequence in the middle\n",
    "\n",
    "            _seq_list.append(_tmp_info['rev_primer'].seq[-20:].reverse_complement()) # reverse primer\n",
    "            # result\n",
    "            dna_alphabet = ['A','A','C','G','T','T']; # used for adding random gap, if needed\n",
    "            _total_seq = Seq('');\n",
    "            for j in range(len(_seq_list)):\n",
    "                _seq = _seq_list[j]\n",
    "                _total_seq += _seq;\n",
    "                if j > 0 and j < len(_seq_list)-2:\n",
    "                    _total_seq += ''.join([choice(dna_alphabet) for i in range(_add_rand_gap)]);\n",
    "            _tmp_info['total_seq'] = _total_seq;\n",
    "\n",
    "            ## Generate total_name:\n",
    "            # chr21:10350001-10400001_reg_208_gene_chr21_pb_41577 (from base name)\n",
    "            # primer_[4,11]\n",
    "            # barcodes_75,109,[]\n",
    "\n",
    "            # base name\n",
    "            _total_name = _tmp_info['name'].split('reg_')[0] + 'reg_'+str(_tmp_info['reg_index']);\n",
    "            if 'gene' in _tmp_info['name']:\n",
    "                _total_name += '_gene' + _tmp_info['name'].split('gene')[1]\n",
    "            elif 'gene' in _tmp_info.keys():\n",
    "                _total_name += '_gene_'+_tmp_info['gene'];\n",
    "            # primer name\n",
    "            _primer_sets = [int(_tmp_info['fwd_primer'].id.split('_')[-1]), int(_tmp_info['rev_primer'].id.split('_')[-1])]\n",
    "            _total_name += '_primer_'+str(_primer_sets).replace(' ','')\n",
    "            # barcode name\n",
    "            _barcode_sets = [];\n",
    "            if _islist:\n",
    "                _barcode_sets.append([rec.id for rec in _tmp_info[_islist]]);\n",
    "                for _k,_v in _barcode_source.iteritems():\n",
    "                    if _k != _islist:\n",
    "                        _barcode_sets.append(_tmp_info[_k].id);\n",
    "            else:\n",
    "                for _k,_v in _barcode_source.iteritems():\n",
    "                    _barcode_sets.append(_tmp_info[_k].id);        \n",
    "            _total_name += '_barcodes_'+str(_barcode_sets).replace(' ','')\n",
    "            # color\n",
    "            _total_name += '_color_'+str(_tmp_info['color'])\n",
    "            \n",
    "            ## save\n",
    "            _tmp_info['total_name'] = _total_name;\n",
    "            ## Append\n",
    "            _plist.append(_tmp_info) # to plist\n",
    "            _precords.append(SeqRecord(_total_seq, id=_total_name, description='', name=_total_name)); # to seq record\n",
    "\n",
    "        return _plist, _precords    \n",
    "    \n",
    "    # generate file encoding\n",
    "    _pb_files, _file_encodings = _generating_file_encoding();\n",
    "\n",
    "    # initialize\n",
    "    _pb_lists, _pb_records = [],[];\n",
    "    # loop through all files\n",
    "    for _fl in sorted(_pb_files, key=lambda fl:int(fl.split('_')[-1].split('.')[0])):\n",
    "        _list, _records = _patch_barcode_per_file(_fl, _file_encodings);\n",
    "        _pb_lists.append(_list);\n",
    "        _pb_records += _records\n",
    "    \n",
    "    # save:\n",
    "    if save:\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "        list_savefile = save_folder + os.sep + 'list.pkl';\n",
    "        pb_savefile = save_folder + os.sep + 'candidate_probes.fasta';\n",
    "        if verbose:\n",
    "            print \"- Saving list to:\", list_savefile\n",
    "        pickle.dump(_pb_lists, open(list_savefile,'w'));\n",
    "        if verbose:\n",
    "            print \"- Saving probes to:\", pb_savefile\n",
    "        with open(pb_savefile, 'w') as output_handle:\n",
    "            SeqIO.write(_pb_records, output_handle, 'fasta');\n",
    "        \n",
    "    return _pb_lists, _pb_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Check inputs\n",
      "- check barcode starts:  {'stv': 1, 'ndb': 1}\n",
      "- Load probe reports, total_num: 42\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_266.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_281.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_320.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_338.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_362.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_380.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_419.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_420.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_484.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_506.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_514.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_520.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_542.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_543.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_557.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_567.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_585.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_590.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_591.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_630.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_632.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_635.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_651.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_653.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_662.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_663.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_674.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_683.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_684.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_693.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_694.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_713.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_725.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_733.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_735.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_748.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_752.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_756.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_782.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_790.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_826.pbr\n",
      "-- patch barcodes : /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21/reports/centered_merged-400/reg_931.pbr\n",
      "- Saving list to: /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21/final_probes/list.pkl\n",
      "- Saving probes to: /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21/final_probes/candidate_probes.fasta\n"
     ]
    }
   ],
   "source": [
    "pb_lists, pb_records = Patch_Barcodes(reg_encodings=sub_encodings,\n",
    "                                      fwd_primer=fprimer, rev_primer=rprimer, \n",
    "                                      barcode_source=barcode_source, barcode_order=barcode_order, \n",
    "                                      stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes, \n",
    "                                      report_folder=report_folder, save_folder=save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16621"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pb_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Check probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- forward primer: ID: W1A03_primer_2\n",
      "Name: W1A03_primer_2\n",
      "Description: W1A03_primer_2\n",
      "Number of features: 0\n",
      "Seq('CCCGCAATGGCTGACAACCG', SingleLetterAlphabet())\n",
      "- reverse primer: ID: W1A10_primer_9\n",
      "Name: W1A10_primer_9\n",
      "Description: W1A10_primer_9\n",
      "Number of features: 0\n",
      "Seq('TAATACGACTCACTATAGGGATTGCCGCATGGTTTCCG', SingleLetterAlphabet())\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "\n",
    "barcode_source = {'bc_decoding':'stv',\n",
    "                  'bc_unique':'ndb'};\n",
    "master_dir =r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21';\n",
    "pb_dir = r'final_probes';\n",
    "# primers\n",
    "fprimer = fwd_primers[1];\n",
    "print '- forward primer:', fprimer\n",
    "rprimer = rev_primers[4];\n",
    "print '- reverse primer:', rprimer\n",
    "\n",
    "# dic for region -> tad\n",
    "if not 'sub_encodings' in vars():\n",
    "    print 'loading sub_encodings'\n",
    "    sub_encodings = pickle.load(open(master_dir+os.sep+'sub_encoding.pkl','r'))\n",
    "if not 'pb_records' in vars():\n",
    "    print '- loading all probes'\n",
    "    with open(master_dir+os.sep+pb_dir+os.sep+'candidate_probes.fasta', \"rU\") as handle:\n",
    "        pb_records = [];\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            pb_records.append(record);\n",
    "if not 'pb_lists' in vars():\n",
    "    print '- loading pb_lists'\n",
    "    pb_lists = pickle.load(open(master_dir+os.sep+pb_dir+os.sep+'list.pkl', \"rU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Check_Probes(pb_records, pb_lists, reg_encodings, master_dir, \n",
    "                 fwd_primer,rev_primer,\n",
    "                 stv_barcodes, ndb_barcodes, barcode_starts={'stv':1,'ndb':1},\n",
    "                 report_dir=r'reports/centered_merged',save_dir=r'final_probes',\n",
    "                 add_rand_gap=0, total_bc=4, barcode_len=20, target_len=42,  \n",
    "                 word_size=17, max_internal_hits=5, max_genome_hits=150,\n",
    "                 index_dir=r'/n/boslfs/LABS/zhuang_lab/User/pzheng/Indeces/human/hg38',\n",
    "                 save=True, verbose=True):\n",
    "    # imports\n",
    "    import os,glob,sys\n",
    "    sys.path.append(r'/n/home13/pzheng/Documents/python-functions/python-functions-library')\n",
    "    from LibraryConstruction import fastaread,fastawrite,fastacombine\n",
    "    import LibraryDesigner as ld\n",
    "    import numpy as np\n",
    "    \n",
    "    def _check_primer_usage(pb_records=pb_records, fwd_primer=fwd_primer, rev_primer=rev_primer,\n",
    "                            _verbose=verbose):\n",
    "        '''Check whether forward or reverse primer are used in all probes'''\n",
    "        if _verbose:\n",
    "            print \"-- Checking primer usage, total probes:\", len(pb_records)\n",
    "        fwd_len = len(fwd_primer.seq);\n",
    "        rev_len = len(rev_primer.seq[-20:].reverse_complement());\n",
    "        \n",
    "        for record in pb_records:\n",
    "            if record.seq[:fwd_len] != fwd_primer.seq:\n",
    "                if _verbose:\n",
    "                    print \"--- Forward primer incorrect!\"\n",
    "                return False\n",
    "            if record.seq[-rev_len:] != rev_primer.seq[-20:].reverse_complement():\n",
    "                if _verbose:\n",
    "                    print \"--- Forward primer incorrect!\"\n",
    "                return False\n",
    "        return True # if no error applies\n",
    "    \n",
    "    def _check_region_size(pb_records=pb_records, pb_lists=pb_lists):\n",
    "        '''Generate a dirctionary '''\n",
    "        # get original region size\n",
    "        _reg_size_dic = {}\n",
    "        for lst in pb_lists:\n",
    "            _reg_size_dic[lst[0]['reg_index']] = len(lst);\n",
    "        # get region size from probe names\n",
    "        _size_from_rec = {}\n",
    "        for record in pb_records:\n",
    "            reg_id = int(record.id.split('_reg_')[1].split('_')[0]);\n",
    "            if reg_id not in _size_from_rec.keys():\n",
    "                _size_from_rec[reg_id] = 1; # if not in key, create\n",
    "            else:\n",
    "                _size_from_rec[reg_id] += 1; # otherwise, add count\n",
    "        # compare\n",
    "        _match = True;\n",
    "        for k,v in sorted(_size_from_rec.items()):\n",
    "            if k not in _reg_size_dic.keys():\n",
    "                print \"region list and region id in probes not match for\", k\n",
    "                _match = False\n",
    "                break\n",
    "            else:\n",
    "                if v != _reg_size_dic[k]:\n",
    "                    print \"region size doesn't match for:\", k\n",
    "                    _match = False\n",
    "                    break\n",
    "        \n",
    "        return _reg_size_dic, _match;\n",
    "    \n",
    "    def _check_gene_size():\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def _check_region_to_barcode(pb_records=pb_records, stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes,\n",
    "                                 total_bc=total_bc):\n",
    "        '''Generate map from region id to barcodes used in this region'''\n",
    "        import re\n",
    "        _reg_to_barcode = {}\n",
    "        for record in pb_records:\n",
    "            # region id\n",
    "            reg_id = int(record.id.split('_reg_')[1].split('_')[0]);\n",
    "            if reg_id not in _reg_to_barcode.keys():\n",
    "                # barcode ids\n",
    "                stv_matches = re.findall('\\'Stv_(.+?)\\'', record.id, re.DOTALL)\n",
    "                ndb_matches = re.findall('\\'NDB_(.+?)\\'', record.id, re.DOTALL)\n",
    "                stv_names = ['Stv_'+str(stv_id) for stv_id in stv_matches]\n",
    "                ndb_names = ['NDB_'+str(ndb_id) for ndb_id in ndb_matches]\n",
    "                _reg_to_barcode[reg_id] = stv_names+ndb_names\n",
    "        \n",
    "        ## barcode check\n",
    "        _barcode_check = True;\n",
    "        # barcode names\n",
    "        bc_names = [stv.id for stv in stv_barcodes] + [ndb.id for ndb in ndb_barcodes]\n",
    "        # search through previous dictionary\n",
    "        for reg,bcs in sorted(_reg_to_barcode.items()):\n",
    "            for bc in bcs:\n",
    "                if len(bcs) != total_bc:\n",
    "                    print \"-- Error in barcode number for region:\", reg\n",
    "                    _barcode_check = False\n",
    "                    break\n",
    "                if bc not in bc_names:\n",
    "                    print \"-- Wrong barcode name for barcode: \"+str(bc)+\", region: \"+str(reg)\n",
    "                    _barcode_check = False\n",
    "                    break\n",
    "        \n",
    "        return _reg_to_barcode, _barcode_check;\n",
    "        \n",
    "    def _parsing_probe_sequence(record, fwd_primer=fwd_primer, rev_primer=rev_primer,\n",
    "                                add_rand_gap=add_rand_gap, barcode_len=barcode_len, target_len=target_len):\n",
    "        '''parse a probe sequence to acquire all barcode binding sites'''\n",
    "        # take in a seq record, parse the sequence and return a list of all included barcodes (20mer,RC)\n",
    "        barcode_list = [];\n",
    "        _main_seq = record.seq[len(fwd_primer.seq):-20];\n",
    "        \n",
    "        \n",
    "        # trim last 2 barcodes\n",
    "        for i in range(2):\n",
    "            barcode_list.append(_main_seq[-barcode_len:]);\n",
    "            _main_seq = _main_seq[:-(barcode_len+add_rand_gap)];\n",
    "        # trim all barcodes from the beginning\n",
    "        while len(_main_seq) > target_len:\n",
    "            barcode_list.append(_main_seq[:barcode_len]);\n",
    "            _main_seq = _main_seq[(barcode_len+add_rand_gap):];\n",
    "        \n",
    "        return barcode_list;\n",
    "    \n",
    "    def _finding_barcode_name(barcode_list, stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes, \n",
    "                              barcode_len=barcode_len, total_bc=total_bc):\n",
    "        '''Given barcode list generated by parsing probe, return a list of barcode names'''\n",
    "        _name_list = [];\n",
    "        for bc_site in barcode_list:\n",
    "            for bc in stv_barcodes+ndb_barcodes:\n",
    "                if bc.seq[-barcode_len:] == bc_site.reverse_complement():\n",
    "                    _name_list.append(bc.id);\n",
    "                    break;\n",
    "        \n",
    "        if len(_name_list) < total_bc:\n",
    "            print \"-- Failed in finding some barcodes.\"\n",
    "            return False\n",
    "        return _name_list;\n",
    "    \n",
    "    def _check_barcode_to_gene():\n",
    "        pass\n",
    "    \n",
    "    def _check_barcode_to_region(reg_to_barcode, \n",
    "                                 pb_records=pb_records, stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes):\n",
    "        '''Generate map from barcode id to region id'''\n",
    "        _barcode_to_reg = {}\n",
    "        _reg_id_exists = []\n",
    "        for record in pb_records:\n",
    "            reg_id = int(record.id.split('_reg_')[1].split('_')[0]);\n",
    "            if reg_id in _reg_id_exists:\n",
    "                continue;\n",
    "            else:\n",
    "                _barcode_list = _parsing_probe_sequence(record)\n",
    "                _name_list = _finding_barcode_name(_barcode_list)\n",
    "                for _n in _name_list:\n",
    "                    if _n not in _barcode_to_reg.keys(): # create if not in dic\n",
    "                        _barcode_to_reg[_n] = [reg_id]\n",
    "                    else: # otherwise, append\n",
    "                        _barcode_to_reg[_n].append(reg_id)\n",
    "            _reg_id_exists.append(reg_id)\n",
    "        ## check region distribution\n",
    "        # invert dic from reg_to_barcode\n",
    "        _inv_dic = {}\n",
    "        for reg,bcs in sorted(reg_to_barcode.items()):\n",
    "            for bc in bcs:\n",
    "                if bc not in _inv_dic.keys():\n",
    "                    _inv_dic[bc] = [reg];\n",
    "                else:\n",
    "                    _inv_dic[bc].append(reg);\n",
    "        # compare\n",
    "        _region_check=True\n",
    "        for bc, regs in sorted(_inv_dic.items()):\n",
    "            if bc not in _barcode_to_reg.keys():\n",
    "                print \"-- \"+str(bc)+\" not in barcode_to_region dic!\"\n",
    "                _region_check = False\n",
    "                break\n",
    "            else:\n",
    "                if sorted(regs) != sorted(_barcode_to_reg[bc]):\n",
    "                    print \"-- \"+str(bc)+\" and region\"+str(regs)+\" not compatible with barcode_to_region dic!\"\n",
    "                    _region_check = False\n",
    "                    break\n",
    "                    \n",
    "        return _barcode_to_reg, _region_check\n",
    "    \n",
    "    def _check_barcode_to_color(pb_records=pb_records, stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes, \n",
    "                                stv_color=True, ndb_color=False,\n",
    "                                _save=save, master_dir=master_dir, save_dir=save_dir):\n",
    "        '''If multi_color is applied, generate a barcode_to_color dic for adaptor design'''\n",
    "        if 'color' not in str(pb_records[0].id):\n",
    "            print \"-- color check not applied\";\n",
    "            return False\n",
    "        elif not stv_color and not ndb_color:\n",
    "            print \"-- color check turned off in both stv and ndb\";\n",
    "            return False\n",
    "        else:\n",
    "            # get barcodes\n",
    "            _barcode_names = []\n",
    "            if stv_color: # if stv has multi-color\n",
    "                _barcode_names += [bc.id for bc in stv_barcodes];\n",
    "            if ndb_color: # if ndb has multi-color\n",
    "                _barcode_names += [bc.id for bc in ndb_barcodes];\n",
    "            # initialize color dic\n",
    "            _barcode_to_color = {};\n",
    "            _exist_regs = [];\n",
    "            # search through all probes\n",
    "            for record in pb_records:\n",
    "                _reg_id = int(record.id.split('_reg_')[1].split('_')[0]); \n",
    "                if _reg_id in _exist_regs:\n",
    "                    continue\n",
    "                else: \n",
    "                    _exist_regs.append(_reg_id);\n",
    "                _color = int(str(record.id).split('color_')[1])\n",
    "                _barcode_list = _parsing_probe_sequence(record)\n",
    "                _name_list = _finding_barcode_name(_barcode_list)\n",
    "                \n",
    "                for _name in _name_list:\n",
    "                    if _name in _barcode_names:\n",
    "                        if _name not in _barcode_to_color.keys():\n",
    "                            _barcode_to_color[_name] = [_color]\n",
    "                        else:\n",
    "                            _barcode_to_color[_name].append(_color);\n",
    "            # keep the unique colors\n",
    "            _barcode_to_unique_color = {}\n",
    "            for k,v in sorted(_barcode_to_color.items()):\n",
    "                _barcode_to_unique_color[k] = np.unique(v)\n",
    "            if _save:\n",
    "                import csv\n",
    "                # mkdir if not exist for this region\n",
    "                if not os.path.exists(master_dir+os.sep+save_dir):\n",
    "                    os.makedirs(master_dir+os.sep+save_dir)\n",
    "                with open(master_dir+os.sep+save_dir+os.sep+'color-usage.csv','w') as output_handle:\n",
    "                    fieldnames = ['barcode', 'color']\n",
    "                    writer = csv.DictWriter(output_handle, fieldnames=fieldnames)\n",
    "                    writer.writeheader()\n",
    "                    for _barcode, _color in sorted(_barcode_to_unique_color.items(), key=lambda (k,v):int(k.split('_')[1])):\n",
    "                        writer.writerow({'barcode': _barcode, 'color': _color})\n",
    "                \n",
    "        return _barcode_to_unique_color\n",
    "                            \n",
    "    \n",
    "    def _construct_internal_map(master_dir=master_dir, save_dir=save_dir, word_size=word_size):\n",
    "        '''Using functions in LibraryDesign, compute an internal khmer map'''\n",
    "        _int_map = khmer.Countgraph(word_size, 1e9, 2) \n",
    "        _int_map.set_use_bigcount(True)\n",
    "        _nms,_seqs = fastaread(master_dir+os.sep+save_dir+os.sep+'candidate_probes.fasta')\n",
    "        for _seq in _seqs:\n",
    "            _int_map.consume(_seq.upper())\n",
    "        return _int_map\n",
    "    \n",
    "    def _check_barcode_in_probes(barcode_to_reg, reg_size_dic, int_map, \n",
    "                                 stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes,\n",
    "                                 barcode_len=barcode_len, max_internal_hits=max_internal_hits):\n",
    "        '''Check barcode appearance in probes, whether that match barcode_to_region scheme'''\n",
    "        _barcode_in_probes = {}\n",
    "        for bc_name, regs in sorted(barcode_to_reg.items()):\n",
    "            bc = None\n",
    "            for _bc in stv_barcodes+ndb_barcodes:\n",
    "                if bc_name == _bc.id:\n",
    "                    bc = _bc\n",
    "                    break\n",
    "            bc_hits = int_map.get_kmer_counts( str(bc.seq[-barcode_len:].reverse_complement()).upper());\n",
    "            if max(bc_hits) - min(bc_hits) > max_internal_hits:\n",
    "                print \"-- Barcode: \"+str(bc)+\" has more off-target in different part of itself!\"\n",
    "                return False\n",
    "            else:\n",
    "                regs,reg_cts = np.unique(regs, return_counts=True);\n",
    "                bc_in_probe = 0;\n",
    "                for reg,ct in zip(regs,reg_cts):\n",
    "                    bc_in_probe += reg_size_dic[reg] * ct;\n",
    "                if max(bc_hits) - bc_in_probe > max_internal_hits:\n",
    "                    print \"-- Barcode: \"+str(bc)+\" has more off-target than threshold!\"\n",
    "                    return False\n",
    "            _barcode_in_probes[bc_name] = bc_in_probe;\n",
    "        return _barcode_in_probes, True\n",
    "    \n",
    "    def _check_between_probes(int_map, pb_lists=pb_lists, pb_records=pb_records):\n",
    "        pass \n",
    "    \n",
    "    def _check_against_genome(pb_records=pb_records, max_genome_hits=max_genome_hits, index_dir=index_dir):\n",
    "        '''Use Khmer to compare probe against genome'''\n",
    "        hg38 = khmer.load_countgraph(index_dir+os.sep+'full_word17_.kmer')\n",
    "        _failed_num = 0;\n",
    "        _keep_pb_records = [];\n",
    "        for record in pb_records:\n",
    "            _kmer_hits = hg38.get_kmer_counts(str(record.seq).upper());\n",
    "            if sum(_kmer_hits) > max_genome_hits:\n",
    "                print '-- Max_genome_hits is: '+str(max_genome_hits)+\", this seq got hits: \"+ str(sum(_kmer_hits))\n",
    "                _failed_num += 1;\n",
    "            else:\n",
    "                _keep_pb_records.append(record);\n",
    "                \n",
    "        return _keep_pb_records, _failed_num # if nothing goes wrong\n",
    "    \n",
    "    def _plot_info():\n",
    "        pass\n",
    "            \n",
    "    ## check primers\n",
    "    primer_usage = _check_primer_usage()\n",
    "    if verbose:\n",
    "        print \"\\n- 1.Passing primer usage check? -\", primer_usage\n",
    "    \n",
    "    ## check region size\n",
    "    reg_size_dic, size_match = _check_region_size()\n",
    "    if verbose:\n",
    "        print \"\\n- 2.Passing region size check? -\", size_match    \n",
    "        for k,v in sorted(reg_size_dic.items()):\n",
    "            print k,':',v\n",
    "        \n",
    "    ## check region to barcode\n",
    "    reg_to_barcode, reg2bc = _check_region_to_barcode()\n",
    "    if verbose:\n",
    "        print \"\\n- 3.Passing region to barcode mapping check? -\", reg2bc    \n",
    "        for k,v in sorted(reg_to_barcode.items(), key=lambda (k,v):k):\n",
    "            print k,':',v\n",
    "        \n",
    "    ## check barcode to region (this step must be run after step 3) \n",
    "    barcode_to_reg, bc2reg = _check_barcode_to_region(reg_to_barcode)\n",
    "    if verbose:\n",
    "        print \"\\n- 4.Passing barcode to region mapping check? -\", bc2reg    \n",
    "        for k,v in sorted(barcode_to_reg.items(), key=lambda (k,v):[k[0],int(k.split('_')[1])]):\n",
    "            print k,':',v\n",
    "    \n",
    "    ## check barcode to region (this step must be run after step 3) \n",
    "    barcode_to_color = _check_barcode_to_color()\n",
    "    if verbose:\n",
    "        print \"\\n- 5.Calculating barcode to color dictionary.\"\n",
    "        for k,v in sorted(barcode_to_color.items(), key=lambda (k,v):[k[0],int(k.split('_')[1])]):\n",
    "            print k,':',v    \n",
    "    \n",
    "    \n",
    "    ## Construct an internal map\n",
    "    int_map = _construct_internal_map();\n",
    "    if verbose:\n",
    "        print \"\\n- 6.Constructing internal khmer map\";\n",
    "    \n",
    "    ## Check barcodes total counts in probes\n",
    "    barcode_in_probes, _bc_counting = _check_barcode_in_probes(barcode_to_reg, reg_size_dic, int_map)\n",
    "    if verbose:\n",
    "        print \"\\n- 7.Passing if counting barcode appearance times in probes\", _bc_counting;    \n",
    "\n",
    "    ## Check against each other    \n",
    "    \n",
    "    ## Check against genome\n",
    "    kept_records, failed_num = _check_against_genome();\n",
    "    if verbose:\n",
    "        print \"\\n- 8.Probes not passing through genome filter:\", failed_num;  \n",
    "    \n",
    "    # check region size for kept probes\n",
    "    _size_from_rec = {}\n",
    "    for record in pb_records:\n",
    "        reg_id = int(record.id.split('_reg_')[1].split('_')[0]);\n",
    "        if reg_id not in _size_from_rec.keys():\n",
    "            _size_from_rec[reg_id] = 1; # if not in key, create\n",
    "        else:\n",
    "            _size_from_rec[reg_id] += 1; # otherwise, add count\n",
    "    if verbose:\n",
    "        print \"--  re-check region size:\"\n",
    "        for k,v in sorted(_size_from_rec.items()):\n",
    "            print k,':',v\n",
    "        print \"--- total number of probes:\", len(kept_records);\n",
    "    if save:\n",
    "        pb_savefile = master_dir + os.sep + save_dir + os.sep + 'filtered_probes.fasta';\n",
    "        if verbose:\n",
    "            print \"\\n- 9.Saving probes to:\", pb_savefile\n",
    "        with open(pb_savefile, 'w') as output_handle:\n",
    "            SeqIO.write(kept_records, output_handle, 'fasta');  \n",
    "        \n",
    "    return kept_records, _size_from_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Checking primer usage, total probes: 16621\n",
      "\n",
      "- 1.Passing primer usage check? - True\n",
      "\n",
      "- 2.Passing region size check? - True\n",
      "0 : 221\n",
      "1 : 400\n",
      "2 : 400\n",
      "3 : 400\n",
      "4 : 400\n",
      "5 : 400\n",
      "6 : 400\n",
      "7 : 400\n",
      "8 : 400\n",
      "9 : 400\n",
      "10 : 400\n",
      "11 : 400\n",
      "12 : 400\n",
      "13 : 400\n",
      "14 : 400\n",
      "15 : 400\n",
      "16 : 400\n",
      "17 : 400\n",
      "18 : 400\n",
      "19 : 400\n",
      "20 : 400\n",
      "21 : 400\n",
      "22 : 400\n",
      "23 : 400\n",
      "24 : 400\n",
      "25 : 400\n",
      "26 : 400\n",
      "27 : 400\n",
      "28 : 400\n",
      "29 : 400\n",
      "30 : 400\n",
      "31 : 400\n",
      "32 : 400\n",
      "33 : 400\n",
      "34 : 400\n",
      "35 : 400\n",
      "36 : 400\n",
      "37 : 400\n",
      "38 : 400\n",
      "39 : 400\n",
      "40 : 400\n",
      "41 : 400\n",
      "\n",
      "- 3.Passing region to barcode mapping check? - True\n",
      "0 : ['Stv_7', 'Stv_8', 'NDB_35']\n",
      "1 : ['Stv_37', 'Stv_39', 'NDB_36']\n",
      "2 : ['Stv_6', 'Stv_9', 'NDB_37']\n",
      "3 : ['Stv_36', 'Stv_40', 'NDB_38']\n",
      "4 : ['Stv_37', 'Stv_40', 'NDB_39']\n",
      "5 : ['Stv_7', 'Stv_9', 'NDB_40']\n",
      "6 : ['Stv_8', 'Stv_9', 'NDB_41']\n",
      "7 : ['Stv_39', 'Stv_40', 'NDB_42']\n",
      "8 : ['Stv_6', 'Stv_8', 'NDB_43']\n",
      "9 : ['Stv_33', 'Stv_37', 'NDB_44']\n",
      "10 : ['Stv_36', 'Stv_39', 'NDB_45']\n",
      "11 : ['Stv_6', 'Stv_7', 'NDB_46']\n",
      "12 : ['Stv_5', 'Stv_9', 'NDB_47']\n",
      "13 : ['Stv_33', 'Stv_36', 'NDB_48']\n",
      "14 : ['Stv_5', 'Stv_8', 'NDB_49']\n",
      "15 : ['Stv_36', 'Stv_37', 'NDB_50']\n",
      "16 : ['Stv_33', 'Stv_35', 'NDB_51']\n",
      "17 : ['Stv_5', 'Stv_7', 'NDB_52']\n",
      "18 : ['Stv_35', 'Stv_40', 'NDB_53']\n",
      "19 : ['Stv_4', 'Stv_7', 'NDB_54']\n",
      "20 : ['Stv_32', 'Stv_40', 'NDB_55']\n",
      "21 : ['Stv_32', 'Stv_39', 'NDB_56']\n",
      "22 : ['Stv_4', 'Stv_6', 'NDB_57']\n",
      "23 : ['Stv_32', 'Stv_37', 'NDB_58']\n",
      "24 : ['Stv_5', 'Stv_6', 'NDB_59']\n",
      "25 : ['Stv_32', 'Stv_36', 'NDB_60']\n",
      "26 : ['Stv_32', 'Stv_35', 'NDB_61']\n",
      "27 : ['Stv_4', 'Stv_5', 'NDB_62']\n",
      "28 : ['Stv_32', 'Stv_33', 'NDB_63']\n",
      "29 : ['Stv_3', 'Stv_9', 'NDB_64']\n",
      "30 : ['Stv_35', 'Stv_39', 'NDB_65']\n",
      "31 : ['Stv_3', 'Stv_8', 'NDB_66']\n",
      "32 : ['Stv_3', 'Stv_7', 'NDB_67']\n",
      "33 : ['Stv_4', 'Stv_9', 'NDB_68']\n",
      "34 : ['Stv_35', 'Stv_37', 'NDB_69']\n",
      "35 : ['Stv_35', 'Stv_36', 'NDB_70']\n",
      "36 : ['Stv_3', 'Stv_6', 'NDB_71']\n",
      "37 : ['Stv_3', 'Stv_5', 'NDB_72']\n",
      "38 : ['Stv_3', 'Stv_4', 'NDB_73']\n",
      "39 : ['Stv_33', 'Stv_40', 'NDB_74']\n",
      "40 : ['Stv_4', 'Stv_8', 'NDB_75']\n",
      "41 : ['Stv_33', 'Stv_39', 'NDB_76']\n",
      "\n",
      "- 4.Passing barcode to region mapping check? - True\n",
      "NDB_35 : [0]\n",
      "NDB_36 : [1]\n",
      "NDB_37 : [2]\n",
      "NDB_38 : [3]\n",
      "NDB_39 : [4]\n",
      "NDB_40 : [5]\n",
      "NDB_41 : [6]\n",
      "NDB_42 : [7]\n",
      "NDB_43 : [8]\n",
      "NDB_44 : [9]\n",
      "NDB_45 : [10]\n",
      "NDB_46 : [11]\n",
      "NDB_47 : [12]\n",
      "NDB_48 : [13]\n",
      "NDB_49 : [14]\n",
      "NDB_50 : [15]\n",
      "NDB_51 : [16]\n",
      "NDB_52 : [17]\n",
      "NDB_53 : [18]\n",
      "NDB_54 : [19]\n",
      "NDB_55 : [20]\n",
      "NDB_56 : [21]\n",
      "NDB_57 : [22]\n",
      "NDB_58 : [23]\n",
      "NDB_59 : [24]\n",
      "NDB_60 : [25]\n",
      "NDB_61 : [26]\n",
      "NDB_62 : [27]\n",
      "NDB_63 : [28]\n",
      "NDB_64 : [29]\n",
      "NDB_65 : [30]\n",
      "NDB_66 : [31]\n",
      "NDB_67 : [32]\n",
      "NDB_68 : [33]\n",
      "NDB_69 : [34]\n",
      "NDB_70 : [35]\n",
      "NDB_71 : [36]\n",
      "NDB_72 : [37]\n",
      "NDB_73 : [38]\n",
      "NDB_74 : [39]\n",
      "NDB_75 : [40]\n",
      "NDB_76 : [41]\n",
      "Stv_3 : [29, 31, 32, 36, 37, 38]\n",
      "Stv_4 : [19, 22, 27, 33, 38, 40]\n",
      "Stv_5 : [12, 14, 17, 24, 27, 37]\n",
      "Stv_6 : [2, 8, 11, 22, 24, 36]\n",
      "Stv_7 : [0, 5, 11, 17, 19, 32]\n",
      "Stv_8 : [0, 6, 8, 14, 31, 40]\n",
      "Stv_9 : [2, 5, 6, 12, 29, 33]\n",
      "Stv_32 : [20, 21, 23, 25, 26, 28]\n",
      "Stv_33 : [9, 13, 16, 28, 39, 41]\n",
      "Stv_35 : [16, 18, 26, 30, 34, 35]\n",
      "Stv_36 : [3, 10, 13, 15, 25, 35]\n",
      "Stv_37 : [1, 4, 9, 15, 23, 34]\n",
      "Stv_39 : [1, 7, 10, 21, 30, 41]\n",
      "Stv_40 : [3, 4, 7, 18, 20, 39]\n",
      "\n",
      "- 5.Calculating barcode to color dictionary.\n",
      "Stv_3 : [0]\n",
      "Stv_4 : [0]\n",
      "Stv_5 : [0]\n",
      "Stv_6 : [0]\n",
      "Stv_7 : [0]\n",
      "Stv_8 : [0]\n",
      "Stv_9 : [0]\n",
      "Stv_32 : [1]\n",
      "Stv_33 : [1]\n",
      "Stv_35 : [1]\n",
      "Stv_36 : [1]\n",
      "Stv_37 : [1]\n",
      "Stv_39 : [1]\n",
      "Stv_40 : [1]\n",
      "\n",
      "- 6.Constructing internal khmer map\n",
      "\n",
      "- 7.Passing if counting barcode appearance times in probes True\n",
      "-- Max_genome_hits is: 150, this seq got hits: 153\n",
      "-- Max_genome_hits is: 150, this seq got hits: 262\n",
      "-- Max_genome_hits is: 150, this seq got hits: 256\n",
      "-- Max_genome_hits is: 150, this seq got hits: 155\n",
      "-- Max_genome_hits is: 150, this seq got hits: 641\n",
      "-- Max_genome_hits is: 150, this seq got hits: 368\n",
      "-- Max_genome_hits is: 150, this seq got hits: 159\n",
      "-- Max_genome_hits is: 150, this seq got hits: 311\n",
      "-- Max_genome_hits is: 150, this seq got hits: 176\n",
      "-- Max_genome_hits is: 150, this seq got hits: 296\n",
      "-- Max_genome_hits is: 150, this seq got hits: 415\n",
      "-- Max_genome_hits is: 150, this seq got hits: 219\n",
      "-- Max_genome_hits is: 150, this seq got hits: 187\n",
      "-- Max_genome_hits is: 150, this seq got hits: 152\n",
      "-- Max_genome_hits is: 150, this seq got hits: 402\n",
      "-- Max_genome_hits is: 150, this seq got hits: 163\n",
      "-- Max_genome_hits is: 150, this seq got hits: 1235\n",
      "-- Max_genome_hits is: 150, this seq got hits: 417\n",
      "-- Max_genome_hits is: 150, this seq got hits: 381\n",
      "-- Max_genome_hits is: 150, this seq got hits: 226\n",
      "-- Max_genome_hits is: 150, this seq got hits: 272\n",
      "-- Max_genome_hits is: 150, this seq got hits: 155\n",
      "-- Max_genome_hits is: 150, this seq got hits: 186\n",
      "-- Max_genome_hits is: 150, this seq got hits: 364\n",
      "-- Max_genome_hits is: 150, this seq got hits: 301\n",
      "-- Max_genome_hits is: 150, this seq got hits: 207\n",
      "-- Max_genome_hits is: 150, this seq got hits: 387\n",
      "-- Max_genome_hits is: 150, this seq got hits: 1202\n",
      "-- Max_genome_hits is: 150, this seq got hits: 236\n",
      "-- Max_genome_hits is: 150, this seq got hits: 162\n",
      "-- Max_genome_hits is: 150, this seq got hits: 5655\n",
      "-- Max_genome_hits is: 150, this seq got hits: 237\n",
      "-- Max_genome_hits is: 150, this seq got hits: 218\n",
      "-- Max_genome_hits is: 150, this seq got hits: 894\n",
      "-- Max_genome_hits is: 150, this seq got hits: 723\n",
      "-- Max_genome_hits is: 150, this seq got hits: 151\n",
      "-- Max_genome_hits is: 150, this seq got hits: 518\n",
      "-- Max_genome_hits is: 150, this seq got hits: 358\n",
      "-- Max_genome_hits is: 150, this seq got hits: 487\n",
      "-- Max_genome_hits is: 150, this seq got hits: 184\n",
      "-- Max_genome_hits is: 150, this seq got hits: 168\n",
      "-- Max_genome_hits is: 150, this seq got hits: 157\n",
      "-- Max_genome_hits is: 150, this seq got hits: 225\n",
      "-- Max_genome_hits is: 150, this seq got hits: 177\n",
      "-- Max_genome_hits is: 150, this seq got hits: 157\n",
      "-- Max_genome_hits is: 150, this seq got hits: 349\n",
      "-- Max_genome_hits is: 150, this seq got hits: 171\n",
      "-- Max_genome_hits is: 150, this seq got hits: 198\n",
      "-- Max_genome_hits is: 150, this seq got hits: 195\n",
      "-- Max_genome_hits is: 150, this seq got hits: 224\n",
      "-- Max_genome_hits is: 150, this seq got hits: 186\n",
      "-- Max_genome_hits is: 150, this seq got hits: 389\n",
      "-- Max_genome_hits is: 150, this seq got hits: 159\n",
      "-- Max_genome_hits is: 150, this seq got hits: 169\n",
      "-- Max_genome_hits is: 150, this seq got hits: 524\n",
      "-- Max_genome_hits is: 150, this seq got hits: 388\n",
      "-- Max_genome_hits is: 150, this seq got hits: 152\n",
      "-- Max_genome_hits is: 150, this seq got hits: 949\n",
      "-- Max_genome_hits is: 150, this seq got hits: 160\n",
      "-- Max_genome_hits is: 150, this seq got hits: 183\n",
      "-- Max_genome_hits is: 150, this seq got hits: 826\n",
      "-- Max_genome_hits is: 150, this seq got hits: 171\n",
      "-- Max_genome_hits is: 150, this seq got hits: 266\n",
      "-- Max_genome_hits is: 150, this seq got hits: 836\n",
      "-- Max_genome_hits is: 150, this seq got hits: 371\n",
      "-- Max_genome_hits is: 150, this seq got hits: 191\n",
      "-- Max_genome_hits is: 150, this seq got hits: 169\n",
      "-- Max_genome_hits is: 150, this seq got hits: 151\n",
      "-- Max_genome_hits is: 150, this seq got hits: 688\n",
      "-- Max_genome_hits is: 150, this seq got hits: 346\n",
      "-- Max_genome_hits is: 150, this seq got hits: 161\n",
      "-- Max_genome_hits is: 150, this seq got hits: 168\n",
      "-- Max_genome_hits is: 150, this seq got hits: 180\n",
      "-- Max_genome_hits is: 150, this seq got hits: 630\n",
      "-- Max_genome_hits is: 150, this seq got hits: 466\n",
      "-- Max_genome_hits is: 150, this seq got hits: 197\n",
      "-- Max_genome_hits is: 150, this seq got hits: 298\n",
      "-- Max_genome_hits is: 150, this seq got hits: 186\n",
      "-- Max_genome_hits is: 150, this seq got hits: 215\n",
      "-- Max_genome_hits is: 150, this seq got hits: 213\n",
      "-- Max_genome_hits is: 150, this seq got hits: 179\n",
      "-- Max_genome_hits is: 150, this seq got hits: 162\n",
      "-- Max_genome_hits is: 150, this seq got hits: 169\n",
      "-- Max_genome_hits is: 150, this seq got hits: 155\n",
      "-- Max_genome_hits is: 150, this seq got hits: 175\n",
      "-- Max_genome_hits is: 150, this seq got hits: 268\n",
      "-- Max_genome_hits is: 150, this seq got hits: 168\n",
      "-- Max_genome_hits is: 150, this seq got hits: 360\n",
      "-- Max_genome_hits is: 150, this seq got hits: 182\n",
      "-- Max_genome_hits is: 150, this seq got hits: 455\n",
      "-- Max_genome_hits is: 150, this seq got hits: 175\n",
      "-- Max_genome_hits is: 150, this seq got hits: 184\n",
      "-- Max_genome_hits is: 150, this seq got hits: 167\n",
      "-- Max_genome_hits is: 150, this seq got hits: 460\n",
      "-- Max_genome_hits is: 150, this seq got hits: 154\n",
      "-- Max_genome_hits is: 150, this seq got hits: 426\n",
      "-- Max_genome_hits is: 150, this seq got hits: 236\n",
      "-- Max_genome_hits is: 150, this seq got hits: 348\n",
      "-- Max_genome_hits is: 150, this seq got hits: 1068\n",
      "-- Max_genome_hits is: 150, this seq got hits: 382\n",
      "-- Max_genome_hits is: 150, this seq got hits: 275\n",
      "-- Max_genome_hits is: 150, this seq got hits: 175\n",
      "-- Max_genome_hits is: 150, this seq got hits: 211\n",
      "-- Max_genome_hits is: 150, this seq got hits: 153\n",
      "-- Max_genome_hits is: 150, this seq got hits: 1200\n",
      "-- Max_genome_hits is: 150, this seq got hits: 273\n",
      "-- Max_genome_hits is: 150, this seq got hits: 156\n",
      "-- Max_genome_hits is: 150, this seq got hits: 160\n",
      "-- Max_genome_hits is: 150, this seq got hits: 212\n",
      "-- Max_genome_hits is: 150, this seq got hits: 213\n",
      "-- Max_genome_hits is: 150, this seq got hits: 174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Max_genome_hits is: 150, this seq got hits: 286\n",
      "-- Max_genome_hits is: 150, this seq got hits: 169\n",
      "-- Max_genome_hits is: 150, this seq got hits: 203\n",
      "-- Max_genome_hits is: 150, this seq got hits: 155\n",
      "-- Max_genome_hits is: 150, this seq got hits: 167\n",
      "-- Max_genome_hits is: 150, this seq got hits: 208\n",
      "-- Max_genome_hits is: 150, this seq got hits: 288\n",
      "-- Max_genome_hits is: 150, this seq got hits: 183\n",
      "-- Max_genome_hits is: 150, this seq got hits: 263\n",
      "-- Max_genome_hits is: 150, this seq got hits: 177\n",
      "-- Max_genome_hits is: 150, this seq got hits: 184\n",
      "-- Max_genome_hits is: 150, this seq got hits: 328\n",
      "-- Max_genome_hits is: 150, this seq got hits: 68608\n",
      "-- Max_genome_hits is: 150, this seq got hits: 159\n",
      "-- Max_genome_hits is: 150, this seq got hits: 164\n",
      "-- Max_genome_hits is: 150, this seq got hits: 185\n",
      "-- Max_genome_hits is: 150, this seq got hits: 191\n",
      "-- Max_genome_hits is: 150, this seq got hits: 373\n",
      "-- Max_genome_hits is: 150, this seq got hits: 164\n",
      "-- Max_genome_hits is: 150, this seq got hits: 244\n",
      "-- Max_genome_hits is: 150, this seq got hits: 319\n",
      "-- Max_genome_hits is: 150, this seq got hits: 152\n",
      "-- Max_genome_hits is: 150, this seq got hits: 277\n",
      "-- Max_genome_hits is: 150, this seq got hits: 381\n",
      "-- Max_genome_hits is: 150, this seq got hits: 696\n",
      "-- Max_genome_hits is: 150, this seq got hits: 510\n",
      "-- Max_genome_hits is: 150, this seq got hits: 151\n",
      "-- Max_genome_hits is: 150, this seq got hits: 238\n",
      "-- Max_genome_hits is: 150, this seq got hits: 202\n",
      "-- Max_genome_hits is: 150, this seq got hits: 366\n",
      "-- Max_genome_hits is: 150, this seq got hits: 629\n",
      "-- Max_genome_hits is: 150, this seq got hits: 182\n",
      "-- Max_genome_hits is: 150, this seq got hits: 190\n",
      "-- Max_genome_hits is: 150, this seq got hits: 521\n",
      "-- Max_genome_hits is: 150, this seq got hits: 156\n",
      "-- Max_genome_hits is: 150, this seq got hits: 205\n",
      "-- Max_genome_hits is: 150, this seq got hits: 228\n",
      "-- Max_genome_hits is: 150, this seq got hits: 395\n",
      "-- Max_genome_hits is: 150, this seq got hits: 170\n",
      "-- Max_genome_hits is: 150, this seq got hits: 911\n",
      "-- Max_genome_hits is: 150, this seq got hits: 172\n",
      "-- Max_genome_hits is: 150, this seq got hits: 311\n",
      "-- Max_genome_hits is: 150, this seq got hits: 386\n",
      "-- Max_genome_hits is: 150, this seq got hits: 492\n",
      "-- Max_genome_hits is: 150, this seq got hits: 161\n",
      "-- Max_genome_hits is: 150, this seq got hits: 178\n",
      "-- Max_genome_hits is: 150, this seq got hits: 349\n",
      "-- Max_genome_hits is: 150, this seq got hits: 188\n",
      "-- Max_genome_hits is: 150, this seq got hits: 667\n",
      "-- Max_genome_hits is: 150, this seq got hits: 808\n",
      "-- Max_genome_hits is: 150, this seq got hits: 178\n",
      "-- Max_genome_hits is: 150, this seq got hits: 177\n",
      "-- Max_genome_hits is: 150, this seq got hits: 429\n",
      "-- Max_genome_hits is: 150, this seq got hits: 256\n",
      "-- Max_genome_hits is: 150, this seq got hits: 193\n",
      "-- Max_genome_hits is: 150, this seq got hits: 614\n",
      "-- Max_genome_hits is: 150, this seq got hits: 156\n",
      "-- Max_genome_hits is: 150, this seq got hits: 7679\n",
      "-- Max_genome_hits is: 150, this seq got hits: 388\n",
      "-- Max_genome_hits is: 150, this seq got hits: 921\n",
      "-- Max_genome_hits is: 150, this seq got hits: 164\n",
      "-- Max_genome_hits is: 150, this seq got hits: 238\n",
      "-- Max_genome_hits is: 150, this seq got hits: 164\n",
      "-- Max_genome_hits is: 150, this seq got hits: 206\n",
      "-- Max_genome_hits is: 150, this seq got hits: 151\n",
      "-- Max_genome_hits is: 150, this seq got hits: 182\n",
      "-- Max_genome_hits is: 150, this seq got hits: 231\n",
      "-- Max_genome_hits is: 150, this seq got hits: 221\n",
      "-- Max_genome_hits is: 150, this seq got hits: 215\n",
      "-- Max_genome_hits is: 150, this seq got hits: 246\n",
      "-- Max_genome_hits is: 150, this seq got hits: 1656\n",
      "-- Max_genome_hits is: 150, this seq got hits: 210\n",
      "-- Max_genome_hits is: 150, this seq got hits: 200\n",
      "-- Max_genome_hits is: 150, this seq got hits: 152\n",
      "-- Max_genome_hits is: 150, this seq got hits: 281\n",
      "-- Max_genome_hits is: 150, this seq got hits: 173\n",
      "-- Max_genome_hits is: 150, this seq got hits: 209\n",
      "-- Max_genome_hits is: 150, this seq got hits: 180\n",
      "-- Max_genome_hits is: 150, this seq got hits: 252\n",
      "-- Max_genome_hits is: 150, this seq got hits: 153\n",
      "-- Max_genome_hits is: 150, this seq got hits: 157\n",
      "-- Max_genome_hits is: 150, this seq got hits: 335\n",
      "-- Max_genome_hits is: 150, this seq got hits: 169\n",
      "-- Max_genome_hits is: 150, this seq got hits: 309\n",
      "-- Max_genome_hits is: 150, this seq got hits: 151\n",
      "-- Max_genome_hits is: 150, this seq got hits: 627\n",
      "-- Max_genome_hits is: 150, this seq got hits: 184\n",
      "-- Max_genome_hits is: 150, this seq got hits: 394\n",
      "-- Max_genome_hits is: 150, this seq got hits: 204\n",
      "-- Max_genome_hits is: 150, this seq got hits: 259\n",
      "-- Max_genome_hits is: 150, this seq got hits: 190\n",
      "-- Max_genome_hits is: 150, this seq got hits: 182\n",
      "-- Max_genome_hits is: 150, this seq got hits: 525\n",
      "-- Max_genome_hits is: 150, this seq got hits: 261\n",
      "-- Max_genome_hits is: 150, this seq got hits: 217\n",
      "-- Max_genome_hits is: 150, this seq got hits: 181\n",
      "\n",
      "- 8.Probes not passing through genome filter: 207\n",
      "--  re-check region size:\n",
      "0 : 221\n",
      "1 : 400\n",
      "2 : 400\n",
      "3 : 400\n",
      "4 : 400\n",
      "5 : 400\n",
      "6 : 400\n",
      "7 : 400\n",
      "8 : 400\n",
      "9 : 400\n",
      "10 : 400\n",
      "11 : 400\n",
      "12 : 400\n",
      "13 : 400\n",
      "14 : 400\n",
      "15 : 400\n",
      "16 : 400\n",
      "17 : 400\n",
      "18 : 400\n",
      "19 : 400\n",
      "20 : 400\n",
      "21 : 400\n",
      "22 : 400\n",
      "23 : 400\n",
      "24 : 400\n",
      "25 : 400\n",
      "26 : 400\n",
      "27 : 400\n",
      "28 : 400\n",
      "29 : 400\n",
      "30 : 400\n",
      "31 : 400\n",
      "32 : 400\n",
      "33 : 400\n",
      "34 : 400\n",
      "35 : 400\n",
      "36 : 400\n",
      "37 : 400\n",
      "38 : 400\n",
      "39 : 400\n",
      "40 : 400\n",
      "41 : 400\n",
      "--- total number of probes: 16414\n",
      "\n",
      "- 9.Saving probes to: /n/boslfs/LABS/zhuang_lab/User/pzheng/Libraries/CTP-03/chr21_7by21/final_probes/filtered_probes.fasta\n"
     ]
    }
   ],
   "source": [
    "kept_records, kept_size_dic = Check_Probes(pb_records, pb_lists, sub_encodings, master_dir, \n",
    "                                           total_bc=3, save_dir = pb_dir,\n",
    "                                           fwd_primer=fprimer, rev_primer=rprimer,\n",
    "                                           stv_barcodes=stv_barcodes, ndb_barcodes=ndb_barcodes,\n",
    "                                           max_genome_hits=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
